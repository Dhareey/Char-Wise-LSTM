{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Copy of Char_Wise_LSTM.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neZktm4u5jE7",
        "colab_type": "text"
      },
      "source": [
        "<h1> INTRODUCTION</h1>\n",
        "This code runs a Character-Wise-LSTM on Yoruba text. The algorithm will train character by character on the yoruba text and also generate text character by character. I specifically chose Yoruba text because it has special characters in it.\n",
        "<h6>The model</h6>\n",
        "The model is based on Andrej Karpathy's <a href= \"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\">post on RNNs</a> and <a href= \"https://github.com/karpathy/char-rnn\">implementation in Torch</a>. Below is the general architecture of the character-wise RNN.\n",
        "\n",
        "<img src=\"https://github.com/Dhareey/Char-Wise-LSTM/blob/master/images/charseq.jpeg?raw=1\" width=\"500\">\n",
        "<h6>The Data</h6>\n",
        "The training data is an excerpt from yoruba bible. I have written a scrapper to scrap any chapter online in Yoruba. \n",
        "\n",
        "<h6> HOW TO GO ABOUT IT</h6>\n",
        "<ol>\n",
        "    <li>Get the data</li>\n",
        "    <li>The algorithm cant understand strings, so we have to convert it to numbers</li>\n",
        "    <li>Preprocess the data</li>\n",
        "    Since its a character-wise training, each character will be fed into the algorithm, one by one. To pass each character into the algorithm, we have to do one <a href=''>hot encoding</a>. Meaning, we will pass array of 1s and 0s, where the column of the character being passed is 1 and the other column is 0. This will be done for each letter in the data. Meaning, the total number of columns will be the total number of unique character in the text. For example. The letter a will be passed as\n",
        "    <p> [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] and the letter be will be passed as </p>\n",
        "    <p> [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]</p>\n",
        "    Where each column represents a unique letter in the alphabet\n",
        "    <li>Since the data is hundreds of thousand character long, we will have to train the algorithm in batches </li>\n",
        "    <li> Define the LSTM architecture</li>\n",
        "    <p> The architecture is pretty basic, one character enters the LSTM at a time. To understand how LSTM works, please chck out the \n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VobVUfXT5jFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scrapper import getchap\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLx55L345jF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step1: Getting the data\n",
        "book, validationbook = ['gal','heb','rom','rev','mat','mrk','luk','jhn'], ['heb', 'rom']\n",
        "chapter, validchapter = 6, 9\n",
        "data, validData= [], []\n",
        "for eachbook in book:\n",
        "    for i in range(chapter):\n",
        "        data.append(getchap(eachbook, str(i+1)))\n",
        "        \n",
        "for eachbook in validationbook:\n",
        "    for i in range(6,validchapter):\n",
        "        validData.append(getchap(eachbook, str(i+1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlcUr3g35jGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datas, valdatas = '\\n'.join(data), '\\n'.join(validData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW5uE9Px5jGf",
        "colab_type": "code",
        "outputId": "ae6233aa-9ce7-494f-fde5-47d6445c34e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#Visualise the data\n",
        "print(datas[:200])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Paulu Aposteli \n",
            "1 Paulu, aposteli tí a rán kì í ṣe láti ọ̀dọ̀ ènìyàn wá, tàbí nípa ènìyàn, ṣùgbọ́n nípa Jesu Kristi àti Ọlọ́run Baba, ẹni tí ó jí i dìde kúrò nínú òkú. \n",
            "2 Àti gbogbo àwọn arákùnrin t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s36Z10X75jG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step2: Tokenise the data\n",
        "uniquedata = tuple(set(datas))\n",
        "datacode = {alphabet:code for code,alphabet in dict(enumerate(uniquedata)).items()}\n",
        "encodedData = np.array([datacode[word] for word in datas])\n",
        "encodedvalData = np.array([datacode[word] for word in valdatas])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oopNB-u5jHI",
        "colab_type": "code",
        "outputId": "4f38d50e-9f0e-4bb6-8dd9-9d67a9888fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "#Visualise tokenised data\n",
        "encodedData[:100]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([54, 79, 71, 35, 78, 68, 78, 79, 37,  4, 49, 92, 46, 56, 68, 39, 79,\n",
              "       60, 54, 79, 71, 35, 78, 68, 78, 19, 79, 35,  4, 49, 92, 46, 56, 68,\n",
              "       39, 79, 46, 29, 79, 35, 79, 72, 82, 22, 79, 94, 33, 79, 29, 79, 57,\n",
              "       56, 79, 68, 82, 46, 39, 79, 80, 31, 38, 80, 31, 79, 44, 22, 33, 28,\n",
              "        2, 22, 79, 20, 82, 19, 79, 46,  2, 55, 29, 79, 22, 29,  4, 35, 79,\n",
              "       44, 22, 33, 28,  2, 22, 19, 79, 57, 93, 14, 55, 80, 81, 22])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0f-hkSg5jHb",
        "colab_type": "code",
        "outputId": "13bfc448-0c87-48c5-b721-fb65e1245b75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "encodedvalData[:100]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([36, 79, 42, 56, 68, 94, 39, 92, 56, 38, 56, 94, 39, 79, 66,  8, 81,\n",
              "       79,  2, 68, 93, 34, 82,  2, 79, 60, 54, 79, 48, 29, 46, 49, 72, 29,\n",
              "       79, 42, 56, 68, 94, 39, 92, 56, 38, 56, 94, 39, 79, 28, 33, 29, 19,\n",
              "       79, 80, 55, 35, 79, 88, 35, 68,  8, 11, 78, 19, 79,  2, 68, 93, 34,\n",
              "       82,  2, 79,  0, 68, 80, 81, 72, 78, 22, 79,  0, 31, 14, 82, 73, 32,\n",
              "       14, 49, 19, 79,  8, 22, 39, 79, 46, 29, 79, 52, 79,  4,  2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHG0cI345jHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_ydata = list(encodedData[1:])\n",
        "encoded_ydata.append(encodedData[0])\n",
        "validdatalist = list(encodedvalData[1:])\n",
        "validdatalist.append(encodedvalData[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAS4dxGa5jIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encodedydata= np.array(encoded_ydata)\n",
        "encodedvaliddata = np.array(validdatalist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzthIES15jIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(encodedData), torch.from_numpy(encodedydata))\n",
        "valid_data = TensorDataset(torch.from_numpy(encodedvalData), torch.from_numpy(encodedvaliddata))\n",
        "\n",
        "# dataloaders\n",
        "batch_size= 20\n",
        "seq_length= 100\n",
        "batch= batch_size * seq_length\n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=False, batch_size=batch, drop_last = True)\n",
        "valid_loader = DataLoader(valid_data, shuffle=False, batch_size=batch, drop_last= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu88bdPV5jIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter= iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "\n",
        "validiter = iter(valid_loader)\n",
        "valid_x, valid_y = dataiter.next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0_oF6Wv5jIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 3. Onehot encoding\n",
        "def oneHotEncode(arr, cols_num):\n",
        "    \"\"\"\n",
        "    This function takes in an pytorch dataloader object and returns a one-hot encoded array with dimensions of array x n_labels.\n",
        "    E.G if it takes an array of [3,2,1] and n_labels of 8, it returns a 3x3(array_size by cols_num) hot encoded array like so\n",
        "    [[0 0 1 0 0 0 0 0]\n",
        "    [0 1 0 0 0 0 0 0]\n",
        "    [1 0 0 0 0 0 0 0]]\n",
        "    \"\"\"\n",
        "    array = np.array(arr)\n",
        "    # First, create an array.size by cols_num array of zeros in float\n",
        "    one_hot = np.zeros((array.size,cols_num), dtype= np.float32)\n",
        "    \n",
        "    # Fill a \"1\" to each row based on the value in array\n",
        "    one_hot[np.arange(one_hot.shape[0]), array.flatten()] = 1.\n",
        "    \n",
        "    # Return back to the original shape\n",
        "    one_hot = one_hot.reshape((*array.shape, cols_num))\n",
        "    return torch.from_numpy(one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foowOx-35jLq",
        "colab_type": "code",
        "outputId": "3f094119-6bf3-4fd7-b1b7-466964ef7191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "if (train_on_gpu):\n",
        "  print('Yaay, CUDA is available, now you can train')\n",
        "else:\n",
        "  print('Dude, dont try it, your pc is gonna crash')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yaay, CUDA is available, now you can train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2BU4myQ5jMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 4 Model Architecture\n",
        "class yorLSTM(nn.Module):\n",
        "    def __init__(self, tokens, n_hidden, n_layers=2,drop_prob=0.5,lr= 0.001):\n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden= n_hidden\n",
        "        self.lr = lr\n",
        "            \n",
        "        #Here, we are creating character dict for the project\n",
        "        self.chars = tokens\n",
        "        self.int2chars = dict(enumerate(self.chars))\n",
        "        self.char2int = {num:alphabet for alphabet,num in self.int2chars.items()}\n",
        "            \n",
        "        # Define model layers\n",
        "        self.lstm = nn.LSTM(len(self.chars), self.n_hidden, self.n_layers,dropout=drop_prob,batch_first=True)\n",
        "            \n",
        "        # Dropout in between layers\n",
        "        self.dropout =nn.Dropout(drop_prob)\n",
        "            \n",
        "        # Connect to a fully connected layer\n",
        "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        out, hidden = self.lstm(x, hidden)\n",
        "        \n",
        "        # Dropout to avoid overfitting\n",
        "        out= self.dropout(out)\n",
        "        \n",
        "        # Reshape for fully connected layer\n",
        "        out = out.contiguous().view(-1, self.n_hidden)\n",
        "        \n",
        "        # Pass through a fully connected layer\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        #return out, hidden\n",
        "        return out, hidden\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "        # Initialize the weight and hidden value\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers,batch_size,self.n_hidden).zero_().cuda(),\n",
        "                      weight.new(self.n_layers,batch_size,self.n_hidden).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                      weight.new(self.n_layers,batch_size,self.n_hidden).zero_())\n",
        "        \n",
        "        return hidden\n",
        "        \n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5n3SMz95jMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step5 Train the Model\n",
        "def train(network,training_data, validation_data, epochs, batch_size,lr, seq_length, clip=5, vis=10):\n",
        "    # Set the RNN network to train\n",
        "    network.train()\n",
        "    \n",
        "    #Set the optimiser and calculate the loss\n",
        "    optimiser = torch.optim.Adam(network.parameters(), lr= lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # Run on CUDA if available\n",
        "    if (train_on_gpu):\n",
        "        network.cuda()\n",
        "        \n",
        "    counter = 0\n",
        "    # set total number of characters\n",
        "    n_chars = len(network.chars)\n",
        "    \n",
        "    # Train in range of epochs\n",
        "    for i in range(epochs):\n",
        "        # initialise the hidden state\n",
        "        h = network.init_hidden(batch_size)\n",
        "        for x, y in training_data:\n",
        "            counter+=1\n",
        "            \n",
        "            # One-Hot-Encode the training data\n",
        "            x = oneHotEncode(x.reshape(batch_size,seq_length), n_chars)\n",
        "            \n",
        "            # If on Cuda, cnvert the x and y to cuda\n",
        "            if (train_on_gpu):\n",
        "                x, y = x.cuda(), y.cuda()\n",
        "            \n",
        "            # Creating new variables for the hidden state, otherwise\n",
        "            # we'd backprop through the entire training history\n",
        "            h = tuple([each.data for each in h])\n",
        "            \n",
        "            # Set accumulated gradient to zero\n",
        "            network.zero_grad()\n",
        "            \n",
        "            output, h = network(x, h)\n",
        "            \n",
        "            # Calculate the loss and back propagate\n",
        "            loss = criterion(output, y.view(batch_size*seq_length).long())\n",
        "            loss.backward()\n",
        "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "            nn.utils.clip_grad_norm_(network.parameters(), clip)\n",
        "            optimiser.step()\n",
        "            \n",
        "            # Calculate validation loss at every 10 iteration\n",
        "            if counter% vis == 0:\n",
        "                # Initialise the hidden state\n",
        "                val_h = network.init_hidden(batch_size)\n",
        "                validation_losses = []\n",
        "                \n",
        "                #set network to evalution\n",
        "                network.eval()\n",
        "                \n",
        "                for x,y in validation_data:\n",
        "                    x = oneHotEncode(x.reshape(batch_size,seq_length), n_chars)\n",
        "                    \n",
        "                    if (train_on_gpu):\n",
        "                        x,y = x.cuda(), y.cuda()\n",
        "                    val_h = tuple([each for each in val_h])\n",
        "                    \n",
        "                    output, val_h = network(x, val_h)\n",
        "                    \n",
        "                    #Calculate the loss\n",
        "                    loss = criterion(output, y.view(batch_size* seq_length).long())\n",
        "                    \n",
        "                    # Append loss to validation losses\n",
        "                    validation_losses.append(loss.item())\n",
        "                    \n",
        "                    # Set network back to training\n",
        "                    network.train()\n",
        "                    \n",
        "                    print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
        "                      \"Step: {}...\".format(counter),\n",
        "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
        "                      \"Val Loss: {:.4f}\".format(np.mean(validation_losses)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpTu3h8_5jMq",
        "colab_type": "code",
        "outputId": "d46e7176-95e4-4876-95f4-8d9beb81e056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "\n",
        "# Instantiate the LSTM Model\n",
        "n_hidden = 500\n",
        "\n",
        "network = yorLSTM(uniquedata,n_hidden)\n",
        "print(network)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yorLSTM(\n",
            "  (lstm): LSTM(97, 500, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=500, out_features=97, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdP2469JAbl9",
        "colab_type": "code",
        "outputId": "548744a2-3c47-4d95-a43d-c67b36a2481b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initiate the training\n",
        "epochs = 40\n",
        "lr = 0.001\n",
        "train(network,train_loader,valid_loader,epochs,batch_size,lr,seq_length)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/40... Step: 10... Loss: 3.5576... Val Loss: 3.5576\n",
            "Epoch: 1/40... Step: 10... Loss: 3.5659... Val Loss: 3.5618\n",
            "Epoch: 1/40... Step: 10... Loss: 3.5607... Val Loss: 3.5614\n",
            "Epoch: 1/40... Step: 10... Loss: 3.5602... Val Loss: 3.5611\n",
            "Epoch: 1/40... Step: 10... Loss: 3.4880... Val Loss: 3.5465\n",
            "Epoch: 1/40... Step: 10... Loss: 3.5762... Val Loss: 3.5514\n",
            "Epoch: 1/40... Step: 10... Loss: 3.5089... Val Loss: 3.5454\n",
            "Epoch: 1/40... Step: 10... Loss: 3.5487... Val Loss: 3.5458\n",
            "Epoch: 1/40... Step: 10... Loss: 3.5582... Val Loss: 3.5472\n",
            "Epoch: 1/40... Step: 10... Loss: 3.6091... Val Loss: 3.5534\n",
            "Epoch: 1/40... Step: 20... Loss: 3.4866... Val Loss: 3.4866\n",
            "Epoch: 1/40... Step: 20... Loss: 3.4578... Val Loss: 3.4722\n",
            "Epoch: 1/40... Step: 20... Loss: 3.4457... Val Loss: 3.4634\n",
            "Epoch: 1/40... Step: 20... Loss: 3.4926... Val Loss: 3.4707\n",
            "Epoch: 1/40... Step: 20... Loss: 3.3997... Val Loss: 3.4565\n",
            "Epoch: 1/40... Step: 20... Loss: 3.4667... Val Loss: 3.4582\n",
            "Epoch: 1/40... Step: 20... Loss: 3.4372... Val Loss: 3.4552\n",
            "Epoch: 1/40... Step: 20... Loss: 3.4384... Val Loss: 3.4531\n",
            "Epoch: 1/40... Step: 20... Loss: 3.4673... Val Loss: 3.4547\n",
            "Epoch: 1/40... Step: 20... Loss: 3.5029... Val Loss: 3.4595\n",
            "Epoch: 1/40... Step: 30... Loss: 3.4598... Val Loss: 3.4598\n",
            "Epoch: 1/40... Step: 30... Loss: 3.4528... Val Loss: 3.4563\n",
            "Epoch: 1/40... Step: 30... Loss: 3.4497... Val Loss: 3.4541\n",
            "Epoch: 1/40... Step: 30... Loss: 3.4510... Val Loss: 3.4533\n",
            "Epoch: 1/40... Step: 30... Loss: 3.3715... Val Loss: 3.4370\n",
            "Epoch: 1/40... Step: 30... Loss: 3.4410... Val Loss: 3.4376\n",
            "Epoch: 1/40... Step: 30... Loss: 3.3949... Val Loss: 3.4315\n",
            "Epoch: 1/40... Step: 30... Loss: 3.4199... Val Loss: 3.4301\n",
            "Epoch: 1/40... Step: 30... Loss: 3.4426... Val Loss: 3.4315\n",
            "Epoch: 1/40... Step: 30... Loss: 3.4864... Val Loss: 3.4370\n",
            "Epoch: 1/40... Step: 40... Loss: 3.4810... Val Loss: 3.4810\n",
            "Epoch: 1/40... Step: 40... Loss: 3.4670... Val Loss: 3.4740\n",
            "Epoch: 1/40... Step: 40... Loss: 3.4340... Val Loss: 3.4606\n",
            "Epoch: 1/40... Step: 40... Loss: 3.4826... Val Loss: 3.4661\n",
            "Epoch: 1/40... Step: 40... Loss: 3.4137... Val Loss: 3.4556\n",
            "Epoch: 1/40... Step: 40... Loss: 3.4579... Val Loss: 3.4560\n",
            "Epoch: 1/40... Step: 40... Loss: 3.4395... Val Loss: 3.4537\n",
            "Epoch: 1/40... Step: 40... Loss: 3.4515... Val Loss: 3.4534\n",
            "Epoch: 1/40... Step: 40... Loss: 3.4566... Val Loss: 3.4538\n",
            "Epoch: 1/40... Step: 40... Loss: 3.4854... Val Loss: 3.4569\n",
            "Epoch: 1/40... Step: 50... Loss: 3.4788... Val Loss: 3.4788\n",
            "Epoch: 1/40... Step: 50... Loss: 3.4595... Val Loss: 3.4692\n",
            "Epoch: 1/40... Step: 50... Loss: 3.4507... Val Loss: 3.4630\n",
            "Epoch: 1/40... Step: 50... Loss: 3.4847... Val Loss: 3.4684\n",
            "Epoch: 1/40... Step: 50... Loss: 3.3975... Val Loss: 3.4542\n",
            "Epoch: 1/40... Step: 50... Loss: 3.4622... Val Loss: 3.4556\n",
            "Epoch: 1/40... Step: 50... Loss: 3.4259... Val Loss: 3.4513\n",
            "Epoch: 1/40... Step: 50... Loss: 3.4437... Val Loss: 3.4504\n",
            "Epoch: 1/40... Step: 50... Loss: 3.4643... Val Loss: 3.4519\n",
            "Epoch: 1/40... Step: 50... Loss: 3.4697... Val Loss: 3.4537\n",
            "Epoch: 1/40... Step: 60... Loss: 3.4795... Val Loss: 3.4795\n",
            "Epoch: 1/40... Step: 60... Loss: 3.4558... Val Loss: 3.4677\n",
            "Epoch: 1/40... Step: 60... Loss: 3.4443... Val Loss: 3.4599\n",
            "Epoch: 1/40... Step: 60... Loss: 3.4711... Val Loss: 3.4627\n",
            "Epoch: 1/40... Step: 60... Loss: 3.3929... Val Loss: 3.4487\n",
            "Epoch: 1/40... Step: 60... Loss: 3.4896... Val Loss: 3.4555\n",
            "Epoch: 1/40... Step: 60... Loss: 3.4485... Val Loss: 3.4545\n",
            "Epoch: 1/40... Step: 60... Loss: 3.4417... Val Loss: 3.4529\n",
            "Epoch: 1/40... Step: 60... Loss: 3.4580... Val Loss: 3.4535\n",
            "Epoch: 1/40... Step: 60... Loss: 3.4882... Val Loss: 3.4570\n",
            "Epoch: 1/40... Step: 70... Loss: 3.4638... Val Loss: 3.4638\n",
            "Epoch: 1/40... Step: 70... Loss: 3.4347... Val Loss: 3.4492\n",
            "Epoch: 1/40... Step: 70... Loss: 3.4225... Val Loss: 3.4403\n",
            "Epoch: 1/40... Step: 70... Loss: 3.4547... Val Loss: 3.4439\n",
            "Epoch: 1/40... Step: 70... Loss: 3.3862... Val Loss: 3.4324\n",
            "Epoch: 1/40... Step: 70... Loss: 3.4488... Val Loss: 3.4351\n",
            "Epoch: 1/40... Step: 70... Loss: 3.4012... Val Loss: 3.4303\n",
            "Epoch: 1/40... Step: 70... Loss: 3.4174... Val Loss: 3.4287\n",
            "Epoch: 1/40... Step: 70... Loss: 3.4243... Val Loss: 3.4282\n",
            "Epoch: 1/40... Step: 70... Loss: 3.4541... Val Loss: 3.4308\n",
            "Epoch: 1/40... Step: 80... Loss: 3.4737... Val Loss: 3.4737\n",
            "Epoch: 1/40... Step: 80... Loss: 3.4744... Val Loss: 3.4741\n",
            "Epoch: 1/40... Step: 80... Loss: 3.4640... Val Loss: 3.4707\n",
            "Epoch: 1/40... Step: 80... Loss: 3.4807... Val Loss: 3.4732\n",
            "Epoch: 1/40... Step: 80... Loss: 3.4293... Val Loss: 3.4644\n",
            "Epoch: 1/40... Step: 80... Loss: 3.4603... Val Loss: 3.4637\n",
            "Epoch: 1/40... Step: 80... Loss: 3.4278... Val Loss: 3.4586\n",
            "Epoch: 1/40... Step: 80... Loss: 3.4511... Val Loss: 3.4577\n",
            "Epoch: 1/40... Step: 80... Loss: 3.4553... Val Loss: 3.4574\n",
            "Epoch: 1/40... Step: 80... Loss: 3.4672... Val Loss: 3.4584\n",
            "Epoch: 1/40... Step: 90... Loss: 3.4368... Val Loss: 3.4368\n",
            "Epoch: 1/40... Step: 90... Loss: 3.4122... Val Loss: 3.4245\n",
            "Epoch: 1/40... Step: 90... Loss: 3.3922... Val Loss: 3.4137\n",
            "Epoch: 1/40... Step: 90... Loss: 3.4249... Val Loss: 3.4165\n",
            "Epoch: 1/40... Step: 90... Loss: 3.3489... Val Loss: 3.4030\n",
            "Epoch: 1/40... Step: 90... Loss: 3.3945... Val Loss: 3.4016\n",
            "Epoch: 1/40... Step: 90... Loss: 3.3668... Val Loss: 3.3966\n",
            "Epoch: 1/40... Step: 90... Loss: 3.3855... Val Loss: 3.3952\n",
            "Epoch: 1/40... Step: 90... Loss: 3.4120... Val Loss: 3.3971\n",
            "Epoch: 1/40... Step: 90... Loss: 3.4210... Val Loss: 3.3995\n",
            "Epoch: 2/40... Step: 100... Loss: 3.3967... Val Loss: 3.3967\n",
            "Epoch: 2/40... Step: 100... Loss: 3.3708... Val Loss: 3.3837\n",
            "Epoch: 2/40... Step: 100... Loss: 3.3452... Val Loss: 3.3709\n",
            "Epoch: 2/40... Step: 100... Loss: 3.3762... Val Loss: 3.3722\n",
            "Epoch: 2/40... Step: 100... Loss: 3.3025... Val Loss: 3.3583\n",
            "Epoch: 2/40... Step: 100... Loss: 3.3555... Val Loss: 3.3578\n",
            "Epoch: 2/40... Step: 100... Loss: 3.3217... Val Loss: 3.3527\n",
            "Epoch: 2/40... Step: 100... Loss: 3.3483... Val Loss: 3.3521\n",
            "Epoch: 2/40... Step: 100... Loss: 3.3658... Val Loss: 3.3536\n",
            "Epoch: 2/40... Step: 100... Loss: 3.3782... Val Loss: 3.3561\n",
            "Epoch: 2/40... Step: 110... Loss: 3.3160... Val Loss: 3.3160\n",
            "Epoch: 2/40... Step: 110... Loss: 3.2884... Val Loss: 3.3022\n",
            "Epoch: 2/40... Step: 110... Loss: 3.2687... Val Loss: 3.2911\n",
            "Epoch: 2/40... Step: 110... Loss: 3.2917... Val Loss: 3.2912\n",
            "Epoch: 2/40... Step: 110... Loss: 3.2211... Val Loss: 3.2772\n",
            "Epoch: 2/40... Step: 110... Loss: 3.2584... Val Loss: 3.2741\n",
            "Epoch: 2/40... Step: 110... Loss: 3.2301... Val Loss: 3.2678\n",
            "Epoch: 2/40... Step: 110... Loss: 3.2573... Val Loss: 3.2665\n",
            "Epoch: 2/40... Step: 110... Loss: 3.2810... Val Loss: 3.2681\n",
            "Epoch: 2/40... Step: 110... Loss: 3.2909... Val Loss: 3.2704\n",
            "Epoch: 2/40... Step: 120... Loss: 3.2171... Val Loss: 3.2171\n",
            "Epoch: 2/40... Step: 120... Loss: 3.1884... Val Loss: 3.2028\n",
            "Epoch: 2/40... Step: 120... Loss: 3.1807... Val Loss: 3.1954\n",
            "Epoch: 2/40... Step: 120... Loss: 3.1816... Val Loss: 3.1920\n",
            "Epoch: 2/40... Step: 120... Loss: 3.1183... Val Loss: 3.1772\n",
            "Epoch: 2/40... Step: 120... Loss: 3.1536... Val Loss: 3.1733\n",
            "Epoch: 2/40... Step: 120... Loss: 3.1191... Val Loss: 3.1656\n",
            "Epoch: 2/40... Step: 120... Loss: 3.1253... Val Loss: 3.1605\n",
            "Epoch: 2/40... Step: 120... Loss: 3.1746... Val Loss: 3.1621\n",
            "Epoch: 2/40... Step: 120... Loss: 3.2042... Val Loss: 3.1663\n",
            "Epoch: 2/40... Step: 130... Loss: 3.1335... Val Loss: 3.1335\n",
            "Epoch: 2/40... Step: 130... Loss: 3.1020... Val Loss: 3.1178\n",
            "Epoch: 2/40... Step: 130... Loss: 3.0720... Val Loss: 3.1025\n",
            "Epoch: 2/40... Step: 130... Loss: 3.0919... Val Loss: 3.0999\n",
            "Epoch: 2/40... Step: 130... Loss: 3.0335... Val Loss: 3.0866\n",
            "Epoch: 2/40... Step: 130... Loss: 3.0349... Val Loss: 3.0780\n",
            "Epoch: 2/40... Step: 130... Loss: 3.0143... Val Loss: 3.0689\n",
            "Epoch: 2/40... Step: 130... Loss: 3.0356... Val Loss: 3.0647\n",
            "Epoch: 2/40... Step: 130... Loss: 3.0854... Val Loss: 3.0670\n",
            "Epoch: 2/40... Step: 130... Loss: 3.0947... Val Loss: 3.0698\n",
            "Epoch: 2/40... Step: 140... Loss: 3.0616... Val Loss: 3.0616\n",
            "Epoch: 2/40... Step: 140... Loss: 3.0302... Val Loss: 3.0459\n",
            "Epoch: 2/40... Step: 140... Loss: 2.9922... Val Loss: 3.0280\n",
            "Epoch: 2/40... Step: 140... Loss: 3.0115... Val Loss: 3.0239\n",
            "Epoch: 2/40... Step: 140... Loss: 2.9326... Val Loss: 3.0056\n",
            "Epoch: 2/40... Step: 140... Loss: 2.9633... Val Loss: 2.9986\n",
            "Epoch: 2/40... Step: 140... Loss: 2.9248... Val Loss: 2.9880\n",
            "Epoch: 2/40... Step: 140... Loss: 2.9177... Val Loss: 2.9792\n",
            "Epoch: 2/40... Step: 140... Loss: 3.0130... Val Loss: 2.9830\n",
            "Epoch: 2/40... Step: 140... Loss: 2.9979... Val Loss: 2.9845\n",
            "Epoch: 2/40... Step: 150... Loss: 2.9881... Val Loss: 2.9881\n",
            "Epoch: 2/40... Step: 150... Loss: 2.9518... Val Loss: 2.9699\n",
            "Epoch: 2/40... Step: 150... Loss: 2.9390... Val Loss: 2.9596\n",
            "Epoch: 2/40... Step: 150... Loss: 2.9512... Val Loss: 2.9575\n",
            "Epoch: 2/40... Step: 150... Loss: 2.8324... Val Loss: 2.9325\n",
            "Epoch: 2/40... Step: 150... Loss: 2.8848... Val Loss: 2.9245\n",
            "Epoch: 2/40... Step: 150... Loss: 2.8694... Val Loss: 2.9167\n",
            "Epoch: 2/40... Step: 150... Loss: 2.8291... Val Loss: 2.9057\n",
            "Epoch: 2/40... Step: 150... Loss: 2.9346... Val Loss: 2.9089\n",
            "Epoch: 2/40... Step: 150... Loss: 2.9204... Val Loss: 2.9101\n",
            "Epoch: 2/40... Step: 160... Loss: 2.9416... Val Loss: 2.9416\n",
            "Epoch: 2/40... Step: 160... Loss: 2.8796... Val Loss: 2.9106\n",
            "Epoch: 2/40... Step: 160... Loss: 2.8730... Val Loss: 2.8981\n",
            "Epoch: 2/40... Step: 160... Loss: 2.8884... Val Loss: 2.8956\n",
            "Epoch: 2/40... Step: 160... Loss: 2.8033... Val Loss: 2.8772\n",
            "Epoch: 2/40... Step: 160... Loss: 2.8118... Val Loss: 2.8663\n",
            "Epoch: 2/40... Step: 160... Loss: 2.8075... Val Loss: 2.8579\n",
            "Epoch: 2/40... Step: 160... Loss: 2.7742... Val Loss: 2.8474\n",
            "Epoch: 2/40... Step: 160... Loss: 2.8628... Val Loss: 2.8491\n",
            "Epoch: 2/40... Step: 160... Loss: 2.8528... Val Loss: 2.8495\n",
            "Epoch: 2/40... Step: 170... Loss: 2.8158... Val Loss: 2.8158\n",
            "Epoch: 2/40... Step: 170... Loss: 2.7558... Val Loss: 2.7858\n",
            "Epoch: 2/40... Step: 170... Loss: 2.7779... Val Loss: 2.7832\n",
            "Epoch: 2/40... Step: 170... Loss: 2.7902... Val Loss: 2.7849\n",
            "Epoch: 2/40... Step: 170... Loss: 2.6877... Val Loss: 2.7655\n",
            "Epoch: 2/40... Step: 170... Loss: 2.6958... Val Loss: 2.7539\n",
            "Epoch: 2/40... Step: 170... Loss: 2.6775... Val Loss: 2.7430\n",
            "Epoch: 2/40... Step: 170... Loss: 2.6335... Val Loss: 2.7293\n",
            "Epoch: 2/40... Step: 170... Loss: 2.7562... Val Loss: 2.7323\n",
            "Epoch: 2/40... Step: 170... Loss: 2.7154... Val Loss: 2.7306\n",
            "Epoch: 2/40... Step: 180... Loss: 2.7293... Val Loss: 2.7293\n",
            "Epoch: 2/40... Step: 180... Loss: 2.6646... Val Loss: 2.6969\n",
            "Epoch: 2/40... Step: 180... Loss: 2.6868... Val Loss: 2.6935\n",
            "Epoch: 2/40... Step: 180... Loss: 2.7022... Val Loss: 2.6957\n",
            "Epoch: 2/40... Step: 180... Loss: 2.6094... Val Loss: 2.6785\n",
            "Epoch: 2/40... Step: 180... Loss: 2.5850... Val Loss: 2.6629\n",
            "Epoch: 2/40... Step: 180... Loss: 2.5592... Val Loss: 2.6481\n",
            "Epoch: 2/40... Step: 180... Loss: 2.5176... Val Loss: 2.6318\n",
            "Epoch: 2/40... Step: 180... Loss: 2.6485... Val Loss: 2.6336\n",
            "Epoch: 2/40... Step: 180... Loss: 2.6012... Val Loss: 2.6304\n",
            "Epoch: 3/40... Step: 190... Loss: 2.6447... Val Loss: 2.6447\n",
            "Epoch: 3/40... Step: 190... Loss: 2.5534... Val Loss: 2.5990\n",
            "Epoch: 3/40... Step: 190... Loss: 2.5983... Val Loss: 2.5988\n",
            "Epoch: 3/40... Step: 190... Loss: 2.6109... Val Loss: 2.6018\n",
            "Epoch: 3/40... Step: 190... Loss: 2.5151... Val Loss: 2.5845\n",
            "Epoch: 3/40... Step: 190... Loss: 2.4674... Val Loss: 2.5650\n",
            "Epoch: 3/40... Step: 190... Loss: 2.4688... Val Loss: 2.5512\n",
            "Epoch: 3/40... Step: 190... Loss: 2.4260... Val Loss: 2.5356\n",
            "Epoch: 3/40... Step: 190... Loss: 2.5388... Val Loss: 2.5359\n",
            "Epoch: 3/40... Step: 190... Loss: 2.5262... Val Loss: 2.5350\n",
            "Epoch: 3/40... Step: 200... Loss: 2.5674... Val Loss: 2.5674\n",
            "Epoch: 3/40... Step: 200... Loss: 2.4438... Val Loss: 2.5056\n",
            "Epoch: 3/40... Step: 200... Loss: 2.5403... Val Loss: 2.5172\n",
            "Epoch: 3/40... Step: 200... Loss: 2.5085... Val Loss: 2.5150\n",
            "Epoch: 3/40... Step: 200... Loss: 2.4213... Val Loss: 2.4963\n",
            "Epoch: 3/40... Step: 200... Loss: 2.4052... Val Loss: 2.4811\n",
            "Epoch: 3/40... Step: 200... Loss: 2.3516... Val Loss: 2.4626\n",
            "Epoch: 3/40... Step: 200... Loss: 2.3301... Val Loss: 2.4460\n",
            "Epoch: 3/40... Step: 200... Loss: 2.4601... Val Loss: 2.4476\n",
            "Epoch: 3/40... Step: 200... Loss: 2.4724... Val Loss: 2.4501\n",
            "Epoch: 3/40... Step: 210... Loss: 2.5132... Val Loss: 2.5132\n",
            "Epoch: 3/40... Step: 210... Loss: 2.4071... Val Loss: 2.4602\n",
            "Epoch: 3/40... Step: 210... Loss: 2.5087... Val Loss: 2.4763\n",
            "Epoch: 3/40... Step: 210... Loss: 2.4728... Val Loss: 2.4754\n",
            "Epoch: 3/40... Step: 210... Loss: 2.3776... Val Loss: 2.4559\n",
            "Epoch: 3/40... Step: 210... Loss: 2.3206... Val Loss: 2.4333\n",
            "Epoch: 3/40... Step: 210... Loss: 2.2810... Val Loss: 2.4116\n",
            "Epoch: 3/40... Step: 210... Loss: 2.2921... Val Loss: 2.3966\n",
            "Epoch: 3/40... Step: 210... Loss: 2.3959... Val Loss: 2.3966\n",
            "Epoch: 3/40... Step: 210... Loss: 2.4064... Val Loss: 2.3975\n",
            "Epoch: 3/40... Step: 220... Loss: 2.4828... Val Loss: 2.4828\n",
            "Epoch: 3/40... Step: 220... Loss: 2.3736... Val Loss: 2.4282\n",
            "Epoch: 3/40... Step: 220... Loss: 2.4616... Val Loss: 2.4394\n",
            "Epoch: 3/40... Step: 220... Loss: 2.4498... Val Loss: 2.4420\n",
            "Epoch: 3/40... Step: 220... Loss: 2.3663... Val Loss: 2.4268\n",
            "Epoch: 3/40... Step: 220... Loss: 2.3353... Val Loss: 2.4116\n",
            "Epoch: 3/40... Step: 220... Loss: 2.2887... Val Loss: 2.3940\n",
            "Epoch: 3/40... Step: 220... Loss: 2.2837... Val Loss: 2.3802\n",
            "Epoch: 3/40... Step: 220... Loss: 2.3818... Val Loss: 2.3804\n",
            "Epoch: 3/40... Step: 220... Loss: 2.4085... Val Loss: 2.3832\n",
            "Epoch: 3/40... Step: 230... Loss: 2.4682... Val Loss: 2.4682\n",
            "Epoch: 3/40... Step: 230... Loss: 2.3532... Val Loss: 2.4107\n",
            "Epoch: 3/40... Step: 230... Loss: 2.4385... Val Loss: 2.4199\n",
            "Epoch: 3/40... Step: 230... Loss: 2.4465... Val Loss: 2.4266\n",
            "Epoch: 3/40... Step: 230... Loss: 2.3274... Val Loss: 2.4067\n",
            "Epoch: 3/40... Step: 230... Loss: 2.3236... Val Loss: 2.3929\n",
            "Epoch: 3/40... Step: 230... Loss: 2.2684... Val Loss: 2.3751\n",
            "Epoch: 3/40... Step: 230... Loss: 2.2602... Val Loss: 2.3607\n",
            "Epoch: 3/40... Step: 230... Loss: 2.3613... Val Loss: 2.3608\n",
            "Epoch: 3/40... Step: 230... Loss: 2.3655... Val Loss: 2.3613\n",
            "Epoch: 3/40... Step: 240... Loss: 2.4488... Val Loss: 2.4488\n",
            "Epoch: 3/40... Step: 240... Loss: 2.3388... Val Loss: 2.3938\n",
            "Epoch: 3/40... Step: 240... Loss: 2.4246... Val Loss: 2.4041\n",
            "Epoch: 3/40... Step: 240... Loss: 2.4068... Val Loss: 2.4048\n",
            "Epoch: 3/40... Step: 240... Loss: 2.3118... Val Loss: 2.3862\n",
            "Epoch: 3/40... Step: 240... Loss: 2.3017... Val Loss: 2.3721\n",
            "Epoch: 3/40... Step: 240... Loss: 2.2489... Val Loss: 2.3545\n",
            "Epoch: 3/40... Step: 240... Loss: 2.2406... Val Loss: 2.3403\n",
            "Epoch: 3/40... Step: 240... Loss: 2.3249... Val Loss: 2.3385\n",
            "Epoch: 3/40... Step: 240... Loss: 2.3299... Val Loss: 2.3377\n",
            "Epoch: 3/40... Step: 250... Loss: 2.4305... Val Loss: 2.4305\n",
            "Epoch: 3/40... Step: 250... Loss: 2.2943... Val Loss: 2.3624\n",
            "Epoch: 3/40... Step: 250... Loss: 2.4185... Val Loss: 2.3811\n",
            "Epoch: 3/40... Step: 250... Loss: 2.4072... Val Loss: 2.3876\n",
            "Epoch: 3/40... Step: 250... Loss: 2.2746... Val Loss: 2.3650\n",
            "Epoch: 3/40... Step: 250... Loss: 2.2929... Val Loss: 2.3530\n",
            "Epoch: 3/40... Step: 250... Loss: 2.2275... Val Loss: 2.3351\n",
            "Epoch: 3/40... Step: 250... Loss: 2.2168... Val Loss: 2.3203\n",
            "Epoch: 3/40... Step: 250... Loss: 2.3144... Val Loss: 2.3196\n",
            "Epoch: 3/40... Step: 250... Loss: 2.3031... Val Loss: 2.3180\n",
            "Epoch: 3/40... Step: 260... Loss: 2.4056... Val Loss: 2.4056\n",
            "Epoch: 3/40... Step: 260... Loss: 2.3008... Val Loss: 2.3532\n",
            "Epoch: 3/40... Step: 260... Loss: 2.4023... Val Loss: 2.3695\n",
            "Epoch: 3/40... Step: 260... Loss: 2.3775... Val Loss: 2.3715\n",
            "Epoch: 3/40... Step: 260... Loss: 2.2742... Val Loss: 2.3521\n",
            "Epoch: 3/40... Step: 260... Loss: 2.2611... Val Loss: 2.3369\n",
            "Epoch: 3/40... Step: 260... Loss: 2.2106... Val Loss: 2.3189\n",
            "Epoch: 3/40... Step: 260... Loss: 2.2099... Val Loss: 2.3052\n",
            "Epoch: 3/40... Step: 260... Loss: 2.2842... Val Loss: 2.3029\n",
            "Epoch: 3/40... Step: 260... Loss: 2.2499... Val Loss: 2.2976\n",
            "Epoch: 3/40... Step: 270... Loss: 2.3851... Val Loss: 2.3851\n",
            "Epoch: 3/40... Step: 270... Loss: 2.2515... Val Loss: 2.3183\n",
            "Epoch: 3/40... Step: 270... Loss: 2.3808... Val Loss: 2.3391\n",
            "Epoch: 3/40... Step: 270... Loss: 2.3377... Val Loss: 2.3388\n",
            "Epoch: 3/40... Step: 270... Loss: 2.2428... Val Loss: 2.3196\n",
            "Epoch: 3/40... Step: 270... Loss: 2.2215... Val Loss: 2.3032\n",
            "Epoch: 3/40... Step: 270... Loss: 2.1323... Val Loss: 2.2788\n",
            "Epoch: 3/40... Step: 270... Loss: 2.1603... Val Loss: 2.2640\n",
            "Epoch: 3/40... Step: 270... Loss: 2.2379... Val Loss: 2.2611\n",
            "Epoch: 3/40... Step: 270... Loss: 2.2262... Val Loss: 2.2576\n",
            "Epoch: 4/40... Step: 280... Loss: 2.3617... Val Loss: 2.3617\n",
            "Epoch: 4/40... Step: 280... Loss: 2.2119... Val Loss: 2.2868\n",
            "Epoch: 4/40... Step: 280... Loss: 2.3410... Val Loss: 2.3049\n",
            "Epoch: 4/40... Step: 280... Loss: 2.3152... Val Loss: 2.3074\n",
            "Epoch: 4/40... Step: 280... Loss: 2.2083... Val Loss: 2.2876\n",
            "Epoch: 4/40... Step: 280... Loss: 2.1640... Val Loss: 2.2670\n",
            "Epoch: 4/40... Step: 280... Loss: 2.1021... Val Loss: 2.2435\n",
            "Epoch: 4/40... Step: 280... Loss: 2.1246... Val Loss: 2.2286\n",
            "Epoch: 4/40... Step: 280... Loss: 2.2278... Val Loss: 2.2285\n",
            "Epoch: 4/40... Step: 280... Loss: 2.1854... Val Loss: 2.2242\n",
            "Epoch: 4/40... Step: 290... Loss: 2.3144... Val Loss: 2.3144\n",
            "Epoch: 4/40... Step: 290... Loss: 2.1665... Val Loss: 2.2405\n",
            "Epoch: 4/40... Step: 290... Loss: 2.2982... Val Loss: 2.2597\n",
            "Epoch: 4/40... Step: 290... Loss: 2.2824... Val Loss: 2.2654\n",
            "Epoch: 4/40... Step: 290... Loss: 2.1735... Val Loss: 2.2470\n",
            "Epoch: 4/40... Step: 290... Loss: 2.1366... Val Loss: 2.2286\n",
            "Epoch: 4/40... Step: 290... Loss: 2.0246... Val Loss: 2.1995\n",
            "Epoch: 4/40... Step: 290... Loss: 2.0950... Val Loss: 2.1864\n",
            "Epoch: 4/40... Step: 290... Loss: 2.1556... Val Loss: 2.1830\n",
            "Epoch: 4/40... Step: 290... Loss: 2.1365... Val Loss: 2.1783\n",
            "Epoch: 4/40... Step: 300... Loss: 2.2878... Val Loss: 2.2878\n",
            "Epoch: 4/40... Step: 300... Loss: 2.1052... Val Loss: 2.1965\n",
            "Epoch: 4/40... Step: 300... Loss: 2.2871... Val Loss: 2.2267\n",
            "Epoch: 4/40... Step: 300... Loss: 2.2534... Val Loss: 2.2334\n",
            "Epoch: 4/40... Step: 300... Loss: 2.1413... Val Loss: 2.2150\n",
            "Epoch: 4/40... Step: 300... Loss: 2.1127... Val Loss: 2.1979\n",
            "Epoch: 4/40... Step: 300... Loss: 1.9956... Val Loss: 2.1690\n",
            "Epoch: 4/40... Step: 300... Loss: 2.0562... Val Loss: 2.1549\n",
            "Epoch: 4/40... Step: 300... Loss: 2.1339... Val Loss: 2.1526\n",
            "Epoch: 4/40... Step: 300... Loss: 2.1253... Val Loss: 2.1499\n",
            "Epoch: 4/40... Step: 310... Loss: 2.2682... Val Loss: 2.2682\n",
            "Epoch: 4/40... Step: 310... Loss: 2.1291... Val Loss: 2.1987\n",
            "Epoch: 4/40... Step: 310... Loss: 2.2831... Val Loss: 2.2268\n",
            "Epoch: 4/40... Step: 310... Loss: 2.2500... Val Loss: 2.2326\n",
            "Epoch: 4/40... Step: 310... Loss: 2.1274... Val Loss: 2.2116\n",
            "Epoch: 4/40... Step: 310... Loss: 2.1166... Val Loss: 2.1958\n",
            "Epoch: 4/40... Step: 310... Loss: 1.9775... Val Loss: 2.1646\n",
            "Epoch: 4/40... Step: 310... Loss: 2.0500... Val Loss: 2.1503\n",
            "Epoch: 4/40... Step: 310... Loss: 2.1169... Val Loss: 2.1465\n",
            "Epoch: 4/40... Step: 310... Loss: 2.1246... Val Loss: 2.1444\n",
            "Epoch: 4/40... Step: 320... Loss: 2.2651... Val Loss: 2.2651\n",
            "Epoch: 4/40... Step: 320... Loss: 2.1284... Val Loss: 2.1967\n",
            "Epoch: 4/40... Step: 320... Loss: 2.2533... Val Loss: 2.2156\n",
            "Epoch: 4/40... Step: 320... Loss: 2.2152... Val Loss: 2.2155\n",
            "Epoch: 4/40... Step: 320... Loss: 2.1229... Val Loss: 2.1970\n",
            "Epoch: 4/40... Step: 320... Loss: 2.0990... Val Loss: 2.1807\n",
            "Epoch: 4/40... Step: 320... Loss: 1.9929... Val Loss: 2.1538\n",
            "Epoch: 4/40... Step: 320... Loss: 2.0439... Val Loss: 2.1401\n",
            "Epoch: 4/40... Step: 320... Loss: 2.1060... Val Loss: 2.1363\n",
            "Epoch: 4/40... Step: 320... Loss: 2.0859... Val Loss: 2.1313\n",
            "Epoch: 4/40... Step: 330... Loss: 2.2446... Val Loss: 2.2446\n",
            "Epoch: 4/40... Step: 330... Loss: 2.1127... Val Loss: 2.1786\n",
            "Epoch: 4/40... Step: 330... Loss: 2.2549... Val Loss: 2.2040\n",
            "Epoch: 4/40... Step: 330... Loss: 2.2303... Val Loss: 2.2106\n",
            "Epoch: 4/40... Step: 330... Loss: 2.0970... Val Loss: 2.1879\n",
            "Epoch: 4/40... Step: 330... Loss: 2.0880... Val Loss: 2.1712\n",
            "Epoch: 4/40... Step: 330... Loss: 2.0014... Val Loss: 2.1470\n",
            "Epoch: 4/40... Step: 330... Loss: 2.0431... Val Loss: 2.1340\n",
            "Epoch: 4/40... Step: 330... Loss: 2.1157... Val Loss: 2.1320\n",
            "Epoch: 4/40... Step: 330... Loss: 2.0779... Val Loss: 2.1266\n",
            "Epoch: 4/40... Step: 340... Loss: 2.2407... Val Loss: 2.2407\n",
            "Epoch: 4/40... Step: 340... Loss: 2.0931... Val Loss: 2.1669\n",
            "Epoch: 4/40... Step: 340... Loss: 2.2562... Val Loss: 2.1966\n",
            "Epoch: 4/40... Step: 340... Loss: 2.2151... Val Loss: 2.2013\n",
            "Epoch: 4/40... Step: 340... Loss: 2.1189... Val Loss: 2.1848\n",
            "Epoch: 4/40... Step: 340... Loss: 2.1074... Val Loss: 2.1719\n",
            "Epoch: 4/40... Step: 340... Loss: 1.9879... Val Loss: 2.1456\n",
            "Epoch: 4/40... Step: 340... Loss: 2.0396... Val Loss: 2.1323\n",
            "Epoch: 4/40... Step: 340... Loss: 2.1025... Val Loss: 2.1290\n",
            "Epoch: 4/40... Step: 340... Loss: 2.0788... Val Loss: 2.1240\n",
            "Epoch: 4/40... Step: 350... Loss: 2.2284... Val Loss: 2.2284\n",
            "Epoch: 4/40... Step: 350... Loss: 2.1154... Val Loss: 2.1719\n",
            "Epoch: 4/40... Step: 350... Loss: 2.2592... Val Loss: 2.2010\n",
            "Epoch: 4/40... Step: 350... Loss: 2.2465... Val Loss: 2.2124\n",
            "Epoch: 4/40... Step: 350... Loss: 2.1163... Val Loss: 2.1932\n",
            "Epoch: 4/40... Step: 350... Loss: 2.0895... Val Loss: 2.1759\n",
            "Epoch: 4/40... Step: 350... Loss: 1.9963... Val Loss: 2.1502\n",
            "Epoch: 4/40... Step: 350... Loss: 2.0484... Val Loss: 2.1375\n",
            "Epoch: 4/40... Step: 350... Loss: 2.0991... Val Loss: 2.1332\n",
            "Epoch: 4/40... Step: 350... Loss: 2.0828... Val Loss: 2.1282\n",
            "Epoch: 4/40... Step: 360... Loss: 2.2000... Val Loss: 2.2000\n",
            "Epoch: 4/40... Step: 360... Loss: 2.0746... Val Loss: 2.1373\n",
            "Epoch: 4/40... Step: 360... Loss: 2.2412... Val Loss: 2.1720\n",
            "Epoch: 4/40... Step: 360... Loss: 2.2208... Val Loss: 2.1842\n",
            "Epoch: 4/40... Step: 360... Loss: 2.0881... Val Loss: 2.1650\n",
            "Epoch: 4/40... Step: 360... Loss: 2.0795... Val Loss: 2.1507\n",
            "Epoch: 4/40... Step: 360... Loss: 1.9622... Val Loss: 2.1238\n",
            "Epoch: 4/40... Step: 360... Loss: 2.0141... Val Loss: 2.1101\n",
            "Epoch: 4/40... Step: 360... Loss: 2.0629... Val Loss: 2.1048\n",
            "Epoch: 4/40... Step: 360... Loss: 2.0481... Val Loss: 2.0992\n",
            "Epoch: 5/40... Step: 370... Loss: 2.2008... Val Loss: 2.2008\n",
            "Epoch: 5/40... Step: 370... Loss: 2.0662... Val Loss: 2.1335\n",
            "Epoch: 5/40... Step: 370... Loss: 2.2253... Val Loss: 2.1641\n",
            "Epoch: 5/40... Step: 370... Loss: 2.2045... Val Loss: 2.1742\n",
            "Epoch: 5/40... Step: 370... Loss: 2.0697... Val Loss: 2.1533\n",
            "Epoch: 5/40... Step: 370... Loss: 2.0382... Val Loss: 2.1341\n",
            "Epoch: 5/40... Step: 370... Loss: 1.9357... Val Loss: 2.1058\n",
            "Epoch: 5/40... Step: 370... Loss: 1.9892... Val Loss: 2.0912\n",
            "Epoch: 5/40... Step: 370... Loss: 2.0550... Val Loss: 2.0872\n",
            "Epoch: 5/40... Step: 370... Loss: 2.0251... Val Loss: 2.0810\n",
            "Epoch: 5/40... Step: 380... Loss: 2.1677... Val Loss: 2.1677\n",
            "Epoch: 5/40... Step: 380... Loss: 2.0295... Val Loss: 2.0986\n",
            "Epoch: 5/40... Step: 380... Loss: 2.2076... Val Loss: 2.1350\n",
            "Epoch: 5/40... Step: 380... Loss: 2.1344... Val Loss: 2.1348\n",
            "Epoch: 5/40... Step: 380... Loss: 2.0359... Val Loss: 2.1150\n",
            "Epoch: 5/40... Step: 380... Loss: 1.9939... Val Loss: 2.0948\n",
            "Epoch: 5/40... Step: 380... Loss: 1.8526... Val Loss: 2.0602\n",
            "Epoch: 5/40... Step: 380... Loss: 1.9414... Val Loss: 2.0454\n",
            "Epoch: 5/40... Step: 380... Loss: 2.0142... Val Loss: 2.0419\n",
            "Epoch: 5/40... Step: 380... Loss: 1.9971... Val Loss: 2.0374\n",
            "Epoch: 5/40... Step: 390... Loss: 2.1389... Val Loss: 2.1389\n",
            "Epoch: 5/40... Step: 390... Loss: 1.9965... Val Loss: 2.0677\n",
            "Epoch: 5/40... Step: 390... Loss: 2.1886... Val Loss: 2.1080\n",
            "Epoch: 5/40... Step: 390... Loss: 2.1150... Val Loss: 2.1097\n",
            "Epoch: 5/40... Step: 390... Loss: 2.0011... Val Loss: 2.0880\n",
            "Epoch: 5/40... Step: 390... Loss: 1.9749... Val Loss: 2.0692\n",
            "Epoch: 5/40... Step: 390... Loss: 1.8394... Val Loss: 2.0363\n",
            "Epoch: 5/40... Step: 390... Loss: 1.9291... Val Loss: 2.0229\n",
            "Epoch: 5/40... Step: 390... Loss: 1.9969... Val Loss: 2.0200\n",
            "Epoch: 5/40... Step: 390... Loss: 1.9698... Val Loss: 2.0150\n",
            "Epoch: 5/40... Step: 400... Loss: 2.1153... Val Loss: 2.1153\n",
            "Epoch: 5/40... Step: 400... Loss: 1.9711... Val Loss: 2.0432\n",
            "Epoch: 5/40... Step: 400... Loss: 2.1605... Val Loss: 2.0823\n",
            "Epoch: 5/40... Step: 400... Loss: 2.1078... Val Loss: 2.0887\n",
            "Epoch: 5/40... Step: 400... Loss: 1.9943... Val Loss: 2.0698\n",
            "Epoch: 5/40... Step: 400... Loss: 1.9369... Val Loss: 2.0477\n",
            "Epoch: 5/40... Step: 400... Loss: 1.8050... Val Loss: 2.0130\n",
            "Epoch: 5/40... Step: 400... Loss: 1.9126... Val Loss: 2.0004\n",
            "Epoch: 5/40... Step: 400... Loss: 1.9746... Val Loss: 1.9976\n",
            "Epoch: 5/40... Step: 400... Loss: 1.9696... Val Loss: 1.9948\n",
            "Epoch: 5/40... Step: 410... Loss: 2.1273... Val Loss: 2.1273\n",
            "Epoch: 5/40... Step: 410... Loss: 2.0151... Val Loss: 2.0712\n",
            "Epoch: 5/40... Step: 410... Loss: 2.1734... Val Loss: 2.1053\n",
            "Epoch: 5/40... Step: 410... Loss: 2.1434... Val Loss: 2.1148\n",
            "Epoch: 5/40... Step: 410... Loss: 2.0041... Val Loss: 2.0927\n",
            "Epoch: 5/40... Step: 410... Loss: 1.9648... Val Loss: 2.0713\n",
            "Epoch: 5/40... Step: 410... Loss: 1.8384... Val Loss: 2.0381\n",
            "Epoch: 5/40... Step: 410... Loss: 1.9327... Val Loss: 2.0249\n",
            "Epoch: 5/40... Step: 410... Loss: 1.9756... Val Loss: 2.0194\n",
            "Epoch: 5/40... Step: 410... Loss: 1.9658... Val Loss: 2.0141\n",
            "Epoch: 5/40... Step: 420... Loss: 2.1176... Val Loss: 2.1176\n",
            "Epoch: 5/40... Step: 420... Loss: 1.9993... Val Loss: 2.0585\n",
            "Epoch: 5/40... Step: 420... Loss: 2.1893... Val Loss: 2.1021\n",
            "Epoch: 5/40... Step: 420... Loss: 2.1268... Val Loss: 2.1083\n",
            "Epoch: 5/40... Step: 420... Loss: 1.9985... Val Loss: 2.0863\n",
            "Epoch: 5/40... Step: 420... Loss: 1.9916... Val Loss: 2.0705\n",
            "Epoch: 5/40... Step: 420... Loss: 1.8554... Val Loss: 2.0398\n",
            "Epoch: 5/40... Step: 420... Loss: 1.9475... Val Loss: 2.0283\n",
            "Epoch: 5/40... Step: 420... Loss: 2.0025... Val Loss: 2.0254\n",
            "Epoch: 5/40... Step: 420... Loss: 1.9622... Val Loss: 2.0191\n",
            "Epoch: 5/40... Step: 430... Loss: 2.1094... Val Loss: 2.1094\n",
            "Epoch: 5/40... Step: 430... Loss: 1.9764... Val Loss: 2.0429\n",
            "Epoch: 5/40... Step: 430... Loss: 2.1716... Val Loss: 2.0858\n",
            "Epoch: 5/40... Step: 430... Loss: 2.1440... Val Loss: 2.1003\n",
            "Epoch: 5/40... Step: 430... Loss: 1.9984... Val Loss: 2.0800\n",
            "Epoch: 5/40... Step: 430... Loss: 1.9851... Val Loss: 2.0641\n",
            "Epoch: 5/40... Step: 430... Loss: 1.8513... Val Loss: 2.0337\n",
            "Epoch: 5/40... Step: 430... Loss: 1.9285... Val Loss: 2.0206\n",
            "Epoch: 5/40... Step: 430... Loss: 1.9672... Val Loss: 2.0146\n",
            "Epoch: 5/40... Step: 430... Loss: 1.9718... Val Loss: 2.0104\n",
            "Epoch: 5/40... Step: 440... Loss: 2.1064... Val Loss: 2.1064\n",
            "Epoch: 5/40... Step: 440... Loss: 2.0069... Val Loss: 2.0567\n",
            "Epoch: 5/40... Step: 440... Loss: 2.1646... Val Loss: 2.0926\n",
            "Epoch: 5/40... Step: 440... Loss: 2.1531... Val Loss: 2.1077\n",
            "Epoch: 5/40... Step: 440... Loss: 2.0270... Val Loss: 2.0916\n",
            "Epoch: 5/40... Step: 440... Loss: 1.9797... Val Loss: 2.0729\n",
            "Epoch: 5/40... Step: 440... Loss: 1.8634... Val Loss: 2.0430\n",
            "Epoch: 5/40... Step: 440... Loss: 1.9419... Val Loss: 2.0304\n",
            "Epoch: 5/40... Step: 440... Loss: 1.9834... Val Loss: 2.0252\n",
            "Epoch: 5/40... Step: 440... Loss: 1.9598... Val Loss: 2.0186\n",
            "Epoch: 5/40... Step: 450... Loss: 2.0809... Val Loss: 2.0809\n",
            "Epoch: 5/40... Step: 450... Loss: 1.9661... Val Loss: 2.0235\n",
            "Epoch: 5/40... Step: 450... Loss: 2.1442... Val Loss: 2.0638\n",
            "Epoch: 5/40... Step: 450... Loss: 2.1067... Val Loss: 2.0745\n",
            "Epoch: 5/40... Step: 450... Loss: 1.9897... Val Loss: 2.0575\n",
            "Epoch: 5/40... Step: 450... Loss: 1.9448... Val Loss: 2.0387\n",
            "Epoch: 5/40... Step: 450... Loss: 1.8142... Val Loss: 2.0067\n",
            "Epoch: 5/40... Step: 450... Loss: 1.9012... Val Loss: 1.9935\n",
            "Epoch: 5/40... Step: 450... Loss: 1.9551... Val Loss: 1.9892\n",
            "Epoch: 5/40... Step: 450... Loss: 1.9190... Val Loss: 1.9822\n",
            "Epoch: 5/40... Step: 460... Loss: 2.1107... Val Loss: 2.1107\n",
            "Epoch: 5/40... Step: 460... Loss: 1.9988... Val Loss: 2.0547\n",
            "Epoch: 5/40... Step: 460... Loss: 2.1559... Val Loss: 2.0885\n",
            "Epoch: 5/40... Step: 460... Loss: 2.1406... Val Loss: 2.1015\n",
            "Epoch: 5/40... Step: 460... Loss: 2.0087... Val Loss: 2.0829\n",
            "Epoch: 5/40... Step: 460... Loss: 1.9440... Val Loss: 2.0598\n",
            "Epoch: 5/40... Step: 460... Loss: 1.8108... Val Loss: 2.0242\n",
            "Epoch: 5/40... Step: 460... Loss: 1.9000... Val Loss: 2.0087\n",
            "Epoch: 5/40... Step: 460... Loss: 1.9657... Val Loss: 2.0039\n",
            "Epoch: 5/40... Step: 460... Loss: 1.9200... Val Loss: 1.9955\n",
            "Epoch: 6/40... Step: 470... Loss: 2.0428... Val Loss: 2.0428\n",
            "Epoch: 6/40... Step: 470... Loss: 1.9359... Val Loss: 1.9893\n",
            "Epoch: 6/40... Step: 470... Loss: 2.1343... Val Loss: 2.0376\n",
            "Epoch: 6/40... Step: 470... Loss: 2.0938... Val Loss: 2.0517\n",
            "Epoch: 6/40... Step: 470... Loss: 1.9456... Val Loss: 2.0305\n",
            "Epoch: 6/40... Step: 470... Loss: 1.8911... Val Loss: 2.0072\n",
            "Epoch: 6/40... Step: 470... Loss: 1.7628... Val Loss: 1.9723\n",
            "Epoch: 6/40... Step: 470... Loss: 1.8760... Val Loss: 1.9603\n",
            "Epoch: 6/40... Step: 470... Loss: 1.9021... Val Loss: 1.9538\n",
            "Epoch: 6/40... Step: 470... Loss: 1.9118... Val Loss: 1.9496\n",
            "Epoch: 6/40... Step: 480... Loss: 2.0121... Val Loss: 2.0121\n",
            "Epoch: 6/40... Step: 480... Loss: 1.8874... Val Loss: 1.9497\n",
            "Epoch: 6/40... Step: 480... Loss: 2.1028... Val Loss: 2.0008\n",
            "Epoch: 6/40... Step: 480... Loss: 2.0498... Val Loss: 2.0130\n",
            "Epoch: 6/40... Step: 480... Loss: 1.9137... Val Loss: 1.9932\n",
            "Epoch: 6/40... Step: 480... Loss: 1.8878... Val Loss: 1.9756\n",
            "Epoch: 6/40... Step: 480... Loss: 1.7321... Val Loss: 1.9408\n",
            "Epoch: 6/40... Step: 480... Loss: 1.8421... Val Loss: 1.9285\n",
            "Epoch: 6/40... Step: 480... Loss: 1.8928... Val Loss: 1.9245\n",
            "Epoch: 6/40... Step: 480... Loss: 1.8887... Val Loss: 1.9209\n",
            "Epoch: 6/40... Step: 490... Loss: 2.0150... Val Loss: 2.0150\n",
            "Epoch: 6/40... Step: 490... Loss: 1.8923... Val Loss: 1.9536\n",
            "Epoch: 6/40... Step: 490... Loss: 2.1029... Val Loss: 2.0034\n",
            "Epoch: 6/40... Step: 490... Loss: 2.0509... Val Loss: 2.0153\n",
            "Epoch: 6/40... Step: 490... Loss: 1.8802... Val Loss: 1.9883\n",
            "Epoch: 6/40... Step: 490... Loss: 1.8433... Val Loss: 1.9641\n",
            "Epoch: 6/40... Step: 490... Loss: 1.6891... Val Loss: 1.9248\n",
            "Epoch: 6/40... Step: 490... Loss: 1.8181... Val Loss: 1.9115\n",
            "Epoch: 6/40... Step: 490... Loss: 1.8648... Val Loss: 1.9063\n",
            "Epoch: 6/40... Step: 490... Loss: 1.8816... Val Loss: 1.9038\n",
            "Epoch: 6/40... Step: 500... Loss: 2.0249... Val Loss: 2.0249\n",
            "Epoch: 6/40... Step: 500... Loss: 1.9110... Val Loss: 1.9680\n",
            "Epoch: 6/40... Step: 500... Loss: 2.0857... Val Loss: 2.0072\n",
            "Epoch: 6/40... Step: 500... Loss: 2.0761... Val Loss: 2.0244\n",
            "Epoch: 6/40... Step: 500... Loss: 1.9177... Val Loss: 2.0031\n",
            "Epoch: 6/40... Step: 500... Loss: 1.8791... Val Loss: 1.9824\n",
            "Epoch: 6/40... Step: 500... Loss: 1.7326... Val Loss: 1.9467\n",
            "Epoch: 6/40... Step: 500... Loss: 1.8621... Val Loss: 1.9362\n",
            "Epoch: 6/40... Step: 500... Loss: 1.8633... Val Loss: 1.9281\n",
            "Epoch: 6/40... Step: 500... Loss: 1.8824... Val Loss: 1.9235\n",
            "Epoch: 6/40... Step: 510... Loss: 2.0217... Val Loss: 2.0217\n",
            "Epoch: 6/40... Step: 510... Loss: 1.9140... Val Loss: 1.9679\n",
            "Epoch: 6/40... Step: 510... Loss: 2.0833... Val Loss: 2.0063\n",
            "Epoch: 6/40... Step: 510... Loss: 2.0643... Val Loss: 2.0208\n",
            "Epoch: 6/40... Step: 510... Loss: 1.9167... Val Loss: 2.0000\n",
            "Epoch: 6/40... Step: 510... Loss: 1.8852... Val Loss: 1.9809\n",
            "Epoch: 6/40... Step: 510... Loss: 1.7506... Val Loss: 1.9480\n",
            "Epoch: 6/40... Step: 510... Loss: 1.8631... Val Loss: 1.9374\n",
            "Epoch: 6/40... Step: 510... Loss: 1.8737... Val Loss: 1.9303\n",
            "Epoch: 6/40... Step: 510... Loss: 1.8669... Val Loss: 1.9240\n",
            "Epoch: 6/40... Step: 520... Loss: 2.0047... Val Loss: 2.0047\n",
            "Epoch: 6/40... Step: 520... Loss: 1.9107... Val Loss: 1.9577\n",
            "Epoch: 6/40... Step: 520... Loss: 2.0889... Val Loss: 2.0014\n",
            "Epoch: 6/40... Step: 520... Loss: 2.0632... Val Loss: 2.0169\n",
            "Epoch: 6/40... Step: 520... Loss: 1.9017... Val Loss: 1.9938\n",
            "Epoch: 6/40... Step: 520... Loss: 1.9165... Val Loss: 1.9810\n",
            "Epoch: 6/40... Step: 520... Loss: 1.7627... Val Loss: 1.9498\n",
            "Epoch: 6/40... Step: 520... Loss: 1.8455... Val Loss: 1.9367\n",
            "Epoch: 6/40... Step: 520... Loss: 1.8774... Val Loss: 1.9301\n",
            "Epoch: 6/40... Step: 520... Loss: 1.8683... Val Loss: 1.9240\n",
            "Epoch: 6/40... Step: 530... Loss: 2.0175... Val Loss: 2.0175\n",
            "Epoch: 6/40... Step: 530... Loss: 1.9120... Val Loss: 1.9647\n",
            "Epoch: 6/40... Step: 530... Loss: 2.0976... Val Loss: 2.0090\n",
            "Epoch: 6/40... Step: 530... Loss: 2.0823... Val Loss: 2.0274\n",
            "Epoch: 6/40... Step: 530... Loss: 1.9255... Val Loss: 2.0070\n",
            "Epoch: 6/40... Step: 530... Loss: 1.9081... Val Loss: 1.9905\n",
            "Epoch: 6/40... Step: 530... Loss: 1.7879... Val Loss: 1.9616\n",
            "Epoch: 6/40... Step: 530... Loss: 1.8534... Val Loss: 1.9481\n",
            "Epoch: 6/40... Step: 530... Loss: 1.8794... Val Loss: 1.9404\n",
            "Epoch: 6/40... Step: 530... Loss: 1.8794... Val Loss: 1.9343\n",
            "Epoch: 6/40... Step: 540... Loss: 1.9999... Val Loss: 1.9999\n",
            "Epoch: 6/40... Step: 540... Loss: 1.8985... Val Loss: 1.9492\n",
            "Epoch: 6/40... Step: 540... Loss: 2.0764... Val Loss: 1.9916\n",
            "Epoch: 6/40... Step: 540... Loss: 2.0521... Val Loss: 2.0067\n",
            "Epoch: 6/40... Step: 540... Loss: 1.9087... Val Loss: 1.9871\n",
            "Epoch: 6/40... Step: 540... Loss: 1.8635... Val Loss: 1.9665\n",
            "Epoch: 6/40... Step: 540... Loss: 1.7469... Val Loss: 1.9352\n",
            "Epoch: 6/40... Step: 540... Loss: 1.8314... Val Loss: 1.9222\n",
            "Epoch: 6/40... Step: 540... Loss: 1.8561... Val Loss: 1.9148\n",
            "Epoch: 6/40... Step: 540... Loss: 1.8480... Val Loss: 1.9082\n",
            "Epoch: 6/40... Step: 550... Loss: 1.9900... Val Loss: 1.9900\n",
            "Epoch: 6/40... Step: 550... Loss: 1.8852... Val Loss: 1.9376\n",
            "Epoch: 6/40... Step: 550... Loss: 2.0805... Val Loss: 1.9852\n",
            "Epoch: 6/40... Step: 550... Loss: 2.0488... Val Loss: 2.0011\n",
            "Epoch: 6/40... Step: 550... Loss: 1.8904... Val Loss: 1.9790\n",
            "Epoch: 6/40... Step: 550... Loss: 1.8506... Val Loss: 1.9576\n",
            "Epoch: 6/40... Step: 550... Loss: 1.7032... Val Loss: 1.9212\n",
            "Epoch: 6/40... Step: 550... Loss: 1.8240... Val Loss: 1.9091\n",
            "Epoch: 6/40... Step: 550... Loss: 1.8601... Val Loss: 1.9036\n",
            "Epoch: 6/40... Step: 550... Loss: 1.8284... Val Loss: 1.8961\n",
            "Epoch: 7/40... Step: 560... Loss: 1.9698... Val Loss: 1.9698\n",
            "Epoch: 7/40... Step: 560... Loss: 1.8718... Val Loss: 1.9208\n",
            "Epoch: 7/40... Step: 560... Loss: 2.0761... Val Loss: 1.9726\n",
            "Epoch: 7/40... Step: 560... Loss: 2.0589... Val Loss: 1.9942\n",
            "Epoch: 7/40... Step: 560... Loss: 1.8815... Val Loss: 1.9716\n",
            "Epoch: 7/40... Step: 560... Loss: 1.8179... Val Loss: 1.9460\n",
            "Epoch: 7/40... Step: 560... Loss: 1.7012... Val Loss: 1.9111\n",
            "Epoch: 7/40... Step: 560... Loss: 1.8069... Val Loss: 1.8980\n",
            "Epoch: 7/40... Step: 560... Loss: 1.8357... Val Loss: 1.8911\n",
            "Epoch: 7/40... Step: 560... Loss: 1.8367... Val Loss: 1.8857\n",
            "Epoch: 7/40... Step: 570... Loss: 1.9436... Val Loss: 1.9436\n",
            "Epoch: 7/40... Step: 570... Loss: 1.8310... Val Loss: 1.8873\n",
            "Epoch: 7/40... Step: 570... Loss: 2.0383... Val Loss: 1.9376\n",
            "Epoch: 7/40... Step: 570... Loss: 2.0161... Val Loss: 1.9573\n",
            "Epoch: 7/40... Step: 570... Loss: 1.8639... Val Loss: 1.9386\n",
            "Epoch: 7/40... Step: 570... Loss: 1.8143... Val Loss: 1.9179\n",
            "Epoch: 7/40... Step: 570... Loss: 1.6540... Val Loss: 1.8802\n",
            "Epoch: 7/40... Step: 570... Loss: 1.7627... Val Loss: 1.8655\n",
            "Epoch: 7/40... Step: 570... Loss: 1.8023... Val Loss: 1.8585\n",
            "Epoch: 7/40... Step: 570... Loss: 1.8266... Val Loss: 1.8553\n",
            "Epoch: 7/40... Step: 580... Loss: 1.9249... Val Loss: 1.9249\n",
            "Epoch: 7/40... Step: 580... Loss: 1.8122... Val Loss: 1.8686\n",
            "Epoch: 7/40... Step: 580... Loss: 2.0734... Val Loss: 1.9368\n",
            "Epoch: 7/40... Step: 580... Loss: 1.9903... Val Loss: 1.9502\n",
            "Epoch: 7/40... Step: 580... Loss: 1.8071... Val Loss: 1.9216\n",
            "Epoch: 7/40... Step: 580... Loss: 1.7816... Val Loss: 1.8983\n",
            "Epoch: 7/40... Step: 580... Loss: 1.6120... Val Loss: 1.8574\n",
            "Epoch: 7/40... Step: 580... Loss: 1.7525... Val Loss: 1.8443\n",
            "Epoch: 7/40... Step: 580... Loss: 1.7829... Val Loss: 1.8374\n",
            "Epoch: 7/40... Step: 580... Loss: 1.8101... Val Loss: 1.8347\n",
            "Epoch: 7/40... Step: 590... Loss: 1.9245... Val Loss: 1.9245\n",
            "Epoch: 7/40... Step: 590... Loss: 1.8494... Val Loss: 1.8869\n",
            "Epoch: 7/40... Step: 590... Loss: 2.0255... Val Loss: 1.9331\n",
            "Epoch: 7/40... Step: 590... Loss: 2.0171... Val Loss: 1.9541\n",
            "Epoch: 7/40... Step: 590... Loss: 1.8507... Val Loss: 1.9334\n",
            "Epoch: 7/40... Step: 590... Loss: 1.8041... Val Loss: 1.9119\n",
            "Epoch: 7/40... Step: 590... Loss: 1.6459... Val Loss: 1.8739\n",
            "Epoch: 7/40... Step: 590... Loss: 1.7820... Val Loss: 1.8624\n",
            "Epoch: 7/40... Step: 590... Loss: 1.7999... Val Loss: 1.8554\n",
            "Epoch: 7/40... Step: 590... Loss: 1.8088... Val Loss: 1.8508\n",
            "Epoch: 7/40... Step: 600... Loss: 1.9375... Val Loss: 1.9375\n",
            "Epoch: 7/40... Step: 600... Loss: 1.8302... Val Loss: 1.8839\n",
            "Epoch: 7/40... Step: 600... Loss: 2.0234... Val Loss: 1.9304\n",
            "Epoch: 7/40... Step: 600... Loss: 1.9875... Val Loss: 1.9447\n",
            "Epoch: 7/40... Step: 600... Loss: 1.8396... Val Loss: 1.9237\n",
            "Epoch: 7/40... Step: 600... Loss: 1.7902... Val Loss: 1.9014\n",
            "Epoch: 7/40... Step: 600... Loss: 1.6549... Val Loss: 1.8662\n",
            "Epoch: 7/40... Step: 600... Loss: 1.7895... Val Loss: 1.8566\n",
            "Epoch: 7/40... Step: 600... Loss: 1.7851... Val Loss: 1.8487\n",
            "Epoch: 7/40... Step: 600... Loss: 1.7948... Val Loss: 1.8433\n",
            "Epoch: 7/40... Step: 610... Loss: 1.9321... Val Loss: 1.9321\n",
            "Epoch: 7/40... Step: 610... Loss: 1.8383... Val Loss: 1.8852\n",
            "Epoch: 7/40... Step: 610... Loss: 2.0273... Val Loss: 1.9326\n",
            "Epoch: 7/40... Step: 610... Loss: 2.0289... Val Loss: 1.9567\n",
            "Epoch: 7/40... Step: 610... Loss: 1.8329... Val Loss: 1.9319\n",
            "Epoch: 7/40... Step: 610... Loss: 1.8261... Val Loss: 1.9143\n",
            "Epoch: 7/40... Step: 610... Loss: 1.6817... Val Loss: 1.8811\n",
            "Epoch: 7/40... Step: 610... Loss: 1.7788... Val Loss: 1.8683\n",
            "Epoch: 7/40... Step: 610... Loss: 1.7950... Val Loss: 1.8601\n",
            "Epoch: 7/40... Step: 610... Loss: 1.8067... Val Loss: 1.8548\n",
            "Epoch: 7/40... Step: 620... Loss: 1.9333... Val Loss: 1.9333\n",
            "Epoch: 7/40... Step: 620... Loss: 1.8475... Val Loss: 1.8904\n",
            "Epoch: 7/40... Step: 620... Loss: 2.0328... Val Loss: 1.9379\n",
            "Epoch: 7/40... Step: 620... Loss: 2.0219... Val Loss: 1.9589\n",
            "Epoch: 7/40... Step: 620... Loss: 1.8750... Val Loss: 1.9421\n",
            "Epoch: 7/40... Step: 620... Loss: 1.8224... Val Loss: 1.9222\n",
            "Epoch: 7/40... Step: 620... Loss: 1.6810... Val Loss: 1.8877\n",
            "Epoch: 7/40... Step: 620... Loss: 1.7698... Val Loss: 1.8730\n",
            "Epoch: 7/40... Step: 620... Loss: 1.7982... Val Loss: 1.8647\n",
            "Epoch: 7/40... Step: 620... Loss: 1.7990... Val Loss: 1.8581\n",
            "Epoch: 7/40... Step: 630... Loss: 1.9183... Val Loss: 1.9183\n",
            "Epoch: 7/40... Step: 630... Loss: 1.8360... Val Loss: 1.8771\n",
            "Epoch: 7/40... Step: 630... Loss: 1.9935... Val Loss: 1.9159\n",
            "Epoch: 7/40... Step: 630... Loss: 2.0000... Val Loss: 1.9369\n",
            "Epoch: 7/40... Step: 630... Loss: 1.8512... Val Loss: 1.9198\n",
            "Epoch: 7/40... Step: 630... Loss: 1.8008... Val Loss: 1.9000\n",
            "Epoch: 7/40... Step: 630... Loss: 1.6682... Val Loss: 1.8668\n",
            "Epoch: 7/40... Step: 630... Loss: 1.7449... Val Loss: 1.8516\n",
            "Epoch: 7/40... Step: 630... Loss: 1.7955... Val Loss: 1.8454\n",
            "Epoch: 7/40... Step: 630... Loss: 1.7899... Val Loss: 1.8398\n",
            "Epoch: 7/40... Step: 640... Loss: 1.9078... Val Loss: 1.9078\n",
            "Epoch: 7/40... Step: 640... Loss: 1.8174... Val Loss: 1.8626\n",
            "Epoch: 7/40... Step: 640... Loss: 2.0230... Val Loss: 1.9161\n",
            "Epoch: 7/40... Step: 640... Loss: 1.9900... Val Loss: 1.9345\n",
            "Epoch: 7/40... Step: 640... Loss: 1.8250... Val Loss: 1.9126\n",
            "Epoch: 7/40... Step: 640... Loss: 1.7817... Val Loss: 1.8908\n",
            "Epoch: 7/40... Step: 640... Loss: 1.6487... Val Loss: 1.8562\n",
            "Epoch: 7/40... Step: 640... Loss: 1.7795... Val Loss: 1.8466\n",
            "Epoch: 7/40... Step: 640... Loss: 1.7897... Val Loss: 1.8403\n",
            "Epoch: 7/40... Step: 640... Loss: 1.7750... Val Loss: 1.8338\n",
            "Epoch: 8/40... Step: 650... Loss: 1.8928... Val Loss: 1.8928\n",
            "Epoch: 8/40... Step: 650... Loss: 1.7974... Val Loss: 1.8451\n",
            "Epoch: 8/40... Step: 650... Loss: 2.0138... Val Loss: 1.9014\n",
            "Epoch: 8/40... Step: 650... Loss: 1.9940... Val Loss: 1.9245\n",
            "Epoch: 8/40... Step: 650... Loss: 1.8118... Val Loss: 1.9020\n",
            "Epoch: 8/40... Step: 650... Loss: 1.7417... Val Loss: 1.8753\n",
            "Epoch: 8/40... Step: 650... Loss: 1.6207... Val Loss: 1.8389\n",
            "Epoch: 8/40... Step: 650... Loss: 1.7543... Val Loss: 1.8283\n",
            "Epoch: 8/40... Step: 650... Loss: 1.7603... Val Loss: 1.8207\n",
            "Epoch: 8/40... Step: 650... Loss: 1.7418... Val Loss: 1.8129\n",
            "Epoch: 8/40... Step: 660... Loss: 1.8750... Val Loss: 1.8750\n",
            "Epoch: 8/40... Step: 660... Loss: 1.7796... Val Loss: 1.8273\n",
            "Epoch: 8/40... Step: 660... Loss: 1.9914... Val Loss: 1.8820\n",
            "Epoch: 8/40... Step: 660... Loss: 1.9449... Val Loss: 1.8977\n",
            "Epoch: 8/40... Step: 660... Loss: 1.8048... Val Loss: 1.8792\n",
            "Epoch: 8/40... Step: 660... Loss: 1.7297... Val Loss: 1.8543\n",
            "Epoch: 8/40... Step: 660... Loss: 1.5669... Val Loss: 1.8132\n",
            "Epoch: 8/40... Step: 660... Loss: 1.7021... Val Loss: 1.7993\n",
            "Epoch: 8/40... Step: 660... Loss: 1.7301... Val Loss: 1.7916\n",
            "Epoch: 8/40... Step: 660... Loss: 1.7626... Val Loss: 1.7887\n",
            "Epoch: 8/40... Step: 670... Loss: 1.8581... Val Loss: 1.8581\n",
            "Epoch: 8/40... Step: 670... Loss: 1.7601... Val Loss: 1.8091\n",
            "Epoch: 8/40... Step: 670... Loss: 1.9952... Val Loss: 1.8711\n",
            "Epoch: 8/40... Step: 670... Loss: 1.9392... Val Loss: 1.8881\n",
            "Epoch: 8/40... Step: 670... Loss: 1.7736... Val Loss: 1.8652\n",
            "Epoch: 8/40... Step: 670... Loss: 1.7048... Val Loss: 1.8385\n",
            "Epoch: 8/40... Step: 670... Loss: 1.5692... Val Loss: 1.8000\n",
            "Epoch: 8/40... Step: 670... Loss: 1.6917... Val Loss: 1.7865\n",
            "Epoch: 8/40... Step: 670... Loss: 1.7159... Val Loss: 1.7786\n",
            "Epoch: 8/40... Step: 670... Loss: 1.7577... Val Loss: 1.7765\n",
            "Epoch: 8/40... Step: 680... Loss: 1.8499... Val Loss: 1.8499\n",
            "Epoch: 8/40... Step: 680... Loss: 1.7743... Val Loss: 1.8121\n",
            "Epoch: 8/40... Step: 680... Loss: 1.9838... Val Loss: 1.8693\n",
            "Epoch: 8/40... Step: 680... Loss: 1.9420... Val Loss: 1.8875\n",
            "Epoch: 8/40... Step: 680... Loss: 1.7952... Val Loss: 1.8690\n",
            "Epoch: 8/40... Step: 680... Loss: 1.7491... Val Loss: 1.8490\n",
            "Epoch: 8/40... Step: 680... Loss: 1.6007... Val Loss: 1.8136\n",
            "Epoch: 8/40... Step: 680... Loss: 1.7126... Val Loss: 1.8009\n",
            "Epoch: 8/40... Step: 680... Loss: 1.7356... Val Loss: 1.7937\n",
            "Epoch: 8/40... Step: 680... Loss: 1.7545... Val Loss: 1.7898\n",
            "Epoch: 8/40... Step: 690... Loss: 1.8721... Val Loss: 1.8721\n",
            "Epoch: 8/40... Step: 690... Loss: 1.7827... Val Loss: 1.8274\n",
            "Epoch: 8/40... Step: 690... Loss: 1.9702... Val Loss: 1.8750\n",
            "Epoch: 8/40... Step: 690... Loss: 1.9668... Val Loss: 1.8979\n",
            "Epoch: 8/40... Step: 690... Loss: 1.7708... Val Loss: 1.8725\n",
            "Epoch: 8/40... Step: 690... Loss: 1.7272... Val Loss: 1.8483\n",
            "Epoch: 8/40... Step: 690... Loss: 1.6063... Val Loss: 1.8137\n",
            "Epoch: 8/40... Step: 690... Loss: 1.7263... Val Loss: 1.8028\n",
            "Epoch: 8/40... Step: 690... Loss: 1.7399... Val Loss: 1.7958\n",
            "Epoch: 8/40... Step: 690... Loss: 1.7386... Val Loss: 1.7901\n",
            "Epoch: 8/40... Step: 700... Loss: 1.8779... Val Loss: 1.8779\n",
            "Epoch: 8/40... Step: 700... Loss: 1.7771... Val Loss: 1.8275\n",
            "Epoch: 8/40... Step: 700... Loss: 1.9691... Val Loss: 1.8747\n",
            "Epoch: 8/40... Step: 700... Loss: 1.9767... Val Loss: 1.9002\n",
            "Epoch: 8/40... Step: 700... Loss: 1.7831... Val Loss: 1.8768\n",
            "Epoch: 8/40... Step: 700... Loss: 1.7706... Val Loss: 1.8591\n",
            "Epoch: 8/40... Step: 700... Loss: 1.6225... Val Loss: 1.8253\n",
            "Epoch: 8/40... Step: 700... Loss: 1.7415... Val Loss: 1.8148\n",
            "Epoch: 8/40... Step: 700... Loss: 1.7512... Val Loss: 1.8077\n",
            "Epoch: 8/40... Step: 700... Loss: 1.7550... Val Loss: 1.8025\n",
            "Epoch: 8/40... Step: 710... Loss: 1.8708... Val Loss: 1.8708\n",
            "Epoch: 8/40... Step: 710... Loss: 1.8054... Val Loss: 1.8381\n",
            "Epoch: 8/40... Step: 710... Loss: 1.9837... Val Loss: 1.8867\n",
            "Epoch: 8/40... Step: 710... Loss: 1.9636... Val Loss: 1.9059\n",
            "Epoch: 8/40... Step: 710... Loss: 1.7895... Val Loss: 1.8826\n",
            "Epoch: 8/40... Step: 710... Loss: 1.7810... Val Loss: 1.8657\n",
            "Epoch: 8/40... Step: 710... Loss: 1.6292... Val Loss: 1.8319\n",
            "Epoch: 8/40... Step: 710... Loss: 1.7398... Val Loss: 1.8204\n",
            "Epoch: 8/40... Step: 710... Loss: 1.7372... Val Loss: 1.8111\n",
            "Epoch: 8/40... Step: 710... Loss: 1.7413... Val Loss: 1.8042\n",
            "Epoch: 8/40... Step: 720... Loss: 1.8629... Val Loss: 1.8629\n",
            "Epoch: 8/40... Step: 720... Loss: 1.7964... Val Loss: 1.8297\n",
            "Epoch: 8/40... Step: 720... Loss: 1.9742... Val Loss: 1.8779\n",
            "Epoch: 8/40... Step: 720... Loss: 1.9631... Val Loss: 1.8992\n",
            "Epoch: 8/40... Step: 720... Loss: 1.8196... Val Loss: 1.8833\n",
            "Epoch: 8/40... Step: 720... Loss: 1.7556... Val Loss: 1.8620\n",
            "Epoch: 8/40... Step: 720... Loss: 1.6356... Val Loss: 1.8296\n",
            "Epoch: 8/40... Step: 720... Loss: 1.7271... Val Loss: 1.8168\n",
            "Epoch: 8/40... Step: 720... Loss: 1.7521... Val Loss: 1.8096\n",
            "Epoch: 8/40... Step: 720... Loss: 1.7587... Val Loss: 1.8045\n",
            "Epoch: 8/40... Step: 730... Loss: 1.8511... Val Loss: 1.8511\n",
            "Epoch: 8/40... Step: 730... Loss: 1.7704... Val Loss: 1.8107\n",
            "Epoch: 8/40... Step: 730... Loss: 1.9768... Val Loss: 1.8661\n",
            "Epoch: 8/40... Step: 730... Loss: 1.9706... Val Loss: 1.8922\n",
            "Epoch: 8/40... Step: 730... Loss: 1.7693... Val Loss: 1.8677\n",
            "Epoch: 8/40... Step: 730... Loss: 1.7399... Val Loss: 1.8464\n",
            "Epoch: 8/40... Step: 730... Loss: 1.5939... Val Loss: 1.8103\n",
            "Epoch: 8/40... Step: 730... Loss: 1.7152... Val Loss: 1.7984\n",
            "Epoch: 8/40... Step: 730... Loss: 1.7302... Val Loss: 1.7908\n",
            "Epoch: 8/40... Step: 730... Loss: 1.7349... Val Loss: 1.7852\n",
            "Epoch: 9/40... Step: 740... Loss: 1.8419... Val Loss: 1.8419\n",
            "Epoch: 9/40... Step: 740... Loss: 1.7625... Val Loss: 1.8022\n",
            "Epoch: 9/40... Step: 740... Loss: 1.9677... Val Loss: 1.8573\n",
            "Epoch: 9/40... Step: 740... Loss: 1.9586... Val Loss: 1.8827\n",
            "Epoch: 9/40... Step: 740... Loss: 1.7685... Val Loss: 1.8598\n",
            "Epoch: 9/40... Step: 740... Loss: 1.7162... Val Loss: 1.8359\n",
            "Epoch: 9/40... Step: 740... Loss: 1.6027... Val Loss: 1.8026\n",
            "Epoch: 9/40... Step: 740... Loss: 1.6966... Val Loss: 1.7893\n",
            "Epoch: 9/40... Step: 740... Loss: 1.7169... Val Loss: 1.7813\n",
            "Epoch: 9/40... Step: 740... Loss: 1.7390... Val Loss: 1.7771\n",
            "Epoch: 9/40... Step: 750... Loss: 1.8233... Val Loss: 1.8233\n",
            "Epoch: 9/40... Step: 750... Loss: 1.7356... Val Loss: 1.7794\n",
            "Epoch: 9/40... Step: 750... Loss: 1.9772... Val Loss: 1.8453\n",
            "Epoch: 9/40... Step: 750... Loss: 1.9154... Val Loss: 1.8629\n",
            "Epoch: 9/40... Step: 750... Loss: 1.7548... Val Loss: 1.8413\n",
            "Epoch: 9/40... Step: 750... Loss: 1.6643... Val Loss: 1.8118\n",
            "Epoch: 9/40... Step: 750... Loss: 1.5251... Val Loss: 1.7708\n",
            "Epoch: 9/40... Step: 750... Loss: 1.6716... Val Loss: 1.7584\n",
            "Epoch: 9/40... Step: 750... Loss: 1.6876... Val Loss: 1.7505\n",
            "Epoch: 9/40... Step: 750... Loss: 1.7110... Val Loss: 1.7466\n",
            "Epoch: 9/40... Step: 760... Loss: 1.8164... Val Loss: 1.8164\n",
            "Epoch: 9/40... Step: 760... Loss: 1.7329... Val Loss: 1.7746\n",
            "Epoch: 9/40... Step: 760... Loss: 1.9641... Val Loss: 1.8378\n",
            "Epoch: 9/40... Step: 760... Loss: 1.9271... Val Loss: 1.8601\n",
            "Epoch: 9/40... Step: 760... Loss: 1.7418... Val Loss: 1.8365\n",
            "Epoch: 9/40... Step: 760... Loss: 1.6827... Val Loss: 1.8108\n",
            "Epoch: 9/40... Step: 760... Loss: 1.5262... Val Loss: 1.7702\n",
            "Epoch: 9/40... Step: 760... Loss: 1.6588... Val Loss: 1.7563\n",
            "Epoch: 9/40... Step: 760... Loss: 1.6957... Val Loss: 1.7495\n",
            "Epoch: 9/40... Step: 760... Loss: 1.6942... Val Loss: 1.7440\n",
            "Epoch: 9/40... Step: 770... Loss: 1.8017... Val Loss: 1.8017\n",
            "Epoch: 9/40... Step: 770... Loss: 1.7224... Val Loss: 1.7621\n",
            "Epoch: 9/40... Step: 770... Loss: 1.9448... Val Loss: 1.8230\n",
            "Epoch: 9/40... Step: 770... Loss: 1.8985... Val Loss: 1.8419\n",
            "Epoch: 9/40... Step: 770... Loss: 1.7381... Val Loss: 1.8211\n",
            "Epoch: 9/40... Step: 770... Loss: 1.6730... Val Loss: 1.7964\n",
            "Epoch: 9/40... Step: 770... Loss: 1.5170... Val Loss: 1.7565\n",
            "Epoch: 9/40... Step: 770... Loss: 1.6790... Val Loss: 1.7468\n",
            "Epoch: 9/40... Step: 770... Loss: 1.6772... Val Loss: 1.7391\n",
            "Epoch: 9/40... Step: 770... Loss: 1.7140... Val Loss: 1.7366\n",
            "Epoch: 9/40... Step: 780... Loss: 1.8119... Val Loss: 1.8119\n",
            "Epoch: 9/40... Step: 780... Loss: 1.7456... Val Loss: 1.7788\n",
            "Epoch: 9/40... Step: 780... Loss: 1.9183... Val Loss: 1.8253\n",
            "Epoch: 9/40... Step: 780... Loss: 1.9070... Val Loss: 1.8457\n",
            "Epoch: 9/40... Step: 780... Loss: 1.7441... Val Loss: 1.8254\n",
            "Epoch: 9/40... Step: 780... Loss: 1.6862... Val Loss: 1.8022\n",
            "Epoch: 9/40... Step: 780... Loss: 1.5602... Val Loss: 1.7676\n",
            "Epoch: 9/40... Step: 780... Loss: 1.6757... Val Loss: 1.7561\n",
            "Epoch: 9/40... Step: 780... Loss: 1.6974... Val Loss: 1.7496\n",
            "Epoch: 9/40... Step: 780... Loss: 1.6979... Val Loss: 1.7444\n",
            "Epoch: 9/40... Step: 790... Loss: 1.8329... Val Loss: 1.8329\n",
            "Epoch: 9/40... Step: 790... Loss: 1.7490... Val Loss: 1.7910\n",
            "Epoch: 9/40... Step: 790... Loss: 1.9452... Val Loss: 1.8424\n",
            "Epoch: 9/40... Step: 790... Loss: 1.9206... Val Loss: 1.8619\n",
            "Epoch: 9/40... Step: 790... Loss: 1.7384... Val Loss: 1.8372\n",
            "Epoch: 9/40... Step: 790... Loss: 1.7064... Val Loss: 1.8154\n",
            "Epoch: 9/40... Step: 790... Loss: 1.5756... Val Loss: 1.7812\n",
            "Epoch: 9/40... Step: 790... Loss: 1.7261... Val Loss: 1.7743\n",
            "Epoch: 9/40... Step: 790... Loss: 1.7188... Val Loss: 1.7681\n",
            "Epoch: 9/40... Step: 790... Loss: 1.7175... Val Loss: 1.7630\n",
            "Epoch: 9/40... Step: 800... Loss: 1.8209... Val Loss: 1.8209\n",
            "Epoch: 9/40... Step: 800... Loss: 1.7585... Val Loss: 1.7897\n",
            "Epoch: 9/40... Step: 800... Loss: 1.9590... Val Loss: 1.8461\n",
            "Epoch: 9/40... Step: 800... Loss: 1.9344... Val Loss: 1.8682\n",
            "Epoch: 9/40... Step: 800... Loss: 1.7667... Val Loss: 1.8479\n",
            "Epoch: 9/40... Step: 800... Loss: 1.7228... Val Loss: 1.8271\n",
            "Epoch: 9/40... Step: 800... Loss: 1.5930... Val Loss: 1.7936\n",
            "Epoch: 9/40... Step: 800... Loss: 1.6880... Val Loss: 1.7804\n",
            "Epoch: 9/40... Step: 800... Loss: 1.7011... Val Loss: 1.7716\n",
            "Epoch: 9/40... Step: 800... Loss: 1.7188... Val Loss: 1.7663\n",
            "Epoch: 9/40... Step: 810... Loss: 1.8122... Val Loss: 1.8122\n",
            "Epoch: 9/40... Step: 810... Loss: 1.7427... Val Loss: 1.7775\n",
            "Epoch: 9/40... Step: 810... Loss: 1.9322... Val Loss: 1.8290\n",
            "Epoch: 9/40... Step: 810... Loss: 1.9265... Val Loss: 1.8534\n",
            "Epoch: 9/40... Step: 810... Loss: 1.7676... Val Loss: 1.8362\n",
            "Epoch: 9/40... Step: 810... Loss: 1.7112... Val Loss: 1.8154\n",
            "Epoch: 9/40... Step: 810... Loss: 1.5980... Val Loss: 1.7843\n",
            "Epoch: 9/40... Step: 810... Loss: 1.6941... Val Loss: 1.7731\n",
            "Epoch: 9/40... Step: 810... Loss: 1.7008... Val Loss: 1.7650\n",
            "Epoch: 9/40... Step: 810... Loss: 1.7281... Val Loss: 1.7613\n",
            "Epoch: 9/40... Step: 820... Loss: 1.8124... Val Loss: 1.8124\n",
            "Epoch: 9/40... Step: 820... Loss: 1.7456... Val Loss: 1.7790\n",
            "Epoch: 9/40... Step: 820... Loss: 1.9319... Val Loss: 1.8299\n",
            "Epoch: 9/40... Step: 820... Loss: 1.9254... Val Loss: 1.8538\n",
            "Epoch: 9/40... Step: 820... Loss: 1.7737... Val Loss: 1.8378\n",
            "Epoch: 9/40... Step: 820... Loss: 1.7227... Val Loss: 1.8186\n",
            "Epoch: 9/40... Step: 820... Loss: 1.5790... Val Loss: 1.7844\n",
            "Epoch: 9/40... Step: 820... Loss: 1.6719... Val Loss: 1.7703\n",
            "Epoch: 9/40... Step: 820... Loss: 1.7008... Val Loss: 1.7626\n",
            "Epoch: 9/40... Step: 820... Loss: 1.7019... Val Loss: 1.7565\n",
            "Epoch: 10/40... Step: 830... Loss: 1.8173... Val Loss: 1.8173\n",
            "Epoch: 10/40... Step: 830... Loss: 1.7430... Val Loss: 1.7801\n",
            "Epoch: 10/40... Step: 830... Loss: 1.9350... Val Loss: 1.8318\n",
            "Epoch: 10/40... Step: 830... Loss: 1.9308... Val Loss: 1.8565\n",
            "Epoch: 10/40... Step: 830... Loss: 1.7439... Val Loss: 1.8340\n",
            "Epoch: 10/40... Step: 830... Loss: 1.6916... Val Loss: 1.8103\n",
            "Epoch: 10/40... Step: 830... Loss: 1.5522... Val Loss: 1.7734\n",
            "Epoch: 10/40... Step: 830... Loss: 1.6829... Val Loss: 1.7621\n",
            "Epoch: 10/40... Step: 830... Loss: 1.6952... Val Loss: 1.7546\n",
            "Epoch: 10/40... Step: 830... Loss: 1.7031... Val Loss: 1.7495\n",
            "Epoch: 10/40... Step: 840... Loss: 1.7867... Val Loss: 1.7867\n",
            "Epoch: 10/40... Step: 840... Loss: 1.7175... Val Loss: 1.7521\n",
            "Epoch: 10/40... Step: 840... Loss: 1.9309... Val Loss: 1.8117\n",
            "Epoch: 10/40... Step: 840... Loss: 1.9077... Val Loss: 1.8357\n",
            "Epoch: 10/40... Step: 840... Loss: 1.7047... Val Loss: 1.8095\n",
            "Epoch: 10/40... Step: 840... Loss: 1.6503... Val Loss: 1.7830\n",
            "Epoch: 10/40... Step: 840... Loss: 1.5018... Val Loss: 1.7428\n",
            "Epoch: 10/40... Step: 840... Loss: 1.6400... Val Loss: 1.7300\n",
            "Epoch: 10/40... Step: 840... Loss: 1.6590... Val Loss: 1.7221\n",
            "Epoch: 10/40... Step: 840... Loss: 1.6783... Val Loss: 1.7177\n",
            "Epoch: 10/40... Step: 850... Loss: 1.7824... Val Loss: 1.7824\n",
            "Epoch: 10/40... Step: 850... Loss: 1.6797... Val Loss: 1.7310\n",
            "Epoch: 10/40... Step: 850... Loss: 1.8905... Val Loss: 1.7842\n",
            "Epoch: 10/40... Step: 850... Loss: 1.8903... Val Loss: 1.8107\n",
            "Epoch: 10/40... Step: 850... Loss: 1.6974... Val Loss: 1.7880\n",
            "Epoch: 10/40... Step: 850... Loss: 1.6464... Val Loss: 1.7644\n",
            "Epoch: 10/40... Step: 850... Loss: 1.5020... Val Loss: 1.7269\n",
            "Epoch: 10/40... Step: 850... Loss: 1.6313... Val Loss: 1.7150\n",
            "Epoch: 10/40... Step: 850... Loss: 1.6437... Val Loss: 1.7071\n",
            "Epoch: 10/40... Step: 850... Loss: 1.6634... Val Loss: 1.7027\n",
            "Epoch: 10/40... Step: 860... Loss: 1.7699... Val Loss: 1.7699\n",
            "Epoch: 10/40... Step: 860... Loss: 1.6753... Val Loss: 1.7226\n",
            "Epoch: 10/40... Step: 860... Loss: 1.9030... Val Loss: 1.7827\n",
            "Epoch: 10/40... Step: 860... Loss: 1.8682... Val Loss: 1.8041\n",
            "Epoch: 10/40... Step: 860... Loss: 1.6867... Val Loss: 1.7806\n",
            "Epoch: 10/40... Step: 860... Loss: 1.6341... Val Loss: 1.7562\n",
            "Epoch: 10/40... Step: 860... Loss: 1.4887... Val Loss: 1.7180\n",
            "Epoch: 10/40... Step: 860... Loss: 1.6074... Val Loss: 1.7042\n",
            "Epoch: 10/40... Step: 860... Loss: 1.6292... Val Loss: 1.6958\n",
            "Epoch: 10/40... Step: 860... Loss: 1.6848... Val Loss: 1.6947\n",
            "Epoch: 10/40... Step: 870... Loss: 1.7642... Val Loss: 1.7642\n",
            "Epoch: 10/40... Step: 870... Loss: 1.6986... Val Loss: 1.7314\n",
            "Epoch: 10/40... Step: 870... Loss: 1.8890... Val Loss: 1.7839\n",
            "Epoch: 10/40... Step: 870... Loss: 1.8908... Val Loss: 1.8106\n",
            "Epoch: 10/40... Step: 870... Loss: 1.6905... Val Loss: 1.7866\n",
            "Epoch: 10/40... Step: 870... Loss: 1.6508... Val Loss: 1.7640\n",
            "Epoch: 10/40... Step: 870... Loss: 1.5345... Val Loss: 1.7312\n",
            "Epoch: 10/40... Step: 870... Loss: 1.6456... Val Loss: 1.7205\n",
            "Epoch: 10/40... Step: 870... Loss: 1.6581... Val Loss: 1.7136\n",
            "Epoch: 10/40... Step: 870... Loss: 1.6738... Val Loss: 1.7096\n",
            "Epoch: 10/40... Step: 880... Loss: 1.7637... Val Loss: 1.7637\n",
            "Epoch: 10/40... Step: 880... Loss: 1.6976... Val Loss: 1.7307\n",
            "Epoch: 10/40... Step: 880... Loss: 1.8911... Val Loss: 1.7842\n",
            "Epoch: 10/40... Step: 880... Loss: 1.8916... Val Loss: 1.8110\n",
            "Epoch: 10/40... Step: 880... Loss: 1.7068... Val Loss: 1.7902\n",
            "Epoch: 10/40... Step: 880... Loss: 1.6688... Val Loss: 1.7699\n",
            "Epoch: 10/40... Step: 880... Loss: 1.5234... Val Loss: 1.7347\n",
            "Epoch: 10/40... Step: 880... Loss: 1.6500... Val Loss: 1.7241\n",
            "Epoch: 10/40... Step: 880... Loss: 1.6383... Val Loss: 1.7146\n",
            "Epoch: 10/40... Step: 880... Loss: 1.6742... Val Loss: 1.7106\n",
            "Epoch: 10/40... Step: 890... Loss: 1.7799... Val Loss: 1.7799\n",
            "Epoch: 10/40... Step: 890... Loss: 1.7098... Val Loss: 1.7448\n",
            "Epoch: 10/40... Step: 890... Loss: 1.9213... Val Loss: 1.8036\n",
            "Epoch: 10/40... Step: 890... Loss: 1.9140... Val Loss: 1.8312\n",
            "Epoch: 10/40... Step: 890... Loss: 1.7056... Val Loss: 1.8061\n",
            "Epoch: 10/40... Step: 890... Loss: 1.6956... Val Loss: 1.7877\n",
            "Epoch: 10/40... Step: 890... Loss: 1.5512... Val Loss: 1.7539\n",
            "Epoch: 10/40... Step: 890... Loss: 1.6414... Val Loss: 1.7398\n",
            "Epoch: 10/40... Step: 890... Loss: 1.6738... Val Loss: 1.7325\n",
            "Epoch: 10/40... Step: 890... Loss: 1.6857... Val Loss: 1.7278\n",
            "Epoch: 10/40... Step: 900... Loss: 1.7877... Val Loss: 1.7877\n",
            "Epoch: 10/40... Step: 900... Loss: 1.7173... Val Loss: 1.7525\n",
            "Epoch: 10/40... Step: 900... Loss: 1.9230... Val Loss: 1.8093\n",
            "Epoch: 10/40... Step: 900... Loss: 1.9097... Val Loss: 1.8344\n",
            "Epoch: 10/40... Step: 900... Loss: 1.7336... Val Loss: 1.8142\n",
            "Epoch: 10/40... Step: 900... Loss: 1.6910... Val Loss: 1.7937\n",
            "Epoch: 10/40... Step: 900... Loss: 1.5683... Val Loss: 1.7615\n",
            "Epoch: 10/40... Step: 900... Loss: 1.6518... Val Loss: 1.7478\n",
            "Epoch: 10/40... Step: 900... Loss: 1.6530... Val Loss: 1.7373\n",
            "Epoch: 10/40... Step: 900... Loss: 1.6975... Val Loss: 1.7333\n",
            "Epoch: 10/40... Step: 910... Loss: 1.7687... Val Loss: 1.7687\n",
            "Epoch: 10/40... Step: 910... Loss: 1.6960... Val Loss: 1.7324\n",
            "Epoch: 10/40... Step: 910... Loss: 1.9019... Val Loss: 1.7889\n",
            "Epoch: 10/40... Step: 910... Loss: 1.9023... Val Loss: 1.8172\n",
            "Epoch: 10/40... Step: 910... Loss: 1.7154... Val Loss: 1.7969\n",
            "Epoch: 10/40... Step: 910... Loss: 1.6661... Val Loss: 1.7751\n",
            "Epoch: 10/40... Step: 910... Loss: 1.5405... Val Loss: 1.7416\n",
            "Epoch: 10/40... Step: 910... Loss: 1.6314... Val Loss: 1.7278\n",
            "Epoch: 10/40... Step: 910... Loss: 1.6477... Val Loss: 1.7189\n",
            "Epoch: 10/40... Step: 910... Loss: 1.6663... Val Loss: 1.7136\n",
            "Epoch: 10/40... Step: 920... Loss: 1.7744... Val Loss: 1.7744\n",
            "Epoch: 10/40... Step: 920... Loss: 1.6597... Val Loss: 1.7171\n",
            "Epoch: 10/40... Step: 920... Loss: 1.8991... Val Loss: 1.7777\n",
            "Epoch: 10/40... Step: 920... Loss: 1.9120... Val Loss: 1.8113\n",
            "Epoch: 10/40... Step: 920... Loss: 1.6825... Val Loss: 1.7855\n",
            "Epoch: 10/40... Step: 920... Loss: 1.6625... Val Loss: 1.7650\n",
            "Epoch: 10/40... Step: 920... Loss: 1.5015... Val Loss: 1.7274\n",
            "Epoch: 10/40... Step: 920... Loss: 1.6275... Val Loss: 1.7149\n",
            "Epoch: 10/40... Step: 920... Loss: 1.6657... Val Loss: 1.7094\n",
            "Epoch: 10/40... Step: 920... Loss: 1.6554... Val Loss: 1.7040\n",
            "Epoch: 11/40... Step: 930... Loss: 1.7416... Val Loss: 1.7416\n",
            "Epoch: 11/40... Step: 930... Loss: 1.6802... Val Loss: 1.7109\n",
            "Epoch: 11/40... Step: 930... Loss: 1.9047... Val Loss: 1.7755\n",
            "Epoch: 11/40... Step: 930... Loss: 1.8828... Val Loss: 1.8023\n",
            "Epoch: 11/40... Step: 930... Loss: 1.6936... Val Loss: 1.7806\n",
            "Epoch: 11/40... Step: 930... Loss: 1.6194... Val Loss: 1.7537\n",
            "Epoch: 11/40... Step: 930... Loss: 1.4723... Val Loss: 1.7135\n",
            "Epoch: 11/40... Step: 930... Loss: 1.6191... Val Loss: 1.7017\n",
            "Epoch: 11/40... Step: 930... Loss: 1.6208... Val Loss: 1.6927\n",
            "Epoch: 11/40... Step: 930... Loss: 1.6514... Val Loss: 1.6886\n",
            "Epoch: 11/40... Step: 940... Loss: 1.7297... Val Loss: 1.7297\n",
            "Epoch: 11/40... Step: 940... Loss: 1.6519... Val Loss: 1.6908\n",
            "Epoch: 11/40... Step: 940... Loss: 1.8610... Val Loss: 1.7476\n",
            "Epoch: 11/40... Step: 940... Loss: 1.8554... Val Loss: 1.7745\n",
            "Epoch: 11/40... Step: 940... Loss: 1.6873... Val Loss: 1.7571\n",
            "Epoch: 11/40... Step: 940... Loss: 1.6122... Val Loss: 1.7329\n",
            "Epoch: 11/40... Step: 940... Loss: 1.4654... Val Loss: 1.6947\n",
            "Epoch: 11/40... Step: 940... Loss: 1.6256... Val Loss: 1.6861\n",
            "Epoch: 11/40... Step: 940... Loss: 1.6100... Val Loss: 1.6776\n",
            "Epoch: 11/40... Step: 940... Loss: 1.6150... Val Loss: 1.6714\n",
            "Epoch: 11/40... Step: 950... Loss: 1.7137... Val Loss: 1.7137\n",
            "Epoch: 11/40... Step: 950... Loss: 1.6400... Val Loss: 1.6769\n",
            "Epoch: 11/40... Step: 950... Loss: 1.8512... Val Loss: 1.7350\n",
            "Epoch: 11/40... Step: 950... Loss: 1.8342... Val Loss: 1.7598\n",
            "Epoch: 11/40... Step: 950... Loss: 1.6416... Val Loss: 1.7361\n",
            "Epoch: 11/40... Step: 950... Loss: 1.5841... Val Loss: 1.7108\n",
            "Epoch: 11/40... Step: 950... Loss: 1.4684... Val Loss: 1.6762\n",
            "Epoch: 11/40... Step: 950... Loss: 1.5912... Val Loss: 1.6655\n",
            "Epoch: 11/40... Step: 950... Loss: 1.5855... Val Loss: 1.6566\n",
            "Epoch: 11/40... Step: 950... Loss: 1.6244... Val Loss: 1.6534\n",
            "Epoch: 11/40... Step: 960... Loss: 1.7229... Val Loss: 1.7229\n",
            "Epoch: 11/40... Step: 960... Loss: 1.6669... Val Loss: 1.6949\n",
            "Epoch: 11/40... Step: 960... Loss: 1.8692... Val Loss: 1.7530\n",
            "Epoch: 11/40... Step: 960... Loss: 1.8305... Val Loss: 1.7724\n",
            "Epoch: 11/40... Step: 960... Loss: 1.6741... Val Loss: 1.7527\n",
            "Epoch: 11/40... Step: 960... Loss: 1.6246... Val Loss: 1.7314\n",
            "Epoch: 11/40... Step: 960... Loss: 1.4771... Val Loss: 1.6950\n",
            "Epoch: 11/40... Step: 960... Loss: 1.5998... Val Loss: 1.6831\n",
            "Epoch: 11/40... Step: 960... Loss: 1.6122... Val Loss: 1.6753\n",
            "Epoch: 11/40... Step: 960... Loss: 1.6401... Val Loss: 1.6717\n",
            "Epoch: 11/40... Step: 970... Loss: 1.7361... Val Loss: 1.7361\n",
            "Epoch: 11/40... Step: 970... Loss: 1.6686... Val Loss: 1.7024\n",
            "Epoch: 11/40... Step: 970... Loss: 1.8553... Val Loss: 1.7533\n",
            "Epoch: 11/40... Step: 970... Loss: 1.8473... Val Loss: 1.7768\n",
            "Epoch: 11/40... Step: 970... Loss: 1.6722... Val Loss: 1.7559\n",
            "Epoch: 11/40... Step: 970... Loss: 1.6229... Val Loss: 1.7337\n",
            "Epoch: 11/40... Step: 970... Loss: 1.4894... Val Loss: 1.6988\n",
            "Epoch: 11/40... Step: 970... Loss: 1.6162... Val Loss: 1.6885\n",
            "Epoch: 11/40... Step: 970... Loss: 1.6370... Val Loss: 1.6828\n",
            "Epoch: 11/40... Step: 970... Loss: 1.6261... Val Loss: 1.6771\n",
            "Epoch: 11/40... Step: 980... Loss: 1.7474... Val Loss: 1.7474\n",
            "Epoch: 11/40... Step: 980... Loss: 1.6461... Val Loss: 1.6967\n",
            "Epoch: 11/40... Step: 980... Loss: 1.8702... Val Loss: 1.7546\n",
            "Epoch: 11/40... Step: 980... Loss: 1.8663... Val Loss: 1.7825\n",
            "Epoch: 11/40... Step: 980... Loss: 1.6856... Val Loss: 1.7631\n",
            "Epoch: 11/40... Step: 980... Loss: 1.6451... Val Loss: 1.7435\n",
            "Epoch: 11/40... Step: 980... Loss: 1.5149... Val Loss: 1.7108\n",
            "Epoch: 11/40... Step: 980... Loss: 1.6326... Val Loss: 1.7010\n",
            "Epoch: 11/40... Step: 980... Loss: 1.6223... Val Loss: 1.6923\n",
            "Epoch: 11/40... Step: 980... Loss: 1.6646... Val Loss: 1.6895\n",
            "Epoch: 11/40... Step: 990... Loss: 1.7477... Val Loss: 1.7477\n",
            "Epoch: 11/40... Step: 990... Loss: 1.6918... Val Loss: 1.7198\n",
            "Epoch: 11/40... Step: 990... Loss: 1.9065... Val Loss: 1.7820\n",
            "Epoch: 11/40... Step: 990... Loss: 1.8861... Val Loss: 1.8080\n",
            "Epoch: 11/40... Step: 990... Loss: 1.7121... Val Loss: 1.7888\n",
            "Epoch: 11/40... Step: 990... Loss: 1.6658... Val Loss: 1.7683\n",
            "Epoch: 11/40... Step: 990... Loss: 1.5385... Val Loss: 1.7355\n",
            "Epoch: 11/40... Step: 990... Loss: 1.6254... Val Loss: 1.7217\n",
            "Epoch: 11/40... Step: 990... Loss: 1.6327... Val Loss: 1.7118\n",
            "Epoch: 11/40... Step: 990... Loss: 1.6564... Val Loss: 1.7063\n",
            "Epoch: 11/40... Step: 1000... Loss: 1.7233... Val Loss: 1.7233\n",
            "Epoch: 11/40... Step: 1000... Loss: 1.6550... Val Loss: 1.6892\n",
            "Epoch: 11/40... Step: 1000... Loss: 1.8663... Val Loss: 1.7482\n",
            "Epoch: 11/40... Step: 1000... Loss: 1.8763... Val Loss: 1.7802\n",
            "Epoch: 11/40... Step: 1000... Loss: 1.6883... Val Loss: 1.7619\n",
            "Epoch: 11/40... Step: 1000... Loss: 1.6343... Val Loss: 1.7406\n",
            "Epoch: 11/40... Step: 1000... Loss: 1.5376... Val Loss: 1.7116\n",
            "Epoch: 11/40... Step: 1000... Loss: 1.6194... Val Loss: 1.7001\n",
            "Epoch: 11/40... Step: 1000... Loss: 1.6096... Val Loss: 1.6900\n",
            "Epoch: 11/40... Step: 1000... Loss: 1.6325... Val Loss: 1.6843\n",
            "Epoch: 11/40... Step: 1010... Loss: 1.7296... Val Loss: 1.7296\n",
            "Epoch: 11/40... Step: 1010... Loss: 1.6628... Val Loss: 1.6962\n",
            "Epoch: 11/40... Step: 1010... Loss: 1.8609... Val Loss: 1.7511\n",
            "Epoch: 11/40... Step: 1010... Loss: 1.8625... Val Loss: 1.7790\n",
            "Epoch: 11/40... Step: 1010... Loss: 1.6769... Val Loss: 1.7586\n",
            "Epoch: 11/40... Step: 1010... Loss: 1.6283... Val Loss: 1.7368\n",
            "Epoch: 11/40... Step: 1010... Loss: 1.4801... Val Loss: 1.7002\n",
            "Epoch: 11/40... Step: 1010... Loss: 1.6192... Val Loss: 1.6900\n",
            "Epoch: 11/40... Step: 1010... Loss: 1.6079... Val Loss: 1.6809\n",
            "Epoch: 11/40... Step: 1010... Loss: 1.6448... Val Loss: 1.6773\n",
            "Epoch: 12/40... Step: 1020... Loss: 1.7106... Val Loss: 1.7106\n",
            "Epoch: 12/40... Step: 1020... Loss: 1.6418... Val Loss: 1.6762\n",
            "Epoch: 12/40... Step: 1020... Loss: 1.8730... Val Loss: 1.7418\n",
            "Epoch: 12/40... Step: 1020... Loss: 1.8695... Val Loss: 1.7737\n",
            "Epoch: 12/40... Step: 1020... Loss: 1.6539... Val Loss: 1.7497\n",
            "Epoch: 12/40... Step: 1020... Loss: 1.6198... Val Loss: 1.7281\n",
            "Epoch: 12/40... Step: 1020... Loss: 1.4689... Val Loss: 1.6911\n",
            "Epoch: 12/40... Step: 1020... Loss: 1.5724... Val Loss: 1.6762\n",
            "Epoch: 12/40... Step: 1020... Loss: 1.5860... Val Loss: 1.6662\n",
            "Epoch: 12/40... Step: 1020... Loss: 1.6256... Val Loss: 1.6621\n",
            "Epoch: 12/40... Step: 1030... Loss: 1.6992... Val Loss: 1.6992\n",
            "Epoch: 12/40... Step: 1030... Loss: 1.6031... Val Loss: 1.6511\n",
            "Epoch: 12/40... Step: 1030... Loss: 1.8428... Val Loss: 1.7150\n",
            "Epoch: 12/40... Step: 1030... Loss: 1.8105... Val Loss: 1.7389\n",
            "Epoch: 12/40... Step: 1030... Loss: 1.6285... Val Loss: 1.7168\n",
            "Epoch: 12/40... Step: 1030... Loss: 1.5802... Val Loss: 1.6941\n",
            "Epoch: 12/40... Step: 1030... Loss: 1.4193... Val Loss: 1.6548\n",
            "Epoch: 12/40... Step: 1030... Loss: 1.5680... Val Loss: 1.6439\n",
            "Epoch: 12/40... Step: 1030... Loss: 1.5869... Val Loss: 1.6376\n",
            "Epoch: 12/40... Step: 1030... Loss: 1.6151... Val Loss: 1.6354\n",
            "Epoch: 12/40... Step: 1040... Loss: 1.6957... Val Loss: 1.6957\n",
            "Epoch: 12/40... Step: 1040... Loss: 1.5914... Val Loss: 1.6435\n",
            "Epoch: 12/40... Step: 1040... Loss: 1.8186... Val Loss: 1.7019\n",
            "Epoch: 12/40... Step: 1040... Loss: 1.7993... Val Loss: 1.7262\n",
            "Epoch: 12/40... Step: 1040... Loss: 1.6272... Val Loss: 1.7064\n",
            "Epoch: 12/40... Step: 1040... Loss: 1.5604... Val Loss: 1.6821\n",
            "Epoch: 12/40... Step: 1040... Loss: 1.4053... Val Loss: 1.6425\n",
            "Epoch: 12/40... Step: 1040... Loss: 1.5616... Val Loss: 1.6324\n",
            "Epoch: 12/40... Step: 1040... Loss: 1.5909... Val Loss: 1.6278\n",
            "Epoch: 12/40... Step: 1040... Loss: 1.6069... Val Loss: 1.6257\n",
            "Epoch: 12/40... Step: 1050... Loss: 1.6862... Val Loss: 1.6862\n",
            "Epoch: 12/40... Step: 1050... Loss: 1.6518... Val Loss: 1.6690\n",
            "Epoch: 12/40... Step: 1050... Loss: 1.8199... Val Loss: 1.7193\n",
            "Epoch: 12/40... Step: 1050... Loss: 1.8210... Val Loss: 1.7447\n",
            "Epoch: 12/40... Step: 1050... Loss: 1.6255... Val Loss: 1.7209\n",
            "Epoch: 12/40... Step: 1050... Loss: 1.5865... Val Loss: 1.6985\n",
            "Epoch: 12/40... Step: 1050... Loss: 1.4485... Val Loss: 1.6628\n",
            "Epoch: 12/40... Step: 1050... Loss: 1.5904... Val Loss: 1.6537\n",
            "Epoch: 12/40... Step: 1050... Loss: 1.5842... Val Loss: 1.6460\n",
            "Epoch: 12/40... Step: 1050... Loss: 1.6226... Val Loss: 1.6436\n",
            "Epoch: 12/40... Step: 1060... Loss: 1.7040... Val Loss: 1.7040\n",
            "Epoch: 12/40... Step: 1060... Loss: 1.6316... Val Loss: 1.6678\n",
            "Epoch: 12/40... Step: 1060... Loss: 1.8480... Val Loss: 1.7279\n",
            "Epoch: 12/40... Step: 1060... Loss: 1.8297... Val Loss: 1.7533\n",
            "Epoch: 12/40... Step: 1060... Loss: 1.6350... Val Loss: 1.7297\n",
            "Epoch: 12/40... Step: 1060... Loss: 1.6037... Val Loss: 1.7087\n",
            "Epoch: 12/40... Step: 1060... Loss: 1.4637... Val Loss: 1.6737\n",
            "Epoch: 12/40... Step: 1060... Loss: 1.5736... Val Loss: 1.6612\n",
            "Epoch: 12/40... Step: 1060... Loss: 1.6131... Val Loss: 1.6558\n",
            "Epoch: 12/40... Step: 1060... Loss: 1.6378... Val Loss: 1.6540\n",
            "Epoch: 12/40... Step: 1070... Loss: 1.7127... Val Loss: 1.7127\n",
            "Epoch: 12/40... Step: 1070... Loss: 1.6307... Val Loss: 1.6717\n",
            "Epoch: 12/40... Step: 1070... Loss: 1.8514... Val Loss: 1.7316\n",
            "Epoch: 12/40... Step: 1070... Loss: 1.8400... Val Loss: 1.7587\n",
            "Epoch: 12/40... Step: 1070... Loss: 1.6605... Val Loss: 1.7391\n",
            "Epoch: 12/40... Step: 1070... Loss: 1.6227... Val Loss: 1.7197\n",
            "Epoch: 12/40... Step: 1070... Loss: 1.4896... Val Loss: 1.6868\n",
            "Epoch: 12/40... Step: 1070... Loss: 1.6002... Val Loss: 1.6760\n",
            "Epoch: 12/40... Step: 1070... Loss: 1.6136... Val Loss: 1.6691\n",
            "Epoch: 12/40... Step: 1070... Loss: 1.6217... Val Loss: 1.6643\n",
            "Epoch: 12/40... Step: 1080... Loss: 1.7009... Val Loss: 1.7009\n",
            "Epoch: 12/40... Step: 1080... Loss: 1.6655... Val Loss: 1.6832\n",
            "Epoch: 12/40... Step: 1080... Loss: 1.8754... Val Loss: 1.7473\n",
            "Epoch: 12/40... Step: 1080... Loss: 1.8582... Val Loss: 1.7750\n",
            "Epoch: 12/40... Step: 1080... Loss: 1.6692... Val Loss: 1.7539\n",
            "Epoch: 12/40... Step: 1080... Loss: 1.6263... Val Loss: 1.7326\n",
            "Epoch: 12/40... Step: 1080... Loss: 1.4963... Val Loss: 1.6989\n",
            "Epoch: 12/40... Step: 1080... Loss: 1.5907... Val Loss: 1.6853\n",
            "Epoch: 12/40... Step: 1080... Loss: 1.5940... Val Loss: 1.6752\n",
            "Epoch: 12/40... Step: 1080... Loss: 1.6389... Val Loss: 1.6716\n",
            "Epoch: 12/40... Step: 1090... Loss: 1.6945... Val Loss: 1.6945\n",
            "Epoch: 12/40... Step: 1090... Loss: 1.6336... Val Loss: 1.6640\n",
            "Epoch: 12/40... Step: 1090... Loss: 1.8553... Val Loss: 1.7278\n",
            "Epoch: 12/40... Step: 1090... Loss: 1.8593... Val Loss: 1.7607\n",
            "Epoch: 12/40... Step: 1090... Loss: 1.6732... Val Loss: 1.7432\n",
            "Epoch: 12/40... Step: 1090... Loss: 1.6212... Val Loss: 1.7228\n",
            "Epoch: 12/40... Step: 1090... Loss: 1.5189... Val Loss: 1.6937\n",
            "Epoch: 12/40... Step: 1090... Loss: 1.6031... Val Loss: 1.6824\n",
            "Epoch: 12/40... Step: 1090... Loss: 1.5877... Val Loss: 1.6719\n",
            "Epoch: 12/40... Step: 1090... Loss: 1.6290... Val Loss: 1.6676\n",
            "Epoch: 12/40... Step: 1100... Loss: 1.6953... Val Loss: 1.6953\n",
            "Epoch: 12/40... Step: 1100... Loss: 1.6154... Val Loss: 1.6553\n",
            "Epoch: 12/40... Step: 1100... Loss: 1.8433... Val Loss: 1.7180\n",
            "Epoch: 12/40... Step: 1100... Loss: 1.8511... Val Loss: 1.7513\n",
            "Epoch: 12/40... Step: 1100... Loss: 1.6313... Val Loss: 1.7273\n",
            "Epoch: 12/40... Step: 1100... Loss: 1.6146... Val Loss: 1.7085\n",
            "Epoch: 12/40... Step: 1100... Loss: 1.4651... Val Loss: 1.6737\n",
            "Epoch: 12/40... Step: 1100... Loss: 1.5759... Val Loss: 1.6615\n",
            "Epoch: 12/40... Step: 1100... Loss: 1.5966... Val Loss: 1.6543\n",
            "Epoch: 12/40... Step: 1100... Loss: 1.6342... Val Loss: 1.6523\n",
            "Epoch: 13/40... Step: 1110... Loss: 1.6855... Val Loss: 1.6855\n",
            "Epoch: 13/40... Step: 1110... Loss: 1.6294... Val Loss: 1.6575\n",
            "Epoch: 13/40... Step: 1110... Loss: 1.8622... Val Loss: 1.7257\n",
            "Epoch: 13/40... Step: 1110... Loss: 1.8527... Val Loss: 1.7575\n",
            "Epoch: 13/40... Step: 1110... Loss: 1.6326... Val Loss: 1.7325\n",
            "Epoch: 13/40... Step: 1110... Loss: 1.5881... Val Loss: 1.7084\n",
            "Epoch: 13/40... Step: 1110... Loss: 1.4675... Val Loss: 1.6740\n",
            "Epoch: 13/40... Step: 1110... Loss: 1.5631... Val Loss: 1.6601\n",
            "Epoch: 13/40... Step: 1110... Loss: 1.5734... Val Loss: 1.6505\n",
            "Epoch: 13/40... Step: 1110... Loss: 1.5905... Val Loss: 1.6445\n",
            "Epoch: 13/40... Step: 1120... Loss: 1.6716... Val Loss: 1.6716\n",
            "Epoch: 13/40... Step: 1120... Loss: 1.5894... Val Loss: 1.6305\n",
            "Epoch: 13/40... Step: 1120... Loss: 1.8054... Val Loss: 1.6888\n",
            "Epoch: 13/40... Step: 1120... Loss: 1.8088... Val Loss: 1.7188\n",
            "Epoch: 13/40... Step: 1120... Loss: 1.6007... Val Loss: 1.6952\n",
            "Epoch: 13/40... Step: 1120... Loss: 1.5577... Val Loss: 1.6723\n",
            "Epoch: 13/40... Step: 1120... Loss: 1.4216... Val Loss: 1.6364\n",
            "Epoch: 13/40... Step: 1120... Loss: 1.5526... Val Loss: 1.6260\n",
            "Epoch: 13/40... Step: 1120... Loss: 1.5640... Val Loss: 1.6191\n",
            "Epoch: 13/40... Step: 1120... Loss: 1.5810... Val Loss: 1.6153\n",
            "Epoch: 13/40... Step: 1130... Loss: 1.6705... Val Loss: 1.6705\n",
            "Epoch: 13/40... Step: 1130... Loss: 1.5917... Val Loss: 1.6311\n",
            "Epoch: 13/40... Step: 1130... Loss: 1.8096... Val Loss: 1.6906\n",
            "Epoch: 13/40... Step: 1130... Loss: 1.8016... Val Loss: 1.7184\n",
            "Epoch: 13/40... Step: 1130... Loss: 1.5918... Val Loss: 1.6931\n",
            "Epoch: 13/40... Step: 1130... Loss: 1.5462... Val Loss: 1.6686\n",
            "Epoch: 13/40... Step: 1130... Loss: 1.3911... Val Loss: 1.6289\n",
            "Epoch: 13/40... Step: 1130... Loss: 1.5283... Val Loss: 1.6164\n",
            "Epoch: 13/40... Step: 1130... Loss: 1.5480... Val Loss: 1.6088\n",
            "Epoch: 13/40... Step: 1130... Loss: 1.5737... Val Loss: 1.6053\n",
            "Epoch: 13/40... Step: 1140... Loss: 1.6594... Val Loss: 1.6594\n",
            "Epoch: 13/40... Step: 1140... Loss: 1.6217... Val Loss: 1.6405\n",
            "Epoch: 13/40... Step: 1140... Loss: 1.8019... Val Loss: 1.6943\n",
            "Epoch: 13/40... Step: 1140... Loss: 1.8068... Val Loss: 1.7225\n",
            "Epoch: 13/40... Step: 1140... Loss: 1.6340... Val Loss: 1.7048\n",
            "Epoch: 13/40... Step: 1140... Loss: 1.5651... Val Loss: 1.6815\n",
            "Epoch: 13/40... Step: 1140... Loss: 1.4228... Val Loss: 1.6445\n",
            "Epoch: 13/40... Step: 1140... Loss: 1.5512... Val Loss: 1.6329\n",
            "Epoch: 13/40... Step: 1140... Loss: 1.5755... Val Loss: 1.6265\n",
            "Epoch: 13/40... Step: 1140... Loss: 1.5970... Val Loss: 1.6236\n",
            "Epoch: 13/40... Step: 1150... Loss: 1.6779... Val Loss: 1.6779\n",
            "Epoch: 13/40... Step: 1150... Loss: 1.6321... Val Loss: 1.6550\n",
            "Epoch: 13/40... Step: 1150... Loss: 1.8103... Val Loss: 1.7068\n",
            "Epoch: 13/40... Step: 1150... Loss: 1.7823... Val Loss: 1.7256\n",
            "Epoch: 13/40... Step: 1150... Loss: 1.6083... Val Loss: 1.7022\n",
            "Epoch: 13/40... Step: 1150... Loss: 1.5587... Val Loss: 1.6783\n",
            "Epoch: 13/40... Step: 1150... Loss: 1.4321... Val Loss: 1.6431\n",
            "Epoch: 13/40... Step: 1150... Loss: 1.5706... Val Loss: 1.6340\n",
            "Epoch: 13/40... Step: 1150... Loss: 1.5747... Val Loss: 1.6274\n",
            "Epoch: 13/40... Step: 1150... Loss: 1.5902... Val Loss: 1.6237\n",
            "Epoch: 13/40... Step: 1160... Loss: 1.6843... Val Loss: 1.6843\n",
            "Epoch: 13/40... Step: 1160... Loss: 1.6007... Val Loss: 1.6425\n",
            "Epoch: 13/40... Step: 1160... Loss: 1.8075... Val Loss: 1.6975\n",
            "Epoch: 13/40... Step: 1160... Loss: 1.8328... Val Loss: 1.7313\n",
            "Epoch: 13/40... Step: 1160... Loss: 1.6288... Val Loss: 1.7108\n",
            "Epoch: 13/40... Step: 1160... Loss: 1.5941... Val Loss: 1.6914\n",
            "Epoch: 13/40... Step: 1160... Loss: 1.4664... Val Loss: 1.6592\n",
            "Epoch: 13/40... Step: 1160... Loss: 1.5853... Val Loss: 1.6500\n",
            "Epoch: 13/40... Step: 1160... Loss: 1.5916... Val Loss: 1.6435\n",
            "Epoch: 13/40... Step: 1160... Loss: 1.6229... Val Loss: 1.6414\n",
            "Epoch: 13/40... Step: 1170... Loss: 1.6803... Val Loss: 1.6803\n",
            "Epoch: 13/40... Step: 1170... Loss: 1.6218... Val Loss: 1.6510\n",
            "Epoch: 13/40... Step: 1170... Loss: 1.8289... Val Loss: 1.7103\n",
            "Epoch: 13/40... Step: 1170... Loss: 1.8323... Val Loss: 1.7408\n",
            "Epoch: 13/40... Step: 1170... Loss: 1.6436... Val Loss: 1.7214\n",
            "Epoch: 13/40... Step: 1170... Loss: 1.6182... Val Loss: 1.7042\n",
            "Epoch: 13/40... Step: 1170... Loss: 1.4846... Val Loss: 1.6728\n",
            "Epoch: 13/40... Step: 1170... Loss: 1.5719... Val Loss: 1.6602\n",
            "Epoch: 13/40... Step: 1170... Loss: 1.5918... Val Loss: 1.6526\n",
            "Epoch: 13/40... Step: 1170... Loss: 1.6170... Val Loss: 1.6490\n",
            "Epoch: 13/40... Step: 1180... Loss: 1.6816... Val Loss: 1.6816\n",
            "Epoch: 13/40... Step: 1180... Loss: 1.6164... Val Loss: 1.6490\n",
            "Epoch: 13/40... Step: 1180... Loss: 1.8308... Val Loss: 1.7096\n",
            "Epoch: 13/40... Step: 1180... Loss: 1.8323... Val Loss: 1.7403\n",
            "Epoch: 13/40... Step: 1180... Loss: 1.6552... Val Loss: 1.7233\n",
            "Epoch: 13/40... Step: 1180... Loss: 1.6042... Val Loss: 1.7034\n",
            "Epoch: 13/40... Step: 1180... Loss: 1.4982... Val Loss: 1.6741\n",
            "Epoch: 13/40... Step: 1180... Loss: 1.5788... Val Loss: 1.6622\n",
            "Epoch: 13/40... Step: 1180... Loss: 1.5972... Val Loss: 1.6550\n",
            "Epoch: 13/40... Step: 1180... Loss: 1.6236... Val Loss: 1.6518\n",
            "Epoch: 13/40... Step: 1190... Loss: 1.6764... Val Loss: 1.6764\n",
            "Epoch: 13/40... Step: 1190... Loss: 1.6267... Val Loss: 1.6516\n",
            "Epoch: 13/40... Step: 1190... Loss: 1.8303... Val Loss: 1.7111\n",
            "Epoch: 13/40... Step: 1190... Loss: 1.8488... Val Loss: 1.7455\n",
            "Epoch: 13/40... Step: 1190... Loss: 1.6394... Val Loss: 1.7243\n",
            "Epoch: 13/40... Step: 1190... Loss: 1.6037... Val Loss: 1.7042\n",
            "Epoch: 13/40... Step: 1190... Loss: 1.4775... Val Loss: 1.6718\n",
            "Epoch: 13/40... Step: 1190... Loss: 1.5689... Val Loss: 1.6590\n",
            "Epoch: 13/40... Step: 1190... Loss: 1.6000... Val Loss: 1.6524\n",
            "Epoch: 13/40... Step: 1190... Loss: 1.6292... Val Loss: 1.6501\n",
            "Epoch: 14/40... Step: 1200... Loss: 1.6640... Val Loss: 1.6640\n",
            "Epoch: 14/40... Step: 1200... Loss: 1.5971... Val Loss: 1.6306\n",
            "Epoch: 14/40... Step: 1200... Loss: 1.8230... Val Loss: 1.6947\n",
            "Epoch: 14/40... Step: 1200... Loss: 1.8395... Val Loss: 1.7309\n",
            "Epoch: 14/40... Step: 1200... Loss: 1.6337... Val Loss: 1.7115\n",
            "Epoch: 14/40... Step: 1200... Loss: 1.5749... Val Loss: 1.6887\n",
            "Epoch: 14/40... Step: 1200... Loss: 1.4316... Val Loss: 1.6520\n",
            "Epoch: 14/40... Step: 1200... Loss: 1.5647... Val Loss: 1.6411\n",
            "Epoch: 14/40... Step: 1200... Loss: 1.5773... Val Loss: 1.6340\n",
            "Epoch: 14/40... Step: 1200... Loss: 1.5736... Val Loss: 1.6279\n",
            "Epoch: 14/40... Step: 1210... Loss: 1.6484... Val Loss: 1.6484\n",
            "Epoch: 14/40... Step: 1210... Loss: 1.6003... Val Loss: 1.6243\n",
            "Epoch: 14/40... Step: 1210... Loss: 1.7895... Val Loss: 1.6794\n",
            "Epoch: 14/40... Step: 1210... Loss: 1.8052... Val Loss: 1.7109\n",
            "Epoch: 14/40... Step: 1210... Loss: 1.5766... Val Loss: 1.6840\n",
            "Epoch: 14/40... Step: 1210... Loss: 1.5376... Val Loss: 1.6596\n",
            "Epoch: 14/40... Step: 1210... Loss: 1.3878... Val Loss: 1.6208\n",
            "Epoch: 14/40... Step: 1210... Loss: 1.5381... Val Loss: 1.6104\n",
            "Epoch: 14/40... Step: 1210... Loss: 1.5451... Val Loss: 1.6032\n",
            "Epoch: 14/40... Step: 1210... Loss: 1.5922... Val Loss: 1.6021\n",
            "Epoch: 14/40... Step: 1220... Loss: 1.6430... Val Loss: 1.6430\n",
            "Epoch: 14/40... Step: 1220... Loss: 1.5609... Val Loss: 1.6019\n",
            "Epoch: 14/40... Step: 1220... Loss: 1.7681... Val Loss: 1.6573\n",
            "Epoch: 14/40... Step: 1220... Loss: 1.7655... Val Loss: 1.6844\n",
            "Epoch: 14/40... Step: 1220... Loss: 1.5856... Val Loss: 1.6646\n",
            "Epoch: 14/40... Step: 1220... Loss: 1.5185... Val Loss: 1.6403\n",
            "Epoch: 14/40... Step: 1220... Loss: 1.3875... Val Loss: 1.6042\n",
            "Epoch: 14/40... Step: 1220... Loss: 1.5210... Val Loss: 1.5938\n",
            "Epoch: 14/40... Step: 1220... Loss: 1.5320... Val Loss: 1.5869\n",
            "Epoch: 14/40... Step: 1220... Loss: 1.5505... Val Loss: 1.5833\n",
            "Epoch: 14/40... Step: 1230... Loss: 1.6363... Val Loss: 1.6363\n",
            "Epoch: 14/40... Step: 1230... Loss: 1.5755... Val Loss: 1.6059\n",
            "Epoch: 14/40... Step: 1230... Loss: 1.7934... Val Loss: 1.6684\n",
            "Epoch: 14/40... Step: 1230... Loss: 1.7691... Val Loss: 1.6936\n",
            "Epoch: 14/40... Step: 1230... Loss: 1.5927... Val Loss: 1.6734\n",
            "Epoch: 14/40... Step: 1230... Loss: 1.5344... Val Loss: 1.6502\n",
            "Epoch: 14/40... Step: 1230... Loss: 1.3860... Val Loss: 1.6125\n",
            "Epoch: 14/40... Step: 1230... Loss: 1.5277... Val Loss: 1.6019\n",
            "Epoch: 14/40... Step: 1230... Loss: 1.5376... Val Loss: 1.5947\n",
            "Epoch: 14/40... Step: 1230... Loss: 1.5898... Val Loss: 1.5942\n",
            "Epoch: 14/40... Step: 1240... Loss: 1.6484... Val Loss: 1.6484\n",
            "Epoch: 14/40... Step: 1240... Loss: 1.5850... Val Loss: 1.6167\n",
            "Epoch: 14/40... Step: 1240... Loss: 1.7833... Val Loss: 1.6722\n",
            "Epoch: 14/40... Step: 1240... Loss: 1.7924... Val Loss: 1.7023\n",
            "Epoch: 14/40... Step: 1240... Loss: 1.5743... Val Loss: 1.6767\n",
            "Epoch: 14/40... Step: 1240... Loss: 1.5544... Val Loss: 1.6563\n",
            "Epoch: 14/40... Step: 1240... Loss: 1.4305... Val Loss: 1.6241\n",
            "Epoch: 14/40... Step: 1240... Loss: 1.5567... Val Loss: 1.6156\n",
            "Epoch: 14/40... Step: 1240... Loss: 1.5471... Val Loss: 1.6080\n",
            "Epoch: 14/40... Step: 1240... Loss: 1.5763... Val Loss: 1.6048\n",
            "Epoch: 14/40... Step: 1250... Loss: 1.6547... Val Loss: 1.6547\n",
            "Epoch: 14/40... Step: 1250... Loss: 1.5852... Val Loss: 1.6199\n",
            "Epoch: 14/40... Step: 1250... Loss: 1.7991... Val Loss: 1.6796\n",
            "Epoch: 14/40... Step: 1250... Loss: 1.7978... Val Loss: 1.7092\n",
            "Epoch: 14/40... Step: 1250... Loss: 1.5797... Val Loss: 1.6833\n",
            "Epoch: 14/40... Step: 1250... Loss: 1.5577... Val Loss: 1.6624\n",
            "Epoch: 14/40... Step: 1250... Loss: 1.4459... Val Loss: 1.6314\n",
            "Epoch: 14/40... Step: 1250... Loss: 1.5601... Val Loss: 1.6225\n",
            "Epoch: 14/40... Step: 1250... Loss: 1.5645... Val Loss: 1.6161\n",
            "Epoch: 14/40... Step: 1250... Loss: 1.5890... Val Loss: 1.6134\n",
            "Epoch: 14/40... Step: 1260... Loss: 1.6578... Val Loss: 1.6578\n",
            "Epoch: 14/40... Step: 1260... Loss: 1.5891... Val Loss: 1.6235\n",
            "Epoch: 14/40... Step: 1260... Loss: 1.8325... Val Loss: 1.6931\n",
            "Epoch: 14/40... Step: 1260... Loss: 1.7940... Val Loss: 1.7183\n",
            "Epoch: 14/40... Step: 1260... Loss: 1.6172... Val Loss: 1.6981\n",
            "Epoch: 14/40... Step: 1260... Loss: 1.5747... Val Loss: 1.6775\n",
            "Epoch: 14/40... Step: 1260... Loss: 1.4546... Val Loss: 1.6457\n",
            "Epoch: 14/40... Step: 1260... Loss: 1.5485... Val Loss: 1.6335\n",
            "Epoch: 14/40... Step: 1260... Loss: 1.5580... Val Loss: 1.6251\n",
            "Epoch: 14/40... Step: 1260... Loss: 1.6019... Val Loss: 1.6228\n",
            "Epoch: 14/40... Step: 1270... Loss: 1.6672... Val Loss: 1.6672\n",
            "Epoch: 14/40... Step: 1270... Loss: 1.5980... Val Loss: 1.6326\n",
            "Epoch: 14/40... Step: 1270... Loss: 1.7926... Val Loss: 1.6859\n",
            "Epoch: 14/40... Step: 1270... Loss: 1.8246... Val Loss: 1.7206\n",
            "Epoch: 14/40... Step: 1270... Loss: 1.6313... Val Loss: 1.7027\n",
            "Epoch: 14/40... Step: 1270... Loss: 1.5922... Val Loss: 1.6843\n",
            "Epoch: 14/40... Step: 1270... Loss: 1.4747... Val Loss: 1.6544\n",
            "Epoch: 14/40... Step: 1270... Loss: 1.5576... Val Loss: 1.6423\n",
            "Epoch: 14/40... Step: 1270... Loss: 1.6134... Val Loss: 1.6391\n",
            "Epoch: 14/40... Step: 1270... Loss: 1.5957... Val Loss: 1.6347\n",
            "Epoch: 14/40... Step: 1280... Loss: 1.6461... Val Loss: 1.6461\n",
            "Epoch: 14/40... Step: 1280... Loss: 1.5903... Val Loss: 1.6182\n",
            "Epoch: 14/40... Step: 1280... Loss: 1.7783... Val Loss: 1.6716\n",
            "Epoch: 14/40... Step: 1280... Loss: 1.8182... Val Loss: 1.7082\n",
            "Epoch: 14/40... Step: 1280... Loss: 1.6077... Val Loss: 1.6881\n",
            "Epoch: 14/40... Step: 1280... Loss: 1.5904... Val Loss: 1.6718\n",
            "Epoch: 14/40... Step: 1280... Loss: 1.4650... Val Loss: 1.6423\n",
            "Epoch: 14/40... Step: 1280... Loss: 1.5518... Val Loss: 1.6310\n",
            "Epoch: 14/40... Step: 1280... Loss: 1.5740... Val Loss: 1.6246\n",
            "Epoch: 14/40... Step: 1280... Loss: 1.5893... Val Loss: 1.6211\n",
            "Epoch: 15/40... Step: 1290... Loss: 1.6568... Val Loss: 1.6568\n",
            "Epoch: 15/40... Step: 1290... Loss: 1.6116... Val Loss: 1.6342\n",
            "Epoch: 15/40... Step: 1290... Loss: 1.8136... Val Loss: 1.6940\n",
            "Epoch: 15/40... Step: 1290... Loss: 1.8045... Val Loss: 1.7216\n",
            "Epoch: 15/40... Step: 1290... Loss: 1.5943... Val Loss: 1.6962\n",
            "Epoch: 15/40... Step: 1290... Loss: 1.5604... Val Loss: 1.6735\n",
            "Epoch: 15/40... Step: 1290... Loss: 1.4189... Val Loss: 1.6372\n",
            "Epoch: 15/40... Step: 1290... Loss: 1.5488... Val Loss: 1.6261\n",
            "Epoch: 15/40... Step: 1290... Loss: 1.5595... Val Loss: 1.6187\n",
            "Epoch: 15/40... Step: 1290... Loss: 1.5743... Val Loss: 1.6143\n",
            "Epoch: 15/40... Step: 1300... Loss: 1.6352... Val Loss: 1.6352\n",
            "Epoch: 15/40... Step: 1300... Loss: 1.5745... Val Loss: 1.6048\n",
            "Epoch: 15/40... Step: 1300... Loss: 1.8039... Val Loss: 1.6712\n",
            "Epoch: 15/40... Step: 1300... Loss: 1.7951... Val Loss: 1.7022\n",
            "Epoch: 15/40... Step: 1300... Loss: 1.5755... Val Loss: 1.6769\n",
            "Epoch: 15/40... Step: 1300... Loss: 1.5517... Val Loss: 1.6560\n",
            "Epoch: 15/40... Step: 1300... Loss: 1.4040... Val Loss: 1.6200\n",
            "Epoch: 15/40... Step: 1300... Loss: 1.5461... Val Loss: 1.6108\n",
            "Epoch: 15/40... Step: 1300... Loss: 1.5366... Val Loss: 1.6025\n",
            "Epoch: 15/40... Step: 1300... Loss: 1.5607... Val Loss: 1.5983\n",
            "Epoch: 15/40... Step: 1310... Loss: 1.6177... Val Loss: 1.6177\n",
            "Epoch: 15/40... Step: 1310... Loss: 1.5440... Val Loss: 1.5808\n",
            "Epoch: 15/40... Step: 1310... Loss: 1.7831... Val Loss: 1.6483\n",
            "Epoch: 15/40... Step: 1310... Loss: 1.7599... Val Loss: 1.6762\n",
            "Epoch: 15/40... Step: 1310... Loss: 1.5812... Val Loss: 1.6572\n",
            "Epoch: 15/40... Step: 1310... Loss: 1.5208... Val Loss: 1.6345\n",
            "Epoch: 15/40... Step: 1310... Loss: 1.3934... Val Loss: 1.6000\n",
            "Epoch: 15/40... Step: 1310... Loss: 1.5355... Val Loss: 1.5920\n",
            "Epoch: 15/40... Step: 1310... Loss: 1.5238... Val Loss: 1.5844\n",
            "Epoch: 15/40... Step: 1310... Loss: 1.5537... Val Loss: 1.5813\n",
            "Epoch: 15/40... Step: 1320... Loss: 1.6201... Val Loss: 1.6201\n",
            "Epoch: 15/40... Step: 1320... Loss: 1.5494... Val Loss: 1.5847\n",
            "Epoch: 15/40... Step: 1320... Loss: 1.7595... Val Loss: 1.6430\n",
            "Epoch: 15/40... Step: 1320... Loss: 1.7555... Val Loss: 1.6711\n",
            "Epoch: 15/40... Step: 1320... Loss: 1.5668... Val Loss: 1.6503\n",
            "Epoch: 15/40... Step: 1320... Loss: 1.5119... Val Loss: 1.6272\n",
            "Epoch: 15/40... Step: 1320... Loss: 1.3754... Val Loss: 1.5912\n",
            "Epoch: 15/40... Step: 1320... Loss: 1.5014... Val Loss: 1.5800\n",
            "Epoch: 15/40... Step: 1320... Loss: 1.5063... Val Loss: 1.5718\n",
            "Epoch: 15/40... Step: 1320... Loss: 1.5374... Val Loss: 1.5684\n",
            "Epoch: 15/40... Step: 1330... Loss: 1.6262... Val Loss: 1.6262\n",
            "Epoch: 15/40... Step: 1330... Loss: 1.5707... Val Loss: 1.5985\n",
            "Epoch: 15/40... Step: 1330... Loss: 1.7727... Val Loss: 1.6565\n",
            "Epoch: 15/40... Step: 1330... Loss: 1.7705... Val Loss: 1.6850\n",
            "Epoch: 15/40... Step: 1330... Loss: 1.5969... Val Loss: 1.6674\n",
            "Epoch: 15/40... Step: 1330... Loss: 1.5326... Val Loss: 1.6449\n",
            "Epoch: 15/40... Step: 1330... Loss: 1.4067... Val Loss: 1.6109\n",
            "Epoch: 15/40... Step: 1330... Loss: 1.5256... Val Loss: 1.6002\n",
            "Epoch: 15/40... Step: 1330... Loss: 1.5320... Val Loss: 1.5927\n",
            "Epoch: 15/40... Step: 1330... Loss: 1.5810... Val Loss: 1.5915\n",
            "Epoch: 15/40... Step: 1340... Loss: 1.6385... Val Loss: 1.6385\n",
            "Epoch: 15/40... Step: 1340... Loss: 1.5741... Val Loss: 1.6063\n",
            "Epoch: 15/40... Step: 1340... Loss: 1.7773... Val Loss: 1.6633\n",
            "Epoch: 15/40... Step: 1340... Loss: 1.7724... Val Loss: 1.6906\n",
            "Epoch: 15/40... Step: 1340... Loss: 1.5839... Val Loss: 1.6692\n",
            "Epoch: 15/40... Step: 1340... Loss: 1.5535... Val Loss: 1.6499\n",
            "Epoch: 15/40... Step: 1340... Loss: 1.4363... Val Loss: 1.6194\n",
            "Epoch: 15/40... Step: 1340... Loss: 1.5453... Val Loss: 1.6102\n",
            "Epoch: 15/40... Step: 1340... Loss: 1.5369... Val Loss: 1.6020\n",
            "Epoch: 15/40... Step: 1340... Loss: 1.5586... Val Loss: 1.5977\n",
            "Epoch: 15/40... Step: 1350... Loss: 1.6403... Val Loss: 1.6403\n",
            "Epoch: 15/40... Step: 1350... Loss: 1.5743... Val Loss: 1.6073\n",
            "Epoch: 15/40... Step: 1350... Loss: 1.7861... Val Loss: 1.6669\n",
            "Epoch: 15/40... Step: 1350... Loss: 1.7959... Val Loss: 1.6991\n",
            "Epoch: 15/40... Step: 1350... Loss: 1.5676... Val Loss: 1.6728\n",
            "Epoch: 15/40... Step: 1350... Loss: 1.5631... Val Loss: 1.6545\n",
            "Epoch: 15/40... Step: 1350... Loss: 1.4788... Val Loss: 1.6294\n",
            "Epoch: 15/40... Step: 1350... Loss: 1.5604... Val Loss: 1.6208\n",
            "Epoch: 15/40... Step: 1350... Loss: 1.5533... Val Loss: 1.6133\n",
            "Epoch: 15/40... Step: 1350... Loss: 1.5771... Val Loss: 1.6097\n",
            "Epoch: 15/40... Step: 1360... Loss: 1.6526... Val Loss: 1.6526\n",
            "Epoch: 15/40... Step: 1360... Loss: 1.6172... Val Loss: 1.6349\n",
            "Epoch: 15/40... Step: 1360... Loss: 1.8016... Val Loss: 1.6905\n",
            "Epoch: 15/40... Step: 1360... Loss: 1.8007... Val Loss: 1.7180\n",
            "Epoch: 15/40... Step: 1360... Loss: 1.6046... Val Loss: 1.6953\n",
            "Epoch: 15/40... Step: 1360... Loss: 1.5704... Val Loss: 1.6745\n",
            "Epoch: 15/40... Step: 1360... Loss: 1.4410... Val Loss: 1.6412\n",
            "Epoch: 15/40... Step: 1360... Loss: 1.5530... Val Loss: 1.6301\n",
            "Epoch: 15/40... Step: 1360... Loss: 1.5685... Val Loss: 1.6233\n",
            "Epoch: 15/40... Step: 1360... Loss: 1.6102... Val Loss: 1.6220\n",
            "Epoch: 15/40... Step: 1370... Loss: 1.6249... Val Loss: 1.6249\n",
            "Epoch: 15/40... Step: 1370... Loss: 1.5895... Val Loss: 1.6072\n",
            "Epoch: 15/40... Step: 1370... Loss: 1.7810... Val Loss: 1.6652\n",
            "Epoch: 15/40... Step: 1370... Loss: 1.8106... Val Loss: 1.7015\n",
            "Epoch: 15/40... Step: 1370... Loss: 1.6041... Val Loss: 1.6820\n",
            "Epoch: 15/40... Step: 1370... Loss: 1.5610... Val Loss: 1.6619\n",
            "Epoch: 15/40... Step: 1370... Loss: 1.4565... Val Loss: 1.6325\n",
            "Epoch: 15/40... Step: 1370... Loss: 1.5457... Val Loss: 1.6217\n",
            "Epoch: 15/40... Step: 1370... Loss: 1.5624... Val Loss: 1.6151\n",
            "Epoch: 15/40... Step: 1370... Loss: 1.5776... Val Loss: 1.6113\n",
            "Epoch: 15/40... Step: 1380... Loss: 1.6369... Val Loss: 1.6369\n",
            "Epoch: 15/40... Step: 1380... Loss: 1.5690... Val Loss: 1.6030\n",
            "Epoch: 15/40... Step: 1380... Loss: 1.7860... Val Loss: 1.6640\n",
            "Epoch: 15/40... Step: 1380... Loss: 1.7863... Val Loss: 1.6946\n",
            "Epoch: 15/40... Step: 1380... Loss: 1.6168... Val Loss: 1.6790\n",
            "Epoch: 15/40... Step: 1380... Loss: 1.5423... Val Loss: 1.6562\n",
            "Epoch: 15/40... Step: 1380... Loss: 1.4162... Val Loss: 1.6219\n",
            "Epoch: 15/40... Step: 1380... Loss: 1.5353... Val Loss: 1.6111\n",
            "Epoch: 15/40... Step: 1380... Loss: 1.5524... Val Loss: 1.6046\n",
            "Epoch: 15/40... Step: 1380... Loss: 1.5583... Val Loss: 1.6000\n",
            "Epoch: 16/40... Step: 1390... Loss: 1.6090... Val Loss: 1.6090\n",
            "Epoch: 16/40... Step: 1390... Loss: 1.5733... Val Loss: 1.5912\n",
            "Epoch: 16/40... Step: 1390... Loss: 1.7831... Val Loss: 1.6552\n",
            "Epoch: 16/40... Step: 1390... Loss: 1.7899... Val Loss: 1.6888\n",
            "Epoch: 16/40... Step: 1390... Loss: 1.5772... Val Loss: 1.6665\n",
            "Epoch: 16/40... Step: 1390... Loss: 1.5181... Val Loss: 1.6418\n",
            "Epoch: 16/40... Step: 1390... Loss: 1.3707... Val Loss: 1.6030\n",
            "Epoch: 16/40... Step: 1390... Loss: 1.4819... Val Loss: 1.5879\n",
            "Epoch: 16/40... Step: 1390... Loss: 1.5166... Val Loss: 1.5800\n",
            "Epoch: 16/40... Step: 1390... Loss: 1.5576... Val Loss: 1.5778\n",
            "Epoch: 16/40... Step: 1400... Loss: 1.5974... Val Loss: 1.5974\n",
            "Epoch: 16/40... Step: 1400... Loss: 1.5332... Val Loss: 1.5653\n",
            "Epoch: 16/40... Step: 1400... Loss: 1.7603... Val Loss: 1.6303\n",
            "Epoch: 16/40... Step: 1400... Loss: 1.7292... Val Loss: 1.6550\n",
            "Epoch: 16/40... Step: 1400... Loss: 1.5644... Val Loss: 1.6369\n",
            "Epoch: 16/40... Step: 1400... Loss: 1.5066... Val Loss: 1.6152\n",
            "Epoch: 16/40... Step: 1400... Loss: 1.3740... Val Loss: 1.5807\n",
            "Epoch: 16/40... Step: 1400... Loss: 1.4852... Val Loss: 1.5688\n",
            "Epoch: 16/40... Step: 1400... Loss: 1.5166... Val Loss: 1.5630\n",
            "Epoch: 16/40... Step: 1400... Loss: 1.5295... Val Loss: 1.5596\n",
            "Epoch: 16/40... Step: 1410... Loss: 1.6066... Val Loss: 1.6066\n",
            "Epoch: 16/40... Step: 1410... Loss: 1.5437... Val Loss: 1.5752\n",
            "Epoch: 16/40... Step: 1410... Loss: 1.7711... Val Loss: 1.6405\n",
            "Epoch: 16/40... Step: 1410... Loss: 1.7483... Val Loss: 1.6674\n",
            "Epoch: 16/40... Step: 1410... Loss: 1.5507... Val Loss: 1.6441\n",
            "Epoch: 16/40... Step: 1410... Loss: 1.5047... Val Loss: 1.6208\n",
            "Epoch: 16/40... Step: 1410... Loss: 1.3643... Val Loss: 1.5842\n",
            "Epoch: 16/40... Step: 1410... Loss: 1.4929... Val Loss: 1.5728\n",
            "Epoch: 16/40... Step: 1410... Loss: 1.5174... Val Loss: 1.5666\n",
            "Epoch: 16/40... Step: 1410... Loss: 1.5286... Val Loss: 1.5628\n",
            "Epoch: 16/40... Step: 1420... Loss: 1.5979... Val Loss: 1.5979\n",
            "Epoch: 16/40... Step: 1420... Loss: 1.5509... Val Loss: 1.5744\n",
            "Epoch: 16/40... Step: 1420... Loss: 1.7510... Val Loss: 1.6332\n",
            "Epoch: 16/40... Step: 1420... Loss: 1.7775... Val Loss: 1.6693\n",
            "Epoch: 16/40... Step: 1420... Loss: 1.5541... Val Loss: 1.6463\n",
            "Epoch: 16/40... Step: 1420... Loss: 1.5295... Val Loss: 1.6268\n",
            "Epoch: 16/40... Step: 1420... Loss: 1.3938... Val Loss: 1.5935\n",
            "Epoch: 16/40... Step: 1420... Loss: 1.4875... Val Loss: 1.5803\n",
            "Epoch: 16/40... Step: 1420... Loss: 1.4923... Val Loss: 1.5705\n",
            "Epoch: 16/40... Step: 1420... Loss: 1.5562... Val Loss: 1.5691\n",
            "Epoch: 16/40... Step: 1430... Loss: 1.6156... Val Loss: 1.6156\n",
            "Epoch: 16/40... Step: 1430... Loss: 1.5552... Val Loss: 1.5854\n",
            "Epoch: 16/40... Step: 1430... Loss: 1.7518... Val Loss: 1.6408\n",
            "Epoch: 16/40... Step: 1430... Loss: 1.7818... Val Loss: 1.6761\n",
            "Epoch: 16/40... Step: 1430... Loss: 1.5747... Val Loss: 1.6558\n",
            "Epoch: 16/40... Step: 1430... Loss: 1.5386... Val Loss: 1.6363\n",
            "Epoch: 16/40... Step: 1430... Loss: 1.4250... Val Loss: 1.6061\n",
            "Epoch: 16/40... Step: 1430... Loss: 1.5330... Val Loss: 1.5970\n",
            "Epoch: 16/40... Step: 1430... Loss: 1.5562... Val Loss: 1.5924\n",
            "Epoch: 16/40... Step: 1430... Loss: 1.5709... Val Loss: 1.5903\n",
            "Epoch: 16/40... Step: 1440... Loss: 1.6219... Val Loss: 1.6219\n",
            "Epoch: 16/40... Step: 1440... Loss: 1.5651... Val Loss: 1.5935\n",
            "Epoch: 16/40... Step: 1440... Loss: 1.7766... Val Loss: 1.6545\n",
            "Epoch: 16/40... Step: 1440... Loss: 1.7886... Val Loss: 1.6881\n",
            "Epoch: 16/40... Step: 1440... Loss: 1.5841... Val Loss: 1.6673\n",
            "Epoch: 16/40... Step: 1440... Loss: 1.5283... Val Loss: 1.6441\n",
            "Epoch: 16/40... Step: 1440... Loss: 1.4450... Val Loss: 1.6157\n",
            "Epoch: 16/40... Step: 1440... Loss: 1.5419... Val Loss: 1.6064\n",
            "Epoch: 16/40... Step: 1440... Loss: 1.5441... Val Loss: 1.5995\n",
            "Epoch: 16/40... Step: 1440... Loss: 1.5967... Val Loss: 1.5992\n",
            "Epoch: 16/40... Step: 1450... Loss: 1.6296... Val Loss: 1.6296\n",
            "Epoch: 16/40... Step: 1450... Loss: 1.5782... Val Loss: 1.6039\n",
            "Epoch: 16/40... Step: 1450... Loss: 1.7828... Val Loss: 1.6635\n",
            "Epoch: 16/40... Step: 1450... Loss: 1.8238... Val Loss: 1.7036\n",
            "Epoch: 16/40... Step: 1450... Loss: 1.5846... Val Loss: 1.6798\n",
            "Epoch: 16/40... Step: 1450... Loss: 1.5732... Val Loss: 1.6620\n",
            "Epoch: 16/40... Step: 1450... Loss: 1.4410... Val Loss: 1.6305\n",
            "Epoch: 16/40... Step: 1450... Loss: 1.5264... Val Loss: 1.6174\n",
            "Epoch: 16/40... Step: 1450... Loss: 1.5308... Val Loss: 1.6078\n",
            "Epoch: 16/40... Step: 1450... Loss: 1.5870... Val Loss: 1.6057\n",
            "Epoch: 16/40... Step: 1460... Loss: 1.6125... Val Loss: 1.6125\n",
            "Epoch: 16/40... Step: 1460... Loss: 1.5766... Val Loss: 1.5945\n",
            "Epoch: 16/40... Step: 1460... Loss: 1.7485... Val Loss: 1.6459\n",
            "Epoch: 16/40... Step: 1460... Loss: 1.7883... Val Loss: 1.6815\n",
            "Epoch: 16/40... Step: 1460... Loss: 1.6033... Val Loss: 1.6658\n",
            "Epoch: 16/40... Step: 1460... Loss: 1.5494... Val Loss: 1.6464\n",
            "Epoch: 16/40... Step: 1460... Loss: 1.4568... Val Loss: 1.6193\n",
            "Epoch: 16/40... Step: 1460... Loss: 1.5234... Val Loss: 1.6073\n",
            "Epoch: 16/40... Step: 1460... Loss: 1.5413... Val Loss: 1.6000\n",
            "Epoch: 16/40... Step: 1460... Loss: 1.5657... Val Loss: 1.5966\n",
            "Epoch: 16/40... Step: 1470... Loss: 1.6221... Val Loss: 1.6221\n",
            "Epoch: 16/40... Step: 1470... Loss: 1.5501... Val Loss: 1.5861\n",
            "Epoch: 16/40... Step: 1470... Loss: 1.7796... Val Loss: 1.6506\n",
            "Epoch: 16/40... Step: 1470... Loss: 1.7907... Val Loss: 1.6856\n",
            "Epoch: 16/40... Step: 1470... Loss: 1.5805... Val Loss: 1.6646\n",
            "Epoch: 16/40... Step: 1470... Loss: 1.5446... Val Loss: 1.6446\n",
            "Epoch: 16/40... Step: 1470... Loss: 1.4096... Val Loss: 1.6110\n",
            "Epoch: 16/40... Step: 1470... Loss: 1.5220... Val Loss: 1.5999\n",
            "Epoch: 16/40... Step: 1470... Loss: 1.5216... Val Loss: 1.5912\n",
            "Epoch: 16/40... Step: 1470... Loss: 1.5497... Val Loss: 1.5871\n",
            "Epoch: 17/40... Step: 1480... Loss: 1.6072... Val Loss: 1.6072\n",
            "Epoch: 17/40... Step: 1480... Loss: 1.5651... Val Loss: 1.5861\n",
            "Epoch: 17/40... Step: 1480... Loss: 1.7970... Val Loss: 1.6564\n",
            "Epoch: 17/40... Step: 1480... Loss: 1.7703... Val Loss: 1.6849\n",
            "Epoch: 17/40... Step: 1480... Loss: 1.5544... Val Loss: 1.6588\n",
            "Epoch: 17/40... Step: 1480... Loss: 1.5213... Val Loss: 1.6359\n",
            "Epoch: 17/40... Step: 1480... Loss: 1.3805... Val Loss: 1.5994\n",
            "Epoch: 17/40... Step: 1480... Loss: 1.5078... Val Loss: 1.5879\n",
            "Epoch: 17/40... Step: 1480... Loss: 1.5084... Val Loss: 1.5791\n",
            "Epoch: 17/40... Step: 1480... Loss: 1.5415... Val Loss: 1.5753\n",
            "Epoch: 17/40... Step: 1490... Loss: 1.5898... Val Loss: 1.5898\n",
            "Epoch: 17/40... Step: 1490... Loss: 1.5061... Val Loss: 1.5480\n",
            "Epoch: 17/40... Step: 1490... Loss: 1.7308... Val Loss: 1.6089\n",
            "Epoch: 17/40... Step: 1490... Loss: 1.7603... Val Loss: 1.6468\n",
            "Epoch: 17/40... Step: 1490... Loss: 1.5316... Val Loss: 1.6237\n",
            "Epoch: 17/40... Step: 1490... Loss: 1.5069... Val Loss: 1.6043\n",
            "Epoch: 17/40... Step: 1490... Loss: 1.3684... Val Loss: 1.5706\n",
            "Epoch: 17/40... Step: 1490... Loss: 1.4794... Val Loss: 1.5592\n",
            "Epoch: 17/40... Step: 1490... Loss: 1.4946... Val Loss: 1.5520\n",
            "Epoch: 17/40... Step: 1490... Loss: 1.5512... Val Loss: 1.5519\n",
            "Epoch: 17/40... Step: 1500... Loss: 1.5928... Val Loss: 1.5928\n",
            "Epoch: 17/40... Step: 1500... Loss: 1.5011... Val Loss: 1.5469\n",
            "Epoch: 17/40... Step: 1500... Loss: 1.7398... Val Loss: 1.6112\n",
            "Epoch: 17/40... Step: 1500... Loss: 1.7397... Val Loss: 1.6433\n",
            "Epoch: 17/40... Step: 1500... Loss: 1.5187... Val Loss: 1.6184\n",
            "Epoch: 17/40... Step: 1500... Loss: 1.4811... Val Loss: 1.5955\n",
            "Epoch: 17/40... Step: 1500... Loss: 1.3531... Val Loss: 1.5609\n",
            "Epoch: 17/40... Step: 1500... Loss: 1.4620... Val Loss: 1.5485\n",
            "Epoch: 17/40... Step: 1500... Loss: 1.4850... Val Loss: 1.5415\n",
            "Epoch: 17/40... Step: 1500... Loss: 1.5488... Val Loss: 1.5422\n",
            "Epoch: 17/40... Step: 1510... Loss: 1.5807... Val Loss: 1.5807\n",
            "Epoch: 17/40... Step: 1510... Loss: 1.5329... Val Loss: 1.5568\n",
            "Epoch: 17/40... Step: 1510... Loss: 1.7476... Val Loss: 1.6204\n",
            "Epoch: 17/40... Step: 1510... Loss: 1.7758... Val Loss: 1.6593\n",
            "Epoch: 17/40... Step: 1510... Loss: 1.5510... Val Loss: 1.6376\n",
            "Epoch: 17/40... Step: 1510... Loss: 1.5173... Val Loss: 1.6176\n",
            "Epoch: 17/40... Step: 1510... Loss: 1.3847... Val Loss: 1.5843\n",
            "Epoch: 17/40... Step: 1510... Loss: 1.5417... Val Loss: 1.5790\n",
            "Epoch: 17/40... Step: 1510... Loss: 1.5083... Val Loss: 1.5711\n",
            "Epoch: 17/40... Step: 1510... Loss: 1.5369... Val Loss: 1.5677\n",
            "Epoch: 17/40... Step: 1520... Loss: 1.6016... Val Loss: 1.6016\n",
            "Epoch: 17/40... Step: 1520... Loss: 1.5334... Val Loss: 1.5675\n",
            "Epoch: 17/40... Step: 1520... Loss: 1.7632... Val Loss: 1.6327\n",
            "Epoch: 17/40... Step: 1520... Loss: 1.7504... Val Loss: 1.6621\n",
            "Epoch: 17/40... Step: 1520... Loss: 1.5534... Val Loss: 1.6404\n",
            "Epoch: 17/40... Step: 1520... Loss: 1.5431... Val Loss: 1.6242\n",
            "Epoch: 17/40... Step: 1520... Loss: 1.4143... Val Loss: 1.5942\n",
            "Epoch: 17/40... Step: 1520... Loss: 1.5110... Val Loss: 1.5838\n",
            "Epoch: 17/40... Step: 1520... Loss: 1.5292... Val Loss: 1.5777\n",
            "Epoch: 17/40... Step: 1520... Loss: 1.5720... Val Loss: 1.5771\n",
            "Epoch: 17/40... Step: 1530... Loss: 1.6177... Val Loss: 1.6177\n",
            "Epoch: 17/40... Step: 1530... Loss: 1.5583... Val Loss: 1.5880\n",
            "Epoch: 17/40... Step: 1530... Loss: 1.7587... Val Loss: 1.6449\n",
            "Epoch: 17/40... Step: 1530... Loss: 1.7912... Val Loss: 1.6815\n",
            "Epoch: 17/40... Step: 1530... Loss: 1.5775... Val Loss: 1.6607\n",
            "Epoch: 17/40... Step: 1530... Loss: 1.5372... Val Loss: 1.6401\n",
            "Epoch: 17/40... Step: 1530... Loss: 1.4265... Val Loss: 1.6096\n",
            "Epoch: 17/40... Step: 1530... Loss: 1.5072... Val Loss: 1.5968\n",
            "Epoch: 17/40... Step: 1530... Loss: 1.5327... Val Loss: 1.5897\n",
            "Epoch: 17/40... Step: 1530... Loss: 1.5874... Val Loss: 1.5895\n",
            "Epoch: 17/40... Step: 1540... Loss: 1.6057... Val Loss: 1.6057\n",
            "Epoch: 17/40... Step: 1540... Loss: 1.5409... Val Loss: 1.5733\n",
            "Epoch: 17/40... Step: 1540... Loss: 1.7858... Val Loss: 1.6441\n",
            "Epoch: 17/40... Step: 1540... Loss: 1.7963... Val Loss: 1.6821\n",
            "Epoch: 17/40... Step: 1540... Loss: 1.5757... Val Loss: 1.6609\n",
            "Epoch: 17/40... Step: 1540... Loss: 1.5754... Val Loss: 1.6466\n",
            "Epoch: 17/40... Step: 1540... Loss: 1.4077... Val Loss: 1.6125\n",
            "Epoch: 17/40... Step: 1540... Loss: 1.5153... Val Loss: 1.6003\n",
            "Epoch: 17/40... Step: 1540... Loss: 1.5220... Val Loss: 1.5916\n",
            "Epoch: 17/40... Step: 1540... Loss: 1.5571... Val Loss: 1.5882\n",
            "Epoch: 17/40... Step: 1550... Loss: 1.6101... Val Loss: 1.6101\n",
            "Epoch: 17/40... Step: 1550... Loss: 1.5624... Val Loss: 1.5863\n",
            "Epoch: 17/40... Step: 1550... Loss: 1.7867... Val Loss: 1.6531\n",
            "Epoch: 17/40... Step: 1550... Loss: 1.7932... Val Loss: 1.6881\n",
            "Epoch: 17/40... Step: 1550... Loss: 1.5996... Val Loss: 1.6704\n",
            "Epoch: 17/40... Step: 1550... Loss: 1.5549... Val Loss: 1.6512\n",
            "Epoch: 17/40... Step: 1550... Loss: 1.4328... Val Loss: 1.6200\n",
            "Epoch: 17/40... Step: 1550... Loss: 1.5275... Val Loss: 1.6084\n",
            "Epoch: 17/40... Step: 1550... Loss: 1.5228... Val Loss: 1.5989\n",
            "Epoch: 17/40... Step: 1550... Loss: 1.5749... Val Loss: 1.5965\n",
            "Epoch: 17/40... Step: 1560... Loss: 1.6001... Val Loss: 1.6001\n",
            "Epoch: 17/40... Step: 1560... Loss: 1.5605... Val Loss: 1.5803\n",
            "Epoch: 17/40... Step: 1560... Loss: 1.7459... Val Loss: 1.6355\n",
            "Epoch: 17/40... Step: 1560... Loss: 1.7851... Val Loss: 1.6729\n",
            "Epoch: 17/40... Step: 1560... Loss: 1.5647... Val Loss: 1.6512\n",
            "Epoch: 17/40... Step: 1560... Loss: 1.5305... Val Loss: 1.6311\n",
            "Epoch: 17/40... Step: 1560... Loss: 1.4183... Val Loss: 1.6007\n",
            "Epoch: 17/40... Step: 1560... Loss: 1.5072... Val Loss: 1.5890\n",
            "Epoch: 17/40... Step: 1560... Loss: 1.5267... Val Loss: 1.5821\n",
            "Epoch: 17/40... Step: 1560... Loss: 1.5401... Val Loss: 1.5779\n",
            "Epoch: 18/40... Step: 1570... Loss: 1.5914... Val Loss: 1.5914\n",
            "Epoch: 18/40... Step: 1570... Loss: 1.5465... Val Loss: 1.5690\n",
            "Epoch: 18/40... Step: 1570... Loss: 1.7793... Val Loss: 1.6391\n",
            "Epoch: 18/40... Step: 1570... Loss: 1.7773... Val Loss: 1.6737\n",
            "Epoch: 18/40... Step: 1570... Loss: 1.5804... Val Loss: 1.6550\n",
            "Epoch: 18/40... Step: 1570... Loss: 1.5261... Val Loss: 1.6335\n",
            "Epoch: 18/40... Step: 1570... Loss: 1.3759... Val Loss: 1.5967\n",
            "Epoch: 18/40... Step: 1570... Loss: 1.5082... Val Loss: 1.5857\n",
            "Epoch: 18/40... Step: 1570... Loss: 1.5013... Val Loss: 1.5763\n",
            "Epoch: 18/40... Step: 1570... Loss: 1.5463... Val Loss: 1.5733\n",
            "Epoch: 18/40... Step: 1580... Loss: 1.5733... Val Loss: 1.5733\n",
            "Epoch: 18/40... Step: 1580... Loss: 1.5037... Val Loss: 1.5385\n",
            "Epoch: 18/40... Step: 1580... Loss: 1.7458... Val Loss: 1.6076\n",
            "Epoch: 18/40... Step: 1580... Loss: 1.7713... Val Loss: 1.6485\n",
            "Epoch: 18/40... Step: 1580... Loss: 1.5353... Val Loss: 1.6259\n",
            "Epoch: 18/40... Step: 1580... Loss: 1.5172... Val Loss: 1.6078\n",
            "Epoch: 18/40... Step: 1580... Loss: 1.3584... Val Loss: 1.5721\n",
            "Epoch: 18/40... Step: 1580... Loss: 1.4744... Val Loss: 1.5599\n",
            "Epoch: 18/40... Step: 1580... Loss: 1.4926... Val Loss: 1.5524\n",
            "Epoch: 18/40... Step: 1580... Loss: 1.5509... Val Loss: 1.5523\n",
            "Epoch: 18/40... Step: 1590... Loss: 1.5720... Val Loss: 1.5720\n",
            "Epoch: 18/40... Step: 1590... Loss: 1.4998... Val Loss: 1.5359\n",
            "Epoch: 18/40... Step: 1590... Loss: 1.7388... Val Loss: 1.6035\n",
            "Epoch: 18/40... Step: 1590... Loss: 1.7109... Val Loss: 1.6304\n",
            "Epoch: 18/40... Step: 1590... Loss: 1.5181... Val Loss: 1.6079\n",
            "Epoch: 18/40... Step: 1590... Loss: 1.4643... Val Loss: 1.5840\n",
            "Epoch: 18/40... Step: 1590... Loss: 1.3312... Val Loss: 1.5479\n",
            "Epoch: 18/40... Step: 1590... Loss: 1.4662... Val Loss: 1.5377\n",
            "Epoch: 18/40... Step: 1590... Loss: 1.4819... Val Loss: 1.5315\n",
            "Epoch: 18/40... Step: 1590... Loss: 1.5103... Val Loss: 1.5294\n",
            "Epoch: 18/40... Step: 1600... Loss: 1.5702... Val Loss: 1.5702\n",
            "Epoch: 18/40... Step: 1600... Loss: 1.4969... Val Loss: 1.5335\n",
            "Epoch: 18/40... Step: 1600... Loss: 1.7282... Val Loss: 1.5984\n",
            "Epoch: 18/40... Step: 1600... Loss: 1.7385... Val Loss: 1.6335\n",
            "Epoch: 18/40... Step: 1600... Loss: 1.5372... Val Loss: 1.6142\n",
            "Epoch: 18/40... Step: 1600... Loss: 1.5075... Val Loss: 1.5964\n",
            "Epoch: 18/40... Step: 1600... Loss: 1.3618... Val Loss: 1.5629\n",
            "Epoch: 18/40... Step: 1600... Loss: 1.5052... Val Loss: 1.5557\n",
            "Epoch: 18/40... Step: 1600... Loss: 1.5100... Val Loss: 1.5506\n",
            "Epoch: 18/40... Step: 1600... Loss: 1.5064... Val Loss: 1.5462\n",
            "Epoch: 18/40... Step: 1610... Loss: 1.5812... Val Loss: 1.5812\n",
            "Epoch: 18/40... Step: 1610... Loss: 1.5662... Val Loss: 1.5737\n",
            "Epoch: 18/40... Step: 1610... Loss: 1.7434... Val Loss: 1.6303\n",
            "Epoch: 18/40... Step: 1610... Loss: 1.7398... Val Loss: 1.6576\n",
            "Epoch: 18/40... Step: 1610... Loss: 1.5493... Val Loss: 1.6360\n",
            "Epoch: 18/40... Step: 1610... Loss: 1.5041... Val Loss: 1.6140\n",
            "Epoch: 18/40... Step: 1610... Loss: 1.4005... Val Loss: 1.5835\n",
            "Epoch: 18/40... Step: 1610... Loss: 1.5006... Val Loss: 1.5731\n",
            "Epoch: 18/40... Step: 1610... Loss: 1.5098... Val Loss: 1.5661\n",
            "Epoch: 18/40... Step: 1610... Loss: 1.5540... Val Loss: 1.5649\n",
            "Epoch: 18/40... Step: 1620... Loss: 1.5903... Val Loss: 1.5903\n",
            "Epoch: 18/40... Step: 1620... Loss: 1.5563... Val Loss: 1.5733\n",
            "Epoch: 18/40... Step: 1620... Loss: 1.7389... Val Loss: 1.6285\n",
            "Epoch: 18/40... Step: 1620... Loss: 1.7784... Val Loss: 1.6660\n",
            "Epoch: 18/40... Step: 1620... Loss: 1.5532... Val Loss: 1.6435\n",
            "Epoch: 18/40... Step: 1620... Loss: 1.5359... Val Loss: 1.6255\n",
            "Epoch: 18/40... Step: 1620... Loss: 1.4242... Val Loss: 1.5968\n",
            "Epoch: 18/40... Step: 1620... Loss: 1.5038... Val Loss: 1.5851\n",
            "Epoch: 18/40... Step: 1620... Loss: 1.5122... Val Loss: 1.5770\n",
            "Epoch: 18/40... Step: 1620... Loss: 1.5449... Val Loss: 1.5738\n",
            "Epoch: 18/40... Step: 1630... Loss: 1.5867... Val Loss: 1.5867\n",
            "Epoch: 18/40... Step: 1630... Loss: 1.5505... Val Loss: 1.5686\n",
            "Epoch: 18/40... Step: 1630... Loss: 1.7302... Val Loss: 1.6225\n",
            "Epoch: 18/40... Step: 1630... Loss: 1.7690... Val Loss: 1.6591\n",
            "Epoch: 18/40... Step: 1630... Loss: 1.5670... Val Loss: 1.6407\n",
            "Epoch: 18/40... Step: 1630... Loss: 1.5504... Val Loss: 1.6256\n",
            "Epoch: 18/40... Step: 1630... Loss: 1.4109... Val Loss: 1.5950\n",
            "Epoch: 18/40... Step: 1630... Loss: 1.5287... Val Loss: 1.5867\n",
            "Epoch: 18/40... Step: 1630... Loss: 1.5127... Val Loss: 1.5785\n",
            "Epoch: 18/40... Step: 1630... Loss: 1.5736... Val Loss: 1.5780\n",
            "Epoch: 18/40... Step: 1640... Loss: 1.6094... Val Loss: 1.6094\n",
            "Epoch: 18/40... Step: 1640... Loss: 1.5738... Val Loss: 1.5916\n",
            "Epoch: 18/40... Step: 1640... Loss: 1.7484... Val Loss: 1.6439\n",
            "Epoch: 18/40... Step: 1640... Loss: 1.7833... Val Loss: 1.6787\n",
            "Epoch: 18/40... Step: 1640... Loss: 1.5773... Val Loss: 1.6584\n",
            "Epoch: 18/40... Step: 1640... Loss: 1.5284... Val Loss: 1.6368\n",
            "Epoch: 18/40... Step: 1640... Loss: 1.4239... Val Loss: 1.6064\n",
            "Epoch: 18/40... Step: 1640... Loss: 1.5273... Val Loss: 1.5965\n",
            "Epoch: 18/40... Step: 1640... Loss: 1.5231... Val Loss: 1.5883\n",
            "Epoch: 18/40... Step: 1640... Loss: 1.5467... Val Loss: 1.5842\n",
            "Epoch: 18/40... Step: 1650... Loss: 1.5873... Val Loss: 1.5873\n",
            "Epoch: 18/40... Step: 1650... Loss: 1.5351... Val Loss: 1.5612\n",
            "Epoch: 18/40... Step: 1650... Loss: 1.7326... Val Loss: 1.6183\n",
            "Epoch: 18/40... Step: 1650... Loss: 1.7926... Val Loss: 1.6619\n",
            "Epoch: 18/40... Step: 1650... Loss: 1.5695... Val Loss: 1.6434\n",
            "Epoch: 18/40... Step: 1650... Loss: 1.5457... Val Loss: 1.6271\n",
            "Epoch: 18/40... Step: 1650... Loss: 1.4110... Val Loss: 1.5962\n",
            "Epoch: 18/40... Step: 1650... Loss: 1.5210... Val Loss: 1.5868\n",
            "Epoch: 18/40... Step: 1650... Loss: 1.5247... Val Loss: 1.5799\n",
            "Epoch: 18/40... Step: 1650... Loss: 1.5607... Val Loss: 1.5780\n",
            "Epoch: 19/40... Step: 1660... Loss: 1.5844... Val Loss: 1.5844\n",
            "Epoch: 19/40... Step: 1660... Loss: 1.5148... Val Loss: 1.5496\n",
            "Epoch: 19/40... Step: 1660... Loss: 1.7463... Val Loss: 1.6151\n",
            "Epoch: 19/40... Step: 1660... Loss: 1.7470... Val Loss: 1.6481\n",
            "Epoch: 19/40... Step: 1660... Loss: 1.5627... Val Loss: 1.6310\n",
            "Epoch: 19/40... Step: 1660... Loss: 1.5223... Val Loss: 1.6129\n",
            "Epoch: 19/40... Step: 1660... Loss: 1.3894... Val Loss: 1.5810\n",
            "Epoch: 19/40... Step: 1660... Loss: 1.4868... Val Loss: 1.5692\n",
            "Epoch: 19/40... Step: 1660... Loss: 1.4965... Val Loss: 1.5611\n",
            "Epoch: 19/40... Step: 1660... Loss: 1.5309... Val Loss: 1.5581\n",
            "Epoch: 19/40... Step: 1670... Loss: 1.5654... Val Loss: 1.5654\n",
            "Epoch: 19/40... Step: 1670... Loss: 1.5307... Val Loss: 1.5480\n",
            "Epoch: 19/40... Step: 1670... Loss: 1.7534... Val Loss: 1.6165\n",
            "Epoch: 19/40... Step: 1670... Loss: 1.7763... Val Loss: 1.6564\n",
            "Epoch: 19/40... Step: 1670... Loss: 1.5395... Val Loss: 1.6331\n",
            "Epoch: 19/40... Step: 1670... Loss: 1.5080... Val Loss: 1.6122\n",
            "Epoch: 19/40... Step: 1670... Loss: 1.3600... Val Loss: 1.5762\n",
            "Epoch: 19/40... Step: 1670... Loss: 1.4725... Val Loss: 1.5632\n",
            "Epoch: 19/40... Step: 1670... Loss: 1.4796... Val Loss: 1.5539\n",
            "Epoch: 19/40... Step: 1670... Loss: 1.5575... Val Loss: 1.5543\n",
            "Epoch: 19/40... Step: 1680... Loss: 1.5524... Val Loss: 1.5524\n",
            "Epoch: 19/40... Step: 1680... Loss: 1.4937... Val Loss: 1.5230\n",
            "Epoch: 19/40... Step: 1680... Loss: 1.7299... Val Loss: 1.5920\n",
            "Epoch: 19/40... Step: 1680... Loss: 1.7164... Val Loss: 1.6231\n",
            "Epoch: 19/40... Step: 1680... Loss: 1.5323... Val Loss: 1.6049\n",
            "Epoch: 19/40... Step: 1680... Loss: 1.4609... Val Loss: 1.5809\n",
            "Epoch: 19/40... Step: 1680... Loss: 1.3385... Val Loss: 1.5463\n",
            "Epoch: 19/40... Step: 1680... Loss: 1.4593... Val Loss: 1.5354\n",
            "Epoch: 19/40... Step: 1680... Loss: 1.4720... Val Loss: 1.5284\n",
            "Epoch: 19/40... Step: 1680... Loss: 1.5159... Val Loss: 1.5271\n",
            "Epoch: 19/40... Step: 1690... Loss: 1.5625... Val Loss: 1.5625\n",
            "Epoch: 19/40... Step: 1690... Loss: 1.4855... Val Loss: 1.5240\n",
            "Epoch: 19/40... Step: 1690... Loss: 1.7168... Val Loss: 1.5883\n",
            "Epoch: 19/40... Step: 1690... Loss: 1.7388... Val Loss: 1.6259\n",
            "Epoch: 19/40... Step: 1690... Loss: 1.5069... Val Loss: 1.6021\n",
            "Epoch: 19/40... Step: 1690... Loss: 1.4892... Val Loss: 1.5833\n",
            "Epoch: 19/40... Step: 1690... Loss: 1.3482... Val Loss: 1.5497\n",
            "Epoch: 19/40... Step: 1690... Loss: 1.4773... Val Loss: 1.5407\n",
            "Epoch: 19/40... Step: 1690... Loss: 1.4759... Val Loss: 1.5335\n",
            "Epoch: 19/40... Step: 1690... Loss: 1.5108... Val Loss: 1.5312\n",
            "Epoch: 19/40... Step: 1700... Loss: 1.5665... Val Loss: 1.5665\n",
            "Epoch: 19/40... Step: 1700... Loss: 1.5452... Val Loss: 1.5559\n",
            "Epoch: 19/40... Step: 1700... Loss: 1.7371... Val Loss: 1.6163\n",
            "Epoch: 19/40... Step: 1700... Loss: 1.7736... Val Loss: 1.6556\n",
            "Epoch: 19/40... Step: 1700... Loss: 1.4940... Val Loss: 1.6233\n",
            "Epoch: 19/40... Step: 1700... Loss: 1.5241... Val Loss: 1.6068\n",
            "Epoch: 19/40... Step: 1700... Loss: 1.3894... Val Loss: 1.5757\n",
            "Epoch: 19/40... Step: 1700... Loss: 1.4973... Val Loss: 1.5659\n",
            "Epoch: 19/40... Step: 1700... Loss: 1.5003... Val Loss: 1.5586\n",
            "Epoch: 19/40... Step: 1700... Loss: 1.5506... Val Loss: 1.5578\n",
            "Epoch: 19/40... Step: 1710... Loss: 1.5778... Val Loss: 1.5778\n",
            "Epoch: 19/40... Step: 1710... Loss: 1.5120... Val Loss: 1.5449\n",
            "Epoch: 19/40... Step: 1710... Loss: 1.7304... Val Loss: 1.6067\n",
            "Epoch: 19/40... Step: 1710... Loss: 1.7526... Val Loss: 1.6432\n",
            "Epoch: 19/40... Step: 1710... Loss: 1.5187... Val Loss: 1.6183\n",
            "Epoch: 19/40... Step: 1710... Loss: 1.5269... Val Loss: 1.6031\n",
            "Epoch: 19/40... Step: 1710... Loss: 1.4022... Val Loss: 1.5744\n",
            "Epoch: 19/40... Step: 1710... Loss: 1.5177... Val Loss: 1.5673\n",
            "Epoch: 19/40... Step: 1710... Loss: 1.5076... Val Loss: 1.5607\n",
            "Epoch: 19/40... Step: 1710... Loss: 1.5454... Val Loss: 1.5591\n",
            "Epoch: 19/40... Step: 1720... Loss: 1.5781... Val Loss: 1.5781\n",
            "Epoch: 19/40... Step: 1720... Loss: 1.5263... Val Loss: 1.5522\n",
            "Epoch: 19/40... Step: 1720... Loss: 1.7477... Val Loss: 1.6173\n",
            "Epoch: 19/40... Step: 1720... Loss: 1.7866... Val Loss: 1.6596\n",
            "Epoch: 19/40... Step: 1720... Loss: 1.5534... Val Loss: 1.6384\n",
            "Epoch: 19/40... Step: 1720... Loss: 1.5202... Val Loss: 1.6187\n",
            "Epoch: 19/40... Step: 1720... Loss: 1.4027... Val Loss: 1.5878\n",
            "Epoch: 19/40... Step: 1720... Loss: 1.5143... Val Loss: 1.5786\n",
            "Epoch: 19/40... Step: 1720... Loss: 1.5155... Val Loss: 1.5716\n",
            "Epoch: 19/40... Step: 1720... Loss: 1.5588... Val Loss: 1.5703\n",
            "Epoch: 19/40... Step: 1730... Loss: 1.6092... Val Loss: 1.6092\n",
            "Epoch: 19/40... Step: 1730... Loss: 1.5525... Val Loss: 1.5809\n",
            "Epoch: 19/40... Step: 1730... Loss: 1.7576... Val Loss: 1.6398\n",
            "Epoch: 19/40... Step: 1730... Loss: 1.7785... Val Loss: 1.6744\n",
            "Epoch: 19/40... Step: 1730... Loss: 1.5683... Val Loss: 1.6532\n",
            "Epoch: 19/40... Step: 1730... Loss: 1.5635... Val Loss: 1.6383\n",
            "Epoch: 19/40... Step: 1730... Loss: 1.4070... Val Loss: 1.6052\n",
            "Epoch: 19/40... Step: 1730... Loss: 1.5195... Val Loss: 1.5945\n",
            "Epoch: 19/40... Step: 1730... Loss: 1.4932... Val Loss: 1.5833\n",
            "Epoch: 19/40... Step: 1730... Loss: 1.5435... Val Loss: 1.5793\n",
            "Epoch: 19/40... Step: 1740... Loss: 1.5754... Val Loss: 1.5754\n",
            "Epoch: 19/40... Step: 1740... Loss: 1.5171... Val Loss: 1.5463\n",
            "Epoch: 19/40... Step: 1740... Loss: 1.7393... Val Loss: 1.6106\n",
            "Epoch: 19/40... Step: 1740... Loss: 1.7608... Val Loss: 1.6481\n",
            "Epoch: 19/40... Step: 1740... Loss: 1.5451... Val Loss: 1.6275\n",
            "Epoch: 19/40... Step: 1740... Loss: 1.5097... Val Loss: 1.6079\n",
            "Epoch: 19/40... Step: 1740... Loss: 1.4391... Val Loss: 1.5838\n",
            "Epoch: 19/40... Step: 1740... Loss: 1.4999... Val Loss: 1.5733\n",
            "Epoch: 19/40... Step: 1740... Loss: 1.5040... Val Loss: 1.5656\n",
            "Epoch: 19/40... Step: 1740... Loss: 1.5375... Val Loss: 1.5628\n",
            "Epoch: 20/40... Step: 1750... Loss: 1.5902... Val Loss: 1.5902\n",
            "Epoch: 20/40... Step: 1750... Loss: 1.5381... Val Loss: 1.5642\n",
            "Epoch: 20/40... Step: 1750... Loss: 1.7404... Val Loss: 1.6229\n",
            "Epoch: 20/40... Step: 1750... Loss: 1.7721... Val Loss: 1.6602\n",
            "Epoch: 20/40... Step: 1750... Loss: 1.5562... Val Loss: 1.6394\n",
            "Epoch: 20/40... Step: 1750... Loss: 1.5174... Val Loss: 1.6191\n",
            "Epoch: 20/40... Step: 1750... Loss: 1.3847... Val Loss: 1.5856\n",
            "Epoch: 20/40... Step: 1750... Loss: 1.5026... Val Loss: 1.5752\n",
            "Epoch: 20/40... Step: 1750... Loss: 1.5299... Val Loss: 1.5702\n",
            "Epoch: 20/40... Step: 1750... Loss: 1.5290... Val Loss: 1.5661\n",
            "Epoch: 20/40... Step: 1760... Loss: 1.5577... Val Loss: 1.5577\n",
            "Epoch: 20/40... Step: 1760... Loss: 1.5022... Val Loss: 1.5299\n",
            "Epoch: 20/40... Step: 1760... Loss: 1.7264... Val Loss: 1.5954\n",
            "Epoch: 20/40... Step: 1760... Loss: 1.7480... Val Loss: 1.6336\n",
            "Epoch: 20/40... Step: 1760... Loss: 1.5374... Val Loss: 1.6143\n",
            "Epoch: 20/40... Step: 1760... Loss: 1.4900... Val Loss: 1.5936\n",
            "Epoch: 20/40... Step: 1760... Loss: 1.3566... Val Loss: 1.5598\n",
            "Epoch: 20/40... Step: 1760... Loss: 1.4531... Val Loss: 1.5464\n",
            "Epoch: 20/40... Step: 1760... Loss: 1.4599... Val Loss: 1.5368\n",
            "Epoch: 20/40... Step: 1760... Loss: 1.5551... Val Loss: 1.5386\n",
            "Epoch: 20/40... Step: 1770... Loss: 1.5514... Val Loss: 1.5514\n",
            "Epoch: 20/40... Step: 1770... Loss: 1.4850... Val Loss: 1.5182\n",
            "Epoch: 20/40... Step: 1770... Loss: 1.7148... Val Loss: 1.5837\n",
            "Epoch: 20/40... Step: 1770... Loss: 1.7133... Val Loss: 1.6161\n",
            "Epoch: 20/40... Step: 1770... Loss: 1.4898... Val Loss: 1.5909\n",
            "Epoch: 20/40... Step: 1770... Loss: 1.4622... Val Loss: 1.5694\n",
            "Epoch: 20/40... Step: 1770... Loss: 1.3398... Val Loss: 1.5366\n",
            "Epoch: 20/40... Step: 1770... Loss: 1.4697... Val Loss: 1.5282\n",
            "Epoch: 20/40... Step: 1770... Loss: 1.4716... Val Loss: 1.5219\n",
            "Epoch: 20/40... Step: 1770... Loss: 1.5152... Val Loss: 1.5213\n",
            "Epoch: 20/40... Step: 1780... Loss: 1.5608... Val Loss: 1.5608\n",
            "Epoch: 20/40... Step: 1780... Loss: 1.4782... Val Loss: 1.5195\n",
            "Epoch: 20/40... Step: 1780... Loss: 1.7233... Val Loss: 1.5874\n",
            "Epoch: 20/40... Step: 1780... Loss: 1.7260... Val Loss: 1.6221\n",
            "Epoch: 20/40... Step: 1780... Loss: 1.5149... Val Loss: 1.6006\n",
            "Epoch: 20/40... Step: 1780... Loss: 1.4557... Val Loss: 1.5765\n",
            "Epoch: 20/40... Step: 1780... Loss: 1.3463... Val Loss: 1.5436\n",
            "Epoch: 20/40... Step: 1780... Loss: 1.4611... Val Loss: 1.5333\n",
            "Epoch: 20/40... Step: 1780... Loss: 1.4851... Val Loss: 1.5279\n",
            "Epoch: 20/40... Step: 1780... Loss: 1.5097... Val Loss: 1.5261\n",
            "Epoch: 20/40... Step: 1790... Loss: 1.5532... Val Loss: 1.5532\n",
            "Epoch: 20/40... Step: 1790... Loss: 1.5171... Val Loss: 1.5351\n",
            "Epoch: 20/40... Step: 1790... Loss: 1.7277... Val Loss: 1.5993\n",
            "Epoch: 20/40... Step: 1790... Loss: 1.7369... Val Loss: 1.6337\n",
            "Epoch: 20/40... Step: 1790... Loss: 1.5001... Val Loss: 1.6070\n",
            "Epoch: 20/40... Step: 1790... Loss: 1.5260... Val Loss: 1.5935\n",
            "Epoch: 20/40... Step: 1790... Loss: 1.3817... Val Loss: 1.5632\n",
            "Epoch: 20/40... Step: 1790... Loss: 1.4967... Val Loss: 1.5549\n",
            "Epoch: 20/40... Step: 1790... Loss: 1.4878... Val Loss: 1.5474\n",
            "Epoch: 20/40... Step: 1790... Loss: 1.5197... Val Loss: 1.5447\n",
            "Epoch: 20/40... Step: 1800... Loss: 1.5580... Val Loss: 1.5580\n",
            "Epoch: 20/40... Step: 1800... Loss: 1.5213... Val Loss: 1.5396\n",
            "Epoch: 20/40... Step: 1800... Loss: 1.7211... Val Loss: 1.6001\n",
            "Epoch: 20/40... Step: 1800... Loss: 1.7245... Val Loss: 1.6312\n",
            "Epoch: 20/40... Step: 1800... Loss: 1.5024... Val Loss: 1.6055\n",
            "Epoch: 20/40... Step: 1800... Loss: 1.5071... Val Loss: 1.5891\n",
            "Epoch: 20/40... Step: 1800... Loss: 1.3833... Val Loss: 1.5597\n",
            "Epoch: 20/40... Step: 1800... Loss: 1.5158... Val Loss: 1.5542\n",
            "Epoch: 20/40... Step: 1800... Loss: 1.4867... Val Loss: 1.5467\n",
            "Epoch: 20/40... Step: 1800... Loss: 1.5606... Val Loss: 1.5481\n",
            "Epoch: 20/40... Step: 1810... Loss: 1.5680... Val Loss: 1.5680\n",
            "Epoch: 20/40... Step: 1810... Loss: 1.5279... Val Loss: 1.5480\n",
            "Epoch: 20/40... Step: 1810... Loss: 1.7164... Val Loss: 1.6041\n",
            "Epoch: 20/40... Step: 1810... Loss: 1.7483... Val Loss: 1.6402\n",
            "Epoch: 20/40... Step: 1810... Loss: 1.5411... Val Loss: 1.6203\n",
            "Epoch: 20/40... Step: 1810... Loss: 1.5407... Val Loss: 1.6071\n",
            "Epoch: 20/40... Step: 1810... Loss: 1.4209... Val Loss: 1.5805\n",
            "Epoch: 20/40... Step: 1810... Loss: 1.5096... Val Loss: 1.5716\n",
            "Epoch: 20/40... Step: 1810... Loss: 1.5091... Val Loss: 1.5647\n",
            "Epoch: 20/40... Step: 1810... Loss: 1.5282... Val Loss: 1.5610\n",
            "Epoch: 20/40... Step: 1820... Loss: 1.5736... Val Loss: 1.5736\n",
            "Epoch: 20/40... Step: 1820... Loss: 1.5365... Val Loss: 1.5551\n",
            "Epoch: 20/40... Step: 1820... Loss: 1.7517... Val Loss: 1.6206\n",
            "Epoch: 20/40... Step: 1820... Loss: 1.7647... Val Loss: 1.6566\n",
            "Epoch: 20/40... Step: 1820... Loss: 1.5464... Val Loss: 1.6346\n",
            "Epoch: 20/40... Step: 1820... Loss: 1.5547... Val Loss: 1.6213\n",
            "Epoch: 20/40... Step: 1820... Loss: 1.3778... Val Loss: 1.5865\n",
            "Epoch: 20/40... Step: 1820... Loss: 1.4894... Val Loss: 1.5744\n",
            "Epoch: 20/40... Step: 1820... Loss: 1.4949... Val Loss: 1.5655\n",
            "Epoch: 20/40... Step: 1820... Loss: 1.5595... Val Loss: 1.5649\n",
            "Epoch: 20/40... Step: 1830... Loss: 1.5577... Val Loss: 1.5577\n",
            "Epoch: 20/40... Step: 1830... Loss: 1.5364... Val Loss: 1.5471\n",
            "Epoch: 20/40... Step: 1830... Loss: 1.7162... Val Loss: 1.6034\n",
            "Epoch: 20/40... Step: 1830... Loss: 1.7473... Val Loss: 1.6394\n",
            "Epoch: 20/40... Step: 1830... Loss: 1.5470... Val Loss: 1.6209\n",
            "Epoch: 20/40... Step: 1830... Loss: 1.5026... Val Loss: 1.6012\n",
            "Epoch: 20/40... Step: 1830... Loss: 1.4001... Val Loss: 1.5725\n",
            "Epoch: 20/40... Step: 1830... Loss: 1.4926... Val Loss: 1.5625\n",
            "Epoch: 20/40... Step: 1830... Loss: 1.5011... Val Loss: 1.5557\n",
            "Epoch: 20/40... Step: 1830... Loss: 1.5288... Val Loss: 1.5530\n",
            "Epoch: 20/40... Step: 1840... Loss: 1.5801... Val Loss: 1.5801\n",
            "Epoch: 20/40... Step: 1840... Loss: 1.5251... Val Loss: 1.5526\n",
            "Epoch: 20/40... Step: 1840... Loss: 1.7529... Val Loss: 1.6194\n",
            "Epoch: 20/40... Step: 1840... Loss: 1.7613... Val Loss: 1.6549\n",
            "Epoch: 20/40... Step: 1840... Loss: 1.5556... Val Loss: 1.6350\n",
            "Epoch: 20/40... Step: 1840... Loss: 1.5054... Val Loss: 1.6134\n",
            "Epoch: 20/40... Step: 1840... Loss: 1.3817... Val Loss: 1.5803\n",
            "Epoch: 20/40... Step: 1840... Loss: 1.4829... Val Loss: 1.5681\n",
            "Epoch: 20/40... Step: 1840... Loss: 1.5084... Val Loss: 1.5615\n",
            "Epoch: 20/40... Step: 1840... Loss: 1.5424... Val Loss: 1.5596\n",
            "Epoch: 21/40... Step: 1850... Loss: 1.5550... Val Loss: 1.5550\n",
            "Epoch: 21/40... Step: 1850... Loss: 1.5251... Val Loss: 1.5401\n",
            "Epoch: 21/40... Step: 1850... Loss: 1.7354... Val Loss: 1.6052\n",
            "Epoch: 21/40... Step: 1850... Loss: 1.7485... Val Loss: 1.6410\n",
            "Epoch: 21/40... Step: 1850... Loss: 1.5234... Val Loss: 1.6175\n",
            "Epoch: 21/40... Step: 1850... Loss: 1.4863... Val Loss: 1.5956\n",
            "Epoch: 21/40... Step: 1850... Loss: 1.3559... Val Loss: 1.5614\n",
            "Epoch: 21/40... Step: 1850... Loss: 1.4592... Val Loss: 1.5486\n",
            "Epoch: 21/40... Step: 1850... Loss: 1.4662... Val Loss: 1.5394\n",
            "Epoch: 21/40... Step: 1850... Loss: 1.5272... Val Loss: 1.5382\n",
            "Epoch: 21/40... Step: 1860... Loss: 1.5397... Val Loss: 1.5397\n",
            "Epoch: 21/40... Step: 1860... Loss: 1.4840... Val Loss: 1.5118\n",
            "Epoch: 21/40... Step: 1860... Loss: 1.7151... Val Loss: 1.5796\n",
            "Epoch: 21/40... Step: 1860... Loss: 1.7491... Val Loss: 1.6220\n",
            "Epoch: 21/40... Step: 1860... Loss: 1.5083... Val Loss: 1.5992\n",
            "Epoch: 21/40... Step: 1860... Loss: 1.4772... Val Loss: 1.5789\n",
            "Epoch: 21/40... Step: 1860... Loss: 1.3336... Val Loss: 1.5438\n",
            "Epoch: 21/40... Step: 1860... Loss: 1.4565... Val Loss: 1.5329\n",
            "Epoch: 21/40... Step: 1860... Loss: 1.4613... Val Loss: 1.5250\n",
            "Epoch: 21/40... Step: 1860... Loss: 1.5096... Val Loss: 1.5234\n",
            "Epoch: 21/40... Step: 1870... Loss: 1.5474... Val Loss: 1.5474\n",
            "Epoch: 21/40... Step: 1870... Loss: 1.4791... Val Loss: 1.5132\n",
            "Epoch: 21/40... Step: 1870... Loss: 1.7012... Val Loss: 1.5759\n",
            "Epoch: 21/40... Step: 1870... Loss: 1.7134... Val Loss: 1.6103\n",
            "Epoch: 21/40... Step: 1870... Loss: 1.4835... Val Loss: 1.5849\n",
            "Epoch: 21/40... Step: 1870... Loss: 1.4415... Val Loss: 1.5610\n",
            "Epoch: 21/40... Step: 1870... Loss: 1.3358... Val Loss: 1.5288\n",
            "Epoch: 21/40... Step: 1870... Loss: 1.4394... Val Loss: 1.5176\n",
            "Epoch: 21/40... Step: 1870... Loss: 1.4538... Val Loss: 1.5106\n",
            "Epoch: 21/40... Step: 1870... Loss: 1.5154... Val Loss: 1.5110\n",
            "Epoch: 21/40... Step: 1880... Loss: 1.5393... Val Loss: 1.5393\n",
            "Epoch: 21/40... Step: 1880... Loss: 1.5062... Val Loss: 1.5228\n",
            "Epoch: 21/40... Step: 1880... Loss: 1.7154... Val Loss: 1.5870\n",
            "Epoch: 21/40... Step: 1880... Loss: 1.7646... Val Loss: 1.6314\n",
            "Epoch: 21/40... Step: 1880... Loss: 1.5178... Val Loss: 1.6087\n",
            "Epoch: 21/40... Step: 1880... Loss: 1.4841... Val Loss: 1.5879\n",
            "Epoch: 21/40... Step: 1880... Loss: 1.3726... Val Loss: 1.5571\n",
            "Epoch: 21/40... Step: 1880... Loss: 1.4758... Val Loss: 1.5470\n",
            "Epoch: 21/40... Step: 1880... Loss: 1.4749... Val Loss: 1.5390\n",
            "Epoch: 21/40... Step: 1880... Loss: 1.5253... Val Loss: 1.5376\n",
            "Epoch: 21/40... Step: 1890... Loss: 1.5590... Val Loss: 1.5590\n",
            "Epoch: 21/40... Step: 1890... Loss: 1.5379... Val Loss: 1.5484\n",
            "Epoch: 21/40... Step: 1890... Loss: 1.7169... Val Loss: 1.6046\n",
            "Epoch: 21/40... Step: 1890... Loss: 1.7276... Val Loss: 1.6354\n",
            "Epoch: 21/40... Step: 1890... Loss: 1.5007... Val Loss: 1.6084\n",
            "Epoch: 21/40... Step: 1890... Loss: 1.4986... Val Loss: 1.5901\n",
            "Epoch: 21/40... Step: 1890... Loss: 1.3686... Val Loss: 1.5585\n",
            "Epoch: 21/40... Step: 1890... Loss: 1.4738... Val Loss: 1.5479\n",
            "Epoch: 21/40... Step: 1890... Loss: 1.4864... Val Loss: 1.5411\n",
            "Epoch: 21/40... Step: 1890... Loss: 1.5425... Val Loss: 1.5412\n",
            "Epoch: 21/40... Step: 1900... Loss: 1.5710... Val Loss: 1.5710\n",
            "Epoch: 21/40... Step: 1900... Loss: 1.5182... Val Loss: 1.5446\n",
            "Epoch: 21/40... Step: 1900... Loss: 1.7429... Val Loss: 1.6107\n",
            "Epoch: 21/40... Step: 1900... Loss: 1.7725... Val Loss: 1.6511\n",
            "Epoch: 21/40... Step: 1900... Loss: 1.5243... Val Loss: 1.6258\n",
            "Epoch: 21/40... Step: 1900... Loss: 1.5365... Val Loss: 1.6109\n",
            "Epoch: 21/40... Step: 1900... Loss: 1.4045... Val Loss: 1.5814\n",
            "Epoch: 21/40... Step: 1900... Loss: 1.5111... Val Loss: 1.5726\n",
            "Epoch: 21/40... Step: 1900... Loss: 1.5237... Val Loss: 1.5672\n",
            "Epoch: 21/40... Step: 1900... Loss: 1.5592... Val Loss: 1.5664\n",
            "Epoch: 21/40... Step: 1910... Loss: 1.5665... Val Loss: 1.5665\n",
            "Epoch: 21/40... Step: 1910... Loss: 1.5350... Val Loss: 1.5508\n",
            "Epoch: 21/40... Step: 1910... Loss: 1.7183... Val Loss: 1.6066\n",
            "Epoch: 21/40... Step: 1910... Loss: 1.7690... Val Loss: 1.6472\n",
            "Epoch: 21/40... Step: 1910... Loss: 1.5225... Val Loss: 1.6223\n",
            "Epoch: 21/40... Step: 1910... Loss: 1.5240... Val Loss: 1.6059\n",
            "Epoch: 21/40... Step: 1910... Loss: 1.3999... Val Loss: 1.5765\n",
            "Epoch: 21/40... Step: 1910... Loss: 1.4824... Val Loss: 1.5647\n",
            "Epoch: 21/40... Step: 1910... Loss: 1.4813... Val Loss: 1.5554\n",
            "Epoch: 21/40... Step: 1910... Loss: 1.5524... Val Loss: 1.5551\n",
            "Epoch: 21/40... Step: 1920... Loss: 1.5606... Val Loss: 1.5606\n",
            "Epoch: 21/40... Step: 1920... Loss: 1.5232... Val Loss: 1.5419\n",
            "Epoch: 21/40... Step: 1920... Loss: 1.7340... Val Loss: 1.6059\n",
            "Epoch: 21/40... Step: 1920... Loss: 1.7405... Val Loss: 1.6395\n",
            "Epoch: 21/40... Step: 1920... Loss: 1.5393... Val Loss: 1.6195\n",
            "Epoch: 21/40... Step: 1920... Loss: 1.5211... Val Loss: 1.6031\n",
            "Epoch: 21/40... Step: 1920... Loss: 1.3983... Val Loss: 1.5738\n",
            "Epoch: 21/40... Step: 1920... Loss: 1.5032... Val Loss: 1.5650\n",
            "Epoch: 21/40... Step: 1920... Loss: 1.4879... Val Loss: 1.5564\n",
            "Epoch: 21/40... Step: 1920... Loss: 1.5426... Val Loss: 1.5551\n",
            "Epoch: 21/40... Step: 1930... Loss: 1.5728... Val Loss: 1.5728\n",
            "Epoch: 21/40... Step: 1930... Loss: 1.5157... Val Loss: 1.5443\n",
            "Epoch: 21/40... Step: 1930... Loss: 1.7494... Val Loss: 1.6127\n",
            "Epoch: 21/40... Step: 1930... Loss: 1.7405... Val Loss: 1.6446\n",
            "Epoch: 21/40... Step: 1930... Loss: 1.5386... Val Loss: 1.6234\n",
            "Epoch: 21/40... Step: 1930... Loss: 1.5039... Val Loss: 1.6035\n",
            "Epoch: 21/40... Step: 1930... Loss: 1.3816... Val Loss: 1.5718\n",
            "Epoch: 21/40... Step: 1930... Loss: 1.4636... Val Loss: 1.5583\n",
            "Epoch: 21/40... Step: 1930... Loss: 1.5118... Val Loss: 1.5531\n",
            "Epoch: 21/40... Step: 1930... Loss: 1.5142... Val Loss: 1.5492\n",
            "Epoch: 22/40... Step: 1940... Loss: 1.5543... Val Loss: 1.5543\n",
            "Epoch: 22/40... Step: 1940... Loss: 1.5288... Val Loss: 1.5416\n",
            "Epoch: 22/40... Step: 1940... Loss: 1.7206... Val Loss: 1.6012\n",
            "Epoch: 22/40... Step: 1940... Loss: 1.7452... Val Loss: 1.6372\n",
            "Epoch: 22/40... Step: 1940... Loss: 1.5260... Val Loss: 1.6150\n",
            "Epoch: 22/40... Step: 1940... Loss: 1.4712... Val Loss: 1.5910\n",
            "Epoch: 22/40... Step: 1940... Loss: 1.3372... Val Loss: 1.5548\n",
            "Epoch: 22/40... Step: 1940... Loss: 1.4560... Val Loss: 1.5424\n",
            "Epoch: 22/40... Step: 1940... Loss: 1.4866... Val Loss: 1.5362\n",
            "Epoch: 22/40... Step: 1940... Loss: 1.5524... Val Loss: 1.5378\n",
            "Epoch: 22/40... Step: 1950... Loss: 1.5347... Val Loss: 1.5347\n",
            "Epoch: 22/40... Step: 1950... Loss: 1.4890... Val Loss: 1.5119\n",
            "Epoch: 22/40... Step: 1950... Loss: 1.7084... Val Loss: 1.5774\n",
            "Epoch: 22/40... Step: 1950... Loss: 1.7243... Val Loss: 1.6141\n",
            "Epoch: 22/40... Step: 1950... Loss: 1.4740... Val Loss: 1.5861\n",
            "Epoch: 22/40... Step: 1950... Loss: 1.4910... Val Loss: 1.5702\n",
            "Epoch: 22/40... Step: 1950... Loss: 1.3121... Val Loss: 1.5333\n",
            "Epoch: 22/40... Step: 1950... Loss: 1.4446... Val Loss: 1.5222\n",
            "Epoch: 22/40... Step: 1950... Loss: 1.4618... Val Loss: 1.5155\n",
            "Epoch: 22/40... Step: 1950... Loss: 1.5380... Val Loss: 1.5178\n",
            "Epoch: 22/40... Step: 1960... Loss: 1.5297... Val Loss: 1.5297\n",
            "Epoch: 22/40... Step: 1960... Loss: 1.4829... Val Loss: 1.5063\n",
            "Epoch: 22/40... Step: 1960... Loss: 1.6975... Val Loss: 1.5700\n",
            "Epoch: 22/40... Step: 1960... Loss: 1.7328... Val Loss: 1.6107\n",
            "Epoch: 22/40... Step: 1960... Loss: 1.4606... Val Loss: 1.5807\n",
            "Epoch: 22/40... Step: 1960... Loss: 1.4576... Val Loss: 1.5602\n",
            "Epoch: 22/40... Step: 1960... Loss: 1.2899... Val Loss: 1.5216\n",
            "Epoch: 22/40... Step: 1960... Loss: 1.4425... Val Loss: 1.5117\n",
            "Epoch: 22/40... Step: 1960... Loss: 1.4573... Val Loss: 1.5056\n",
            "Epoch: 22/40... Step: 1960... Loss: 1.5059... Val Loss: 1.5057\n",
            "Epoch: 22/40... Step: 1970... Loss: 1.5419... Val Loss: 1.5419\n",
            "Epoch: 22/40... Step: 1970... Loss: 1.4799... Val Loss: 1.5109\n",
            "Epoch: 22/40... Step: 1970... Loss: 1.7093... Val Loss: 1.5770\n",
            "Epoch: 22/40... Step: 1970... Loss: 1.7384... Val Loss: 1.6174\n",
            "Epoch: 22/40... Step: 1970... Loss: 1.4937... Val Loss: 1.5926\n",
            "Epoch: 22/40... Step: 1970... Loss: 1.4737... Val Loss: 1.5728\n",
            "Epoch: 22/40... Step: 1970... Loss: 1.3497... Val Loss: 1.5409\n",
            "Epoch: 22/40... Step: 1970... Loss: 1.4739... Val Loss: 1.5326\n",
            "Epoch: 22/40... Step: 1970... Loss: 1.4838... Val Loss: 1.5271\n",
            "Epoch: 22/40... Step: 1970... Loss: 1.5192... Val Loss: 1.5263\n",
            "Epoch: 22/40... Step: 1980... Loss: 1.5512... Val Loss: 1.5512\n",
            "Epoch: 22/40... Step: 1980... Loss: 1.5254... Val Loss: 1.5383\n",
            "Epoch: 22/40... Step: 1980... Loss: 1.7213... Val Loss: 1.5993\n",
            "Epoch: 22/40... Step: 1980... Loss: 1.7198... Val Loss: 1.6294\n",
            "Epoch: 22/40... Step: 1980... Loss: 1.4847... Val Loss: 1.6005\n",
            "Epoch: 22/40... Step: 1980... Loss: 1.4986... Val Loss: 1.5835\n",
            "Epoch: 22/40... Step: 1980... Loss: 1.3524... Val Loss: 1.5505\n",
            "Epoch: 22/40... Step: 1980... Loss: 1.4803... Val Loss: 1.5417\n",
            "Epoch: 22/40... Step: 1980... Loss: 1.4719... Val Loss: 1.5339\n",
            "Epoch: 22/40... Step: 1980... Loss: 1.5203... Val Loss: 1.5326\n",
            "Epoch: 22/40... Step: 1990... Loss: 1.5629... Val Loss: 1.5629\n",
            "Epoch: 22/40... Step: 1990... Loss: 1.5378... Val Loss: 1.5503\n",
            "Epoch: 22/40... Step: 1990... Loss: 1.7329... Val Loss: 1.6112\n",
            "Epoch: 22/40... Step: 1990... Loss: 1.7635... Val Loss: 1.6493\n",
            "Epoch: 22/40... Step: 1990... Loss: 1.5242... Val Loss: 1.6242\n",
            "Epoch: 22/40... Step: 1990... Loss: 1.5058... Val Loss: 1.6045\n",
            "Epoch: 22/40... Step: 1990... Loss: 1.3987... Val Loss: 1.5751\n",
            "Epoch: 22/40... Step: 1990... Loss: 1.4936... Val Loss: 1.5649\n",
            "Epoch: 22/40... Step: 1990... Loss: 1.4796... Val Loss: 1.5554\n",
            "Epoch: 22/40... Step: 1990... Loss: 1.5652... Val Loss: 1.5564\n",
            "Epoch: 22/40... Step: 2000... Loss: 1.5651... Val Loss: 1.5651\n",
            "Epoch: 22/40... Step: 2000... Loss: 1.5396... Val Loss: 1.5523\n",
            "Epoch: 22/40... Step: 2000... Loss: 1.7425... Val Loss: 1.6157\n",
            "Epoch: 22/40... Step: 2000... Loss: 1.7519... Val Loss: 1.6497\n",
            "Epoch: 22/40... Step: 2000... Loss: 1.5195... Val Loss: 1.6237\n",
            "Epoch: 22/40... Step: 2000... Loss: 1.5210... Val Loss: 1.6066\n",
            "Epoch: 22/40... Step: 2000... Loss: 1.4117... Val Loss: 1.5787\n",
            "Epoch: 22/40... Step: 2000... Loss: 1.4913... Val Loss: 1.5678\n",
            "Epoch: 22/40... Step: 2000... Loss: 1.5092... Val Loss: 1.5613\n",
            "Epoch: 22/40... Step: 2000... Loss: 1.5498... Val Loss: 1.5602\n",
            "Epoch: 22/40... Step: 2010... Loss: 1.5671... Val Loss: 1.5671\n",
            "Epoch: 22/40... Step: 2010... Loss: 1.5272... Val Loss: 1.5471\n",
            "Epoch: 22/40... Step: 2010... Loss: 1.7474... Val Loss: 1.6139\n",
            "Epoch: 22/40... Step: 2010... Loss: 1.7692... Val Loss: 1.6527\n",
            "Epoch: 22/40... Step: 2010... Loss: 1.5614... Val Loss: 1.6345\n",
            "Epoch: 22/40... Step: 2010... Loss: 1.5166... Val Loss: 1.6148\n",
            "Epoch: 22/40... Step: 2010... Loss: 1.3881... Val Loss: 1.5824\n",
            "Epoch: 22/40... Step: 2010... Loss: 1.5088... Val Loss: 1.5732\n",
            "Epoch: 22/40... Step: 2010... Loss: 1.4873... Val Loss: 1.5637\n",
            "Epoch: 22/40... Step: 2010... Loss: 1.5416... Val Loss: 1.5615\n",
            "Epoch: 22/40... Step: 2020... Loss: 1.5480... Val Loss: 1.5480\n",
            "Epoch: 22/40... Step: 2020... Loss: 1.5072... Val Loss: 1.5276\n",
            "Epoch: 22/40... Step: 2020... Loss: 1.7179... Val Loss: 1.5911\n",
            "Epoch: 22/40... Step: 2020... Loss: 1.7368... Val Loss: 1.6275\n",
            "Epoch: 22/40... Step: 2020... Loss: 1.5285... Val Loss: 1.6077\n",
            "Epoch: 22/40... Step: 2020... Loss: 1.5063... Val Loss: 1.5908\n",
            "Epoch: 22/40... Step: 2020... Loss: 1.3822... Val Loss: 1.5610\n",
            "Epoch: 22/40... Step: 2020... Loss: 1.4606... Val Loss: 1.5485\n",
            "Epoch: 22/40... Step: 2020... Loss: 1.4905... Val Loss: 1.5420\n",
            "Epoch: 22/40... Step: 2020... Loss: 1.5273... Val Loss: 1.5406\n",
            "Epoch: 23/40... Step: 2030... Loss: 1.5491... Val Loss: 1.5491\n",
            "Epoch: 23/40... Step: 2030... Loss: 1.5164... Val Loss: 1.5327\n",
            "Epoch: 23/40... Step: 2030... Loss: 1.7123... Val Loss: 1.5926\n",
            "Epoch: 23/40... Step: 2030... Loss: 1.7315... Val Loss: 1.6273\n",
            "Epoch: 23/40... Step: 2030... Loss: 1.5171... Val Loss: 1.6053\n",
            "Epoch: 23/40... Step: 2030... Loss: 1.4831... Val Loss: 1.5849\n",
            "Epoch: 23/40... Step: 2030... Loss: 1.3601... Val Loss: 1.5528\n",
            "Epoch: 23/40... Step: 2030... Loss: 1.4588... Val Loss: 1.5411\n",
            "Epoch: 23/40... Step: 2030... Loss: 1.4894... Val Loss: 1.5353\n",
            "Epoch: 23/40... Step: 2030... Loss: 1.5097... Val Loss: 1.5328\n",
            "Epoch: 23/40... Step: 2040... Loss: 1.5252... Val Loss: 1.5252\n",
            "Epoch: 23/40... Step: 2040... Loss: 1.4908... Val Loss: 1.5080\n",
            "Epoch: 23/40... Step: 2040... Loss: 1.7402... Val Loss: 1.5854\n",
            "Epoch: 23/40... Step: 2040... Loss: 1.7487... Val Loss: 1.6262\n",
            "Epoch: 23/40... Step: 2040... Loss: 1.4933... Val Loss: 1.5996\n",
            "Epoch: 23/40... Step: 2040... Loss: 1.4602... Val Loss: 1.5764\n",
            "Epoch: 23/40... Step: 2040... Loss: 1.3169... Val Loss: 1.5393\n",
            "Epoch: 23/40... Step: 2040... Loss: 1.4629... Val Loss: 1.5298\n",
            "Epoch: 23/40... Step: 2040... Loss: 1.4671... Val Loss: 1.5228\n",
            "Epoch: 23/40... Step: 2040... Loss: 1.5010... Val Loss: 1.5206\n",
            "Epoch: 23/40... Step: 2050... Loss: 1.5222... Val Loss: 1.5222\n",
            "Epoch: 23/40... Step: 2050... Loss: 1.4769... Val Loss: 1.4995\n",
            "Epoch: 23/40... Step: 2050... Loss: 1.6964... Val Loss: 1.5652\n",
            "Epoch: 23/40... Step: 2050... Loss: 1.7082... Val Loss: 1.6009\n",
            "Epoch: 23/40... Step: 2050... Loss: 1.4987... Val Loss: 1.5805\n",
            "Epoch: 23/40... Step: 2050... Loss: 1.4550... Val Loss: 1.5596\n",
            "Epoch: 23/40... Step: 2050... Loss: 1.3065... Val Loss: 1.5234\n",
            "Epoch: 23/40... Step: 2050... Loss: 1.4603... Val Loss: 1.5155\n",
            "Epoch: 23/40... Step: 2050... Loss: 1.4585... Val Loss: 1.5092\n",
            "Epoch: 23/40... Step: 2050... Loss: 1.4946... Val Loss: 1.5077\n",
            "Epoch: 23/40... Step: 2060... Loss: 1.5361... Val Loss: 1.5361\n",
            "Epoch: 23/40... Step: 2060... Loss: 1.4882... Val Loss: 1.5121\n",
            "Epoch: 23/40... Step: 2060... Loss: 1.6732... Val Loss: 1.5658\n",
            "Epoch: 23/40... Step: 2060... Loss: 1.7051... Val Loss: 1.6006\n",
            "Epoch: 23/40... Step: 2060... Loss: 1.4984... Val Loss: 1.5802\n",
            "Epoch: 23/40... Step: 2060... Loss: 1.4612... Val Loss: 1.5604\n",
            "Epoch: 23/40... Step: 2060... Loss: 1.3536... Val Loss: 1.5308\n",
            "Epoch: 23/40... Step: 2060... Loss: 1.4598... Val Loss: 1.5219\n",
            "Epoch: 23/40... Step: 2060... Loss: 1.4723... Val Loss: 1.5164\n",
            "Epoch: 23/40... Step: 2060... Loss: 1.5240... Val Loss: 1.5172\n",
            "Epoch: 23/40... Step: 2070... Loss: 1.5423... Val Loss: 1.5423\n",
            "Epoch: 23/40... Step: 2070... Loss: 1.5228... Val Loss: 1.5325\n",
            "Epoch: 23/40... Step: 2070... Loss: 1.7021... Val Loss: 1.5891\n",
            "Epoch: 23/40... Step: 2070... Loss: 1.7323... Val Loss: 1.6249\n",
            "Epoch: 23/40... Step: 2070... Loss: 1.5140... Val Loss: 1.6027\n",
            "Epoch: 23/40... Step: 2070... Loss: 1.4908... Val Loss: 1.5841\n",
            "Epoch: 23/40... Step: 2070... Loss: 1.3667... Val Loss: 1.5530\n",
            "Epoch: 23/40... Step: 2070... Loss: 1.4969... Val Loss: 1.5460\n",
            "Epoch: 23/40... Step: 2070... Loss: 1.4863... Val Loss: 1.5394\n",
            "Epoch: 23/40... Step: 2070... Loss: 1.5628... Val Loss: 1.5417\n",
            "Epoch: 23/40... Step: 2080... Loss: 1.5405... Val Loss: 1.5405\n",
            "Epoch: 23/40... Step: 2080... Loss: 1.5130... Val Loss: 1.5267\n",
            "Epoch: 23/40... Step: 2080... Loss: 1.7076... Val Loss: 1.5870\n",
            "Epoch: 23/40... Step: 2080... Loss: 1.7333... Val Loss: 1.6236\n",
            "Epoch: 23/40... Step: 2080... Loss: 1.5126... Val Loss: 1.6014\n",
            "Epoch: 23/40... Step: 2080... Loss: 1.5101... Val Loss: 1.5862\n",
            "Epoch: 23/40... Step: 2080... Loss: 1.3967... Val Loss: 1.5591\n",
            "Epoch: 23/40... Step: 2080... Loss: 1.5080... Val Loss: 1.5527\n",
            "Epoch: 23/40... Step: 2080... Loss: 1.4830... Val Loss: 1.5450\n",
            "Epoch: 23/40... Step: 2080... Loss: 1.5437... Val Loss: 1.5448\n",
            "Epoch: 23/40... Step: 2090... Loss: 1.5424... Val Loss: 1.5424\n",
            "Epoch: 23/40... Step: 2090... Loss: 1.4901... Val Loss: 1.5162\n",
            "Epoch: 23/40... Step: 2090... Loss: 1.7179... Val Loss: 1.5834\n",
            "Epoch: 23/40... Step: 2090... Loss: 1.7341... Val Loss: 1.6211\n",
            "Epoch: 23/40... Step: 2090... Loss: 1.5417... Val Loss: 1.6052\n",
            "Epoch: 23/40... Step: 2090... Loss: 1.4955... Val Loss: 1.5869\n",
            "Epoch: 23/40... Step: 2090... Loss: 1.4117... Val Loss: 1.5619\n",
            "Epoch: 23/40... Step: 2090... Loss: 1.5151... Val Loss: 1.5561\n",
            "Epoch: 23/40... Step: 2090... Loss: 1.5012... Val Loss: 1.5500\n",
            "Epoch: 23/40... Step: 2090... Loss: 1.5277... Val Loss: 1.5477\n",
            "Epoch: 23/40... Step: 2100... Loss: 1.5535... Val Loss: 1.5535\n",
            "Epoch: 23/40... Step: 2100... Loss: 1.5541... Val Loss: 1.5538\n",
            "Epoch: 23/40... Step: 2100... Loss: 1.7354... Val Loss: 1.6143\n",
            "Epoch: 23/40... Step: 2100... Loss: 1.7788... Val Loss: 1.6554\n",
            "Epoch: 23/40... Step: 2100... Loss: 1.5211... Val Loss: 1.6286\n",
            "Epoch: 23/40... Step: 2100... Loss: 1.5400... Val Loss: 1.6138\n",
            "Epoch: 23/40... Step: 2100... Loss: 1.4131... Val Loss: 1.5852\n",
            "Epoch: 23/40... Step: 2100... Loss: 1.5081... Val Loss: 1.5755\n",
            "Epoch: 23/40... Step: 2100... Loss: 1.4845... Val Loss: 1.5654\n",
            "Epoch: 23/40... Step: 2100... Loss: 1.5355... Val Loss: 1.5624\n",
            "Epoch: 23/40... Step: 2110... Loss: 1.5425... Val Loss: 1.5425\n",
            "Epoch: 23/40... Step: 2110... Loss: 1.5119... Val Loss: 1.5272\n",
            "Epoch: 23/40... Step: 2110... Loss: 1.7008... Val Loss: 1.5851\n",
            "Epoch: 23/40... Step: 2110... Loss: 1.7496... Val Loss: 1.6262\n",
            "Epoch: 23/40... Step: 2110... Loss: 1.5003... Val Loss: 1.6010\n",
            "Epoch: 23/40... Step: 2110... Loss: 1.5068... Val Loss: 1.5853\n",
            "Epoch: 23/40... Step: 2110... Loss: 1.3853... Val Loss: 1.5568\n",
            "Epoch: 23/40... Step: 2110... Loss: 1.4987... Val Loss: 1.5495\n",
            "Epoch: 23/40... Step: 2110... Loss: 1.4810... Val Loss: 1.5419\n",
            "Epoch: 23/40... Step: 2110... Loss: 1.5110... Val Loss: 1.5388\n",
            "Epoch: 24/40... Step: 2120... Loss: 1.5568... Val Loss: 1.5568\n",
            "Epoch: 24/40... Step: 2120... Loss: 1.5346... Val Loss: 1.5457\n",
            "Epoch: 24/40... Step: 2120... Loss: 1.7648... Val Loss: 1.6187\n",
            "Epoch: 24/40... Step: 2120... Loss: 1.7446... Val Loss: 1.6502\n",
            "Epoch: 24/40... Step: 2120... Loss: 1.5343... Val Loss: 1.6270\n",
            "Epoch: 24/40... Step: 2120... Loss: 1.4949... Val Loss: 1.6050\n",
            "Epoch: 24/40... Step: 2120... Loss: 1.3593... Val Loss: 1.5699\n",
            "Epoch: 24/40... Step: 2120... Loss: 1.4772... Val Loss: 1.5583\n",
            "Epoch: 24/40... Step: 2120... Loss: 1.5030... Val Loss: 1.5522\n",
            "Epoch: 24/40... Step: 2120... Loss: 1.5575... Val Loss: 1.5527\n",
            "Epoch: 24/40... Step: 2130... Loss: 1.5220... Val Loss: 1.5220\n",
            "Epoch: 24/40... Step: 2130... Loss: 1.5029... Val Loss: 1.5124\n",
            "Epoch: 24/40... Step: 2130... Loss: 1.7383... Val Loss: 1.5877\n",
            "Epoch: 24/40... Step: 2130... Loss: 1.7374... Val Loss: 1.6251\n",
            "Epoch: 24/40... Step: 2130... Loss: 1.4739... Val Loss: 1.5949\n",
            "Epoch: 24/40... Step: 2130... Loss: 1.4770... Val Loss: 1.5752\n",
            "Epoch: 24/40... Step: 2130... Loss: 1.3213... Val Loss: 1.5390\n",
            "Epoch: 24/40... Step: 2130... Loss: 1.4230... Val Loss: 1.5245\n",
            "Epoch: 24/40... Step: 2130... Loss: 1.4435... Val Loss: 1.5155\n",
            "Epoch: 24/40... Step: 2130... Loss: 1.5338... Val Loss: 1.5173\n",
            "Epoch: 24/40... Step: 2140... Loss: 1.5200... Val Loss: 1.5200\n",
            "Epoch: 24/40... Step: 2140... Loss: 1.4793... Val Loss: 1.4996\n",
            "Epoch: 24/40... Step: 2140... Loss: 1.7024... Val Loss: 1.5672\n",
            "Epoch: 24/40... Step: 2140... Loss: 1.7227... Val Loss: 1.6061\n",
            "Epoch: 24/40... Step: 2140... Loss: 1.4611... Val Loss: 1.5771\n",
            "Epoch: 24/40... Step: 2140... Loss: 1.4479... Val Loss: 1.5555\n",
            "Epoch: 24/40... Step: 2140... Loss: 1.3036... Val Loss: 1.5196\n",
            "Epoch: 24/40... Step: 2140... Loss: 1.4309... Val Loss: 1.5085\n",
            "Epoch: 24/40... Step: 2140... Loss: 1.4515... Val Loss: 1.5021\n",
            "Epoch: 24/40... Step: 2140... Loss: 1.4859... Val Loss: 1.5005\n",
            "Epoch: 24/40... Step: 2150... Loss: 1.5302... Val Loss: 1.5302\n",
            "Epoch: 24/40... Step: 2150... Loss: 1.4798... Val Loss: 1.5050\n",
            "Epoch: 24/40... Step: 2150... Loss: 1.7026... Val Loss: 1.5709\n",
            "Epoch: 24/40... Step: 2150... Loss: 1.7133... Val Loss: 1.6065\n",
            "Epoch: 24/40... Step: 2150... Loss: 1.4804... Val Loss: 1.5812\n",
            "Epoch: 24/40... Step: 2150... Loss: 1.4395... Val Loss: 1.5576\n",
            "Epoch: 24/40... Step: 2150... Loss: 1.3022... Val Loss: 1.5211\n",
            "Epoch: 24/40... Step: 2150... Loss: 1.4808... Val Loss: 1.5161\n",
            "Epoch: 24/40... Step: 2150... Loss: 1.4363... Val Loss: 1.5072\n",
            "Epoch: 24/40... Step: 2150... Loss: 1.5097... Val Loss: 1.5075\n",
            "Epoch: 24/40... Step: 2160... Loss: 1.5400... Val Loss: 1.5400\n",
            "Epoch: 24/40... Step: 2160... Loss: 1.5167... Val Loss: 1.5284\n",
            "Epoch: 24/40... Step: 2160... Loss: 1.7492... Val Loss: 1.6020\n",
            "Epoch: 24/40... Step: 2160... Loss: 1.7773... Val Loss: 1.6458\n",
            "Epoch: 24/40... Step: 2160... Loss: 1.4936... Val Loss: 1.6154\n",
            "Epoch: 24/40... Step: 2160... Loss: 1.4926... Val Loss: 1.5949\n",
            "Epoch: 24/40... Step: 2160... Loss: 1.3767... Val Loss: 1.5637\n",
            "Epoch: 24/40... Step: 2160... Loss: 1.4925... Val Loss: 1.5548\n",
            "Epoch: 24/40... Step: 2160... Loss: 1.4694... Val Loss: 1.5453\n",
            "Epoch: 24/40... Step: 2160... Loss: 1.5410... Val Loss: 1.5449\n",
            "Epoch: 24/40... Step: 2170... Loss: 1.5478... Val Loss: 1.5478\n",
            "Epoch: 24/40... Step: 2170... Loss: 1.5218... Val Loss: 1.5348\n",
            "Epoch: 24/40... Step: 2170... Loss: 1.7243... Val Loss: 1.5979\n",
            "Epoch: 24/40... Step: 2170... Loss: 1.7373... Val Loss: 1.6328\n",
            "Epoch: 24/40... Step: 2170... Loss: 1.5019... Val Loss: 1.6066\n",
            "Epoch: 24/40... Step: 2170... Loss: 1.4789... Val Loss: 1.5853\n",
            "Epoch: 24/40... Step: 2170... Loss: 1.3917... Val Loss: 1.5577\n",
            "Epoch: 24/40... Step: 2170... Loss: 1.5006... Val Loss: 1.5505\n",
            "Epoch: 24/40... Step: 2170... Loss: 1.5148... Val Loss: 1.5466\n",
            "Epoch: 24/40... Step: 2170... Loss: 1.5619... Val Loss: 1.5481\n",
            "Epoch: 24/40... Step: 2180... Loss: 1.5453... Val Loss: 1.5453\n",
            "Epoch: 24/40... Step: 2180... Loss: 1.5322... Val Loss: 1.5388\n",
            "Epoch: 24/40... Step: 2180... Loss: 1.7285... Val Loss: 1.6020\n",
            "Epoch: 24/40... Step: 2180... Loss: 1.7203... Val Loss: 1.6316\n",
            "Epoch: 24/40... Step: 2180... Loss: 1.5066... Val Loss: 1.6066\n",
            "Epoch: 24/40... Step: 2180... Loss: 1.5172... Val Loss: 1.5917\n",
            "Epoch: 24/40... Step: 2180... Loss: 1.4092... Val Loss: 1.5656\n",
            "Epoch: 24/40... Step: 2180... Loss: 1.5031... Val Loss: 1.5578\n",
            "Epoch: 24/40... Step: 2180... Loss: 1.5143... Val Loss: 1.5530\n",
            "Epoch: 24/40... Step: 2180... Loss: 1.5724... Val Loss: 1.5549\n",
            "Epoch: 24/40... Step: 2190... Loss: 1.5579... Val Loss: 1.5579\n",
            "Epoch: 24/40... Step: 2190... Loss: 1.5134... Val Loss: 1.5356\n",
            "Epoch: 24/40... Step: 2190... Loss: 1.7208... Val Loss: 1.5973\n",
            "Epoch: 24/40... Step: 2190... Loss: 1.7381... Val Loss: 1.6325\n",
            "Epoch: 24/40... Step: 2190... Loss: 1.5156... Val Loss: 1.6091\n",
            "Epoch: 24/40... Step: 2190... Loss: 1.5228... Val Loss: 1.5948\n",
            "Epoch: 24/40... Step: 2190... Loss: 1.3982... Val Loss: 1.5667\n",
            "Epoch: 24/40... Step: 2190... Loss: 1.4839... Val Loss: 1.5563\n",
            "Epoch: 24/40... Step: 2190... Loss: 1.4780... Val Loss: 1.5476\n",
            "Epoch: 24/40... Step: 2190... Loss: 1.5382... Val Loss: 1.5467\n",
            "Epoch: 24/40... Step: 2200... Loss: 1.5441... Val Loss: 1.5441\n",
            "Epoch: 24/40... Step: 2200... Loss: 1.5244... Val Loss: 1.5343\n",
            "Epoch: 24/40... Step: 2200... Loss: 1.7360... Val Loss: 1.6015\n",
            "Epoch: 24/40... Step: 2200... Loss: 1.7588... Val Loss: 1.6408\n",
            "Epoch: 24/40... Step: 2200... Loss: 1.4893... Val Loss: 1.6105\n",
            "Epoch: 24/40... Step: 2200... Loss: 1.5065... Val Loss: 1.5932\n",
            "Epoch: 24/40... Step: 2200... Loss: 1.4129... Val Loss: 1.5674\n",
            "Epoch: 24/40... Step: 2200... Loss: 1.4714... Val Loss: 1.5554\n",
            "Epoch: 24/40... Step: 2200... Loss: 1.4767... Val Loss: 1.5467\n",
            "Epoch: 24/40... Step: 2200... Loss: 1.5451... Val Loss: 1.5465\n",
            "Epoch: 25/40... Step: 2210... Loss: 1.5544... Val Loss: 1.5544\n",
            "Epoch: 25/40... Step: 2210... Loss: 1.5234... Val Loss: 1.5389\n",
            "Epoch: 25/40... Step: 2210... Loss: 1.7228... Val Loss: 1.6002\n",
            "Epoch: 25/40... Step: 2210... Loss: 1.7523... Val Loss: 1.6382\n",
            "Epoch: 25/40... Step: 2210... Loss: 1.5176... Val Loss: 1.6141\n",
            "Epoch: 25/40... Step: 2210... Loss: 1.4957... Val Loss: 1.5944\n",
            "Epoch: 25/40... Step: 2210... Loss: 1.3585... Val Loss: 1.5607\n",
            "Epoch: 25/40... Step: 2210... Loss: 1.4522... Val Loss: 1.5471\n",
            "Epoch: 25/40... Step: 2210... Loss: 1.5086... Val Loss: 1.5428\n",
            "Epoch: 25/40... Step: 2210... Loss: 1.5423... Val Loss: 1.5428\n",
            "Epoch: 25/40... Step: 2220... Loss: 1.5192... Val Loss: 1.5192\n",
            "Epoch: 25/40... Step: 2220... Loss: 1.4727... Val Loss: 1.4960\n",
            "Epoch: 25/40... Step: 2220... Loss: 1.7046... Val Loss: 1.5655\n",
            "Epoch: 25/40... Step: 2220... Loss: 1.7302... Val Loss: 1.6067\n",
            "Epoch: 25/40... Step: 2220... Loss: 1.4969... Val Loss: 1.5848\n",
            "Epoch: 25/40... Step: 2220... Loss: 1.4649... Val Loss: 1.5648\n",
            "Epoch: 25/40... Step: 2220... Loss: 1.3204... Val Loss: 1.5299\n",
            "Epoch: 25/40... Step: 2220... Loss: 1.4278... Val Loss: 1.5171\n",
            "Epoch: 25/40... Step: 2220... Loss: 1.4711... Val Loss: 1.5120\n",
            "Epoch: 25/40... Step: 2220... Loss: 1.5102... Val Loss: 1.5118\n",
            "Epoch: 25/40... Step: 2230... Loss: 1.5112... Val Loss: 1.5112\n",
            "Epoch: 25/40... Step: 2230... Loss: 1.4771... Val Loss: 1.4942\n",
            "Epoch: 25/40... Step: 2230... Loss: 1.7438... Val Loss: 1.5774\n",
            "Epoch: 25/40... Step: 2230... Loss: 1.7226... Val Loss: 1.6137\n",
            "Epoch: 25/40... Step: 2230... Loss: 1.4881... Val Loss: 1.5886\n",
            "Epoch: 25/40... Step: 2230... Loss: 1.4675... Val Loss: 1.5684\n",
            "Epoch: 25/40... Step: 2230... Loss: 1.3214... Val Loss: 1.5331\n",
            "Epoch: 25/40... Step: 2230... Loss: 1.4587... Val Loss: 1.5238\n",
            "Epoch: 25/40... Step: 2230... Loss: 1.4897... Val Loss: 1.5200\n",
            "Epoch: 25/40... Step: 2230... Loss: 1.5184... Val Loss: 1.5199\n",
            "Epoch: 25/40... Step: 2240... Loss: 1.5275... Val Loss: 1.5275\n",
            "Epoch: 25/40... Step: 2240... Loss: 1.4901... Val Loss: 1.5088\n",
            "Epoch: 25/40... Step: 2240... Loss: 1.7201... Val Loss: 1.5792\n",
            "Epoch: 25/40... Step: 2240... Loss: 1.7091... Val Loss: 1.6117\n",
            "Epoch: 25/40... Step: 2240... Loss: 1.4692... Val Loss: 1.5832\n",
            "Epoch: 25/40... Step: 2240... Loss: 1.4191... Val Loss: 1.5559\n",
            "Epoch: 25/40... Step: 2240... Loss: 1.3193... Val Loss: 1.5221\n",
            "Epoch: 25/40... Step: 2240... Loss: 1.4390... Val Loss: 1.5117\n",
            "Epoch: 25/40... Step: 2240... Loss: 1.4569... Val Loss: 1.5056\n",
            "Epoch: 25/40... Step: 2240... Loss: 1.4897... Val Loss: 1.5040\n",
            "Epoch: 25/40... Step: 2250... Loss: 1.5369... Val Loss: 1.5369\n",
            "Epoch: 25/40... Step: 2250... Loss: 1.4992... Val Loss: 1.5181\n",
            "Epoch: 25/40... Step: 2250... Loss: 1.7096... Val Loss: 1.5819\n",
            "Epoch: 25/40... Step: 2250... Loss: 1.7314... Val Loss: 1.6193\n",
            "Epoch: 25/40... Step: 2250... Loss: 1.5208... Val Loss: 1.5996\n",
            "Epoch: 25/40... Step: 2250... Loss: 1.4687... Val Loss: 1.5778\n",
            "Epoch: 25/40... Step: 2250... Loss: 1.3638... Val Loss: 1.5472\n",
            "Epoch: 25/40... Step: 2250... Loss: 1.4750... Val Loss: 1.5382\n",
            "Epoch: 25/40... Step: 2250... Loss: 1.4893... Val Loss: 1.5327\n",
            "Epoch: 25/40... Step: 2250... Loss: 1.5357... Val Loss: 1.5330\n",
            "Epoch: 25/40... Step: 2260... Loss: 1.5509... Val Loss: 1.5509\n",
            "Epoch: 25/40... Step: 2260... Loss: 1.5031... Val Loss: 1.5270\n",
            "Epoch: 25/40... Step: 2260... Loss: 1.7331... Val Loss: 1.5957\n",
            "Epoch: 25/40... Step: 2260... Loss: 1.7327... Val Loss: 1.6300\n",
            "Epoch: 25/40... Step: 2260... Loss: 1.5057... Val Loss: 1.6051\n",
            "Epoch: 25/40... Step: 2260... Loss: 1.4902... Val Loss: 1.5860\n",
            "Epoch: 25/40... Step: 2260... Loss: 1.3917... Val Loss: 1.5582\n",
            "Epoch: 25/40... Step: 2260... Loss: 1.4828... Val Loss: 1.5488\n",
            "Epoch: 25/40... Step: 2260... Loss: 1.5082... Val Loss: 1.5443\n",
            "Epoch: 25/40... Step: 2260... Loss: 1.5464... Val Loss: 1.5445\n",
            "Epoch: 25/40... Step: 2270... Loss: 1.5482... Val Loss: 1.5482\n",
            "Epoch: 25/40... Step: 2270... Loss: 1.5125... Val Loss: 1.5304\n",
            "Epoch: 25/40... Step: 2270... Loss: 1.7378... Val Loss: 1.5995\n",
            "Epoch: 25/40... Step: 2270... Loss: 1.7459... Val Loss: 1.6361\n",
            "Epoch: 25/40... Step: 2270... Loss: 1.5153... Val Loss: 1.6119\n",
            "Epoch: 25/40... Step: 2270... Loss: 1.5036... Val Loss: 1.5939\n",
            "Epoch: 25/40... Step: 2270... Loss: 1.4028... Val Loss: 1.5666\n",
            "Epoch: 25/40... Step: 2270... Loss: 1.4718... Val Loss: 1.5547\n",
            "Epoch: 25/40... Step: 2270... Loss: 1.4918... Val Loss: 1.5477\n",
            "Epoch: 25/40... Step: 2270... Loss: 1.5565... Val Loss: 1.5486\n",
            "Epoch: 25/40... Step: 2280... Loss: 1.5581... Val Loss: 1.5581\n",
            "Epoch: 25/40... Step: 2280... Loss: 1.5112... Val Loss: 1.5347\n",
            "Epoch: 25/40... Step: 2280... Loss: 1.7245... Val Loss: 1.5980\n",
            "Epoch: 25/40... Step: 2280... Loss: 1.7410... Val Loss: 1.6337\n",
            "Epoch: 25/40... Step: 2280... Loss: 1.5179... Val Loss: 1.6105\n",
            "Epoch: 25/40... Step: 2280... Loss: 1.5258... Val Loss: 1.5964\n",
            "Epoch: 25/40... Step: 2280... Loss: 1.4003... Val Loss: 1.5684\n",
            "Epoch: 25/40... Step: 2280... Loss: 1.4882... Val Loss: 1.5584\n",
            "Epoch: 25/40... Step: 2280... Loss: 1.4989... Val Loss: 1.5518\n",
            "Epoch: 25/40... Step: 2280... Loss: 1.5424... Val Loss: 1.5508\n",
            "Epoch: 25/40... Step: 2290... Loss: 1.5487... Val Loss: 1.5487\n",
            "Epoch: 25/40... Step: 2290... Loss: 1.5071... Val Loss: 1.5279\n",
            "Epoch: 25/40... Step: 2290... Loss: 1.7412... Val Loss: 1.5990\n",
            "Epoch: 25/40... Step: 2290... Loss: 1.7753... Val Loss: 1.6431\n",
            "Epoch: 25/40... Step: 2290... Loss: 1.5112... Val Loss: 1.6167\n",
            "Epoch: 25/40... Step: 2290... Loss: 1.4998... Val Loss: 1.5972\n",
            "Epoch: 25/40... Step: 2290... Loss: 1.3839... Val Loss: 1.5667\n",
            "Epoch: 25/40... Step: 2290... Loss: 1.4649... Val Loss: 1.5540\n",
            "Epoch: 25/40... Step: 2290... Loss: 1.4818... Val Loss: 1.5460\n",
            "Epoch: 25/40... Step: 2290... Loss: 1.5260... Val Loss: 1.5440\n",
            "Epoch: 25/40... Step: 2300... Loss: 1.5561... Val Loss: 1.5561\n",
            "Epoch: 25/40... Step: 2300... Loss: 1.5148... Val Loss: 1.5355\n",
            "Epoch: 25/40... Step: 2300... Loss: 1.7201... Val Loss: 1.5970\n",
            "Epoch: 25/40... Step: 2300... Loss: 1.7299... Val Loss: 1.6302\n",
            "Epoch: 25/40... Step: 2300... Loss: 1.5014... Val Loss: 1.6045\n",
            "Epoch: 25/40... Step: 2300... Loss: 1.5055... Val Loss: 1.5880\n",
            "Epoch: 25/40... Step: 2300... Loss: 1.3799... Val Loss: 1.5583\n",
            "Epoch: 25/40... Step: 2300... Loss: 1.4767... Val Loss: 1.5481\n",
            "Epoch: 25/40... Step: 2300... Loss: 1.4946... Val Loss: 1.5421\n",
            "Epoch: 25/40... Step: 2300... Loss: 1.5430... Val Loss: 1.5422\n",
            "Epoch: 26/40... Step: 2310... Loss: 1.5217... Val Loss: 1.5217\n",
            "Epoch: 26/40... Step: 2310... Loss: 1.4964... Val Loss: 1.5090\n",
            "Epoch: 26/40... Step: 2310... Loss: 1.7302... Val Loss: 1.5828\n",
            "Epoch: 26/40... Step: 2310... Loss: 1.7229... Val Loss: 1.6178\n",
            "Epoch: 26/40... Step: 2310... Loss: 1.5163... Val Loss: 1.5975\n",
            "Epoch: 26/40... Step: 2310... Loss: 1.4416... Val Loss: 1.5715\n",
            "Epoch: 26/40... Step: 2310... Loss: 1.3433... Val Loss: 1.5389\n",
            "Epoch: 26/40... Step: 2310... Loss: 1.4366... Val Loss: 1.5261\n",
            "Epoch: 26/40... Step: 2310... Loss: 1.4357... Val Loss: 1.5161\n",
            "Epoch: 26/40... Step: 2310... Loss: 1.5239... Val Loss: 1.5169\n",
            "Epoch: 26/40... Step: 2320... Loss: 1.5056... Val Loss: 1.5056\n",
            "Epoch: 26/40... Step: 2320... Loss: 1.4774... Val Loss: 1.4915\n",
            "Epoch: 26/40... Step: 2320... Loss: 1.7098... Val Loss: 1.5643\n",
            "Epoch: 26/40... Step: 2320... Loss: 1.7278... Val Loss: 1.6052\n",
            "Epoch: 26/40... Step: 2320... Loss: 1.4791... Val Loss: 1.5800\n",
            "Epoch: 26/40... Step: 2320... Loss: 1.4615... Val Loss: 1.5602\n",
            "Epoch: 26/40... Step: 2320... Loss: 1.3326... Val Loss: 1.5277\n",
            "Epoch: 26/40... Step: 2320... Loss: 1.4563... Val Loss: 1.5188\n",
            "Epoch: 26/40... Step: 2320... Loss: 1.4718... Val Loss: 1.5136\n",
            "Epoch: 26/40... Step: 2320... Loss: 1.5435... Val Loss: 1.5166\n",
            "Epoch: 26/40... Step: 2330... Loss: 1.5235... Val Loss: 1.5235\n",
            "Epoch: 26/40... Step: 2330... Loss: 1.4678... Val Loss: 1.4956\n",
            "Epoch: 26/40... Step: 2330... Loss: 1.7022... Val Loss: 1.5645\n",
            "Epoch: 26/40... Step: 2330... Loss: 1.7200... Val Loss: 1.6033\n",
            "Epoch: 26/40... Step: 2330... Loss: 1.4746... Val Loss: 1.5776\n",
            "Epoch: 26/40... Step: 2330... Loss: 1.4173... Val Loss: 1.5509\n",
            "Epoch: 26/40... Step: 2330... Loss: 1.3108... Val Loss: 1.5166\n",
            "Epoch: 26/40... Step: 2330... Loss: 1.4375... Val Loss: 1.5067\n",
            "Epoch: 26/40... Step: 2330... Loss: 1.4493... Val Loss: 1.5003\n",
            "Epoch: 26/40... Step: 2330... Loss: 1.5054... Val Loss: 1.5008\n",
            "Epoch: 26/40... Step: 2340... Loss: 1.5215... Val Loss: 1.5215\n",
            "Epoch: 26/40... Step: 2340... Loss: 1.5255... Val Loss: 1.5235\n",
            "Epoch: 26/40... Step: 2340... Loss: 1.7081... Val Loss: 1.5850\n",
            "Epoch: 26/40... Step: 2340... Loss: 1.7322... Val Loss: 1.6218\n",
            "Epoch: 26/40... Step: 2340... Loss: 1.5089... Val Loss: 1.5992\n",
            "Epoch: 26/40... Step: 2340... Loss: 1.4431... Val Loss: 1.5732\n",
            "Epoch: 26/40... Step: 2340... Loss: 1.3438... Val Loss: 1.5404\n",
            "Epoch: 26/40... Step: 2340... Loss: 1.4806... Val Loss: 1.5330\n",
            "Epoch: 26/40... Step: 2340... Loss: 1.4457... Val Loss: 1.5233\n",
            "Epoch: 26/40... Step: 2340... Loss: 1.4996... Val Loss: 1.5209\n",
            "Epoch: 26/40... Step: 2350... Loss: 1.5355... Val Loss: 1.5355\n",
            "Epoch: 26/40... Step: 2350... Loss: 1.5189... Val Loss: 1.5272\n",
            "Epoch: 26/40... Step: 2350... Loss: 1.7358... Val Loss: 1.5967\n",
            "Epoch: 26/40... Step: 2350... Loss: 1.7611... Val Loss: 1.6378\n",
            "Epoch: 26/40... Step: 2350... Loss: 1.4886... Val Loss: 1.6080\n",
            "Epoch: 26/40... Step: 2350... Loss: 1.4847... Val Loss: 1.5874\n",
            "Epoch: 26/40... Step: 2350... Loss: 1.3857... Val Loss: 1.5586\n",
            "Epoch: 26/40... Step: 2350... Loss: 1.5027... Val Loss: 1.5516\n",
            "Epoch: 26/40... Step: 2350... Loss: 1.5020... Val Loss: 1.5461\n",
            "Epoch: 26/40... Step: 2350... Loss: 1.5231... Val Loss: 1.5438\n",
            "Epoch: 26/40... Step: 2360... Loss: 1.5440... Val Loss: 1.5440\n",
            "Epoch: 26/40... Step: 2360... Loss: 1.5096... Val Loss: 1.5268\n",
            "Epoch: 26/40... Step: 2360... Loss: 1.7210... Val Loss: 1.5915\n",
            "Epoch: 26/40... Step: 2360... Loss: 1.7380... Val Loss: 1.6281\n",
            "Epoch: 26/40... Step: 2360... Loss: 1.5182... Val Loss: 1.6061\n",
            "Epoch: 26/40... Step: 2360... Loss: 1.5139... Val Loss: 1.5908\n",
            "Epoch: 26/40... Step: 2360... Loss: 1.4119... Val Loss: 1.5652\n",
            "Epoch: 26/40... Step: 2360... Loss: 1.4980... Val Loss: 1.5568\n",
            "Epoch: 26/40... Step: 2360... Loss: 1.5242... Val Loss: 1.5532\n",
            "Epoch: 26/40... Step: 2360... Loss: 1.5534... Val Loss: 1.5532\n",
            "Epoch: 26/40... Step: 2370... Loss: 1.5367... Val Loss: 1.5367\n",
            "Epoch: 26/40... Step: 2370... Loss: 1.5168... Val Loss: 1.5267\n",
            "Epoch: 26/40... Step: 2370... Loss: 1.7284... Val Loss: 1.5940\n",
            "Epoch: 26/40... Step: 2370... Loss: 1.7540... Val Loss: 1.6340\n",
            "Epoch: 26/40... Step: 2370... Loss: 1.5109... Val Loss: 1.6094\n",
            "Epoch: 26/40... Step: 2370... Loss: 1.4954... Val Loss: 1.5904\n",
            "Epoch: 26/40... Step: 2370... Loss: 1.3835... Val Loss: 1.5608\n",
            "Epoch: 26/40... Step: 2370... Loss: 1.4984... Val Loss: 1.5530\n",
            "Epoch: 26/40... Step: 2370... Loss: 1.5046... Val Loss: 1.5476\n",
            "Epoch: 26/40... Step: 2370... Loss: 1.5637... Val Loss: 1.5492\n",
            "Epoch: 26/40... Step: 2380... Loss: 1.5459... Val Loss: 1.5459\n",
            "Epoch: 26/40... Step: 2380... Loss: 1.5158... Val Loss: 1.5308\n",
            "Epoch: 26/40... Step: 2380... Loss: 1.7289... Val Loss: 1.5969\n",
            "Epoch: 26/40... Step: 2380... Loss: 1.8021... Val Loss: 1.6482\n",
            "Epoch: 26/40... Step: 2380... Loss: 1.5224... Val Loss: 1.6230\n",
            "Epoch: 26/40... Step: 2380... Loss: 1.5163... Val Loss: 1.6052\n",
            "Epoch: 26/40... Step: 2380... Loss: 1.4363... Val Loss: 1.5811\n",
            "Epoch: 26/40... Step: 2380... Loss: 1.4952... Val Loss: 1.5704\n",
            "Epoch: 26/40... Step: 2380... Loss: 1.4763... Val Loss: 1.5599\n",
            "Epoch: 26/40... Step: 2380... Loss: 1.5486... Val Loss: 1.5588\n",
            "Epoch: 26/40... Step: 2390... Loss: 1.5428... Val Loss: 1.5428\n",
            "Epoch: 26/40... Step: 2390... Loss: 1.5406... Val Loss: 1.5417\n",
            "Epoch: 26/40... Step: 2390... Loss: 1.7188... Val Loss: 1.6007\n",
            "Epoch: 26/40... Step: 2390... Loss: 1.7716... Val Loss: 1.6434\n",
            "Epoch: 26/40... Step: 2390... Loss: 1.5042... Val Loss: 1.6156\n",
            "Epoch: 26/40... Step: 2390... Loss: 1.5081... Val Loss: 1.5977\n",
            "Epoch: 26/40... Step: 2390... Loss: 1.3845... Val Loss: 1.5672\n",
            "Epoch: 26/40... Step: 2390... Loss: 1.4696... Val Loss: 1.5550\n",
            "Epoch: 26/40... Step: 2390... Loss: 1.4897... Val Loss: 1.5478\n",
            "Epoch: 26/40... Step: 2390... Loss: 1.5322... Val Loss: 1.5462\n",
            "Epoch: 27/40... Step: 2400... Loss: 1.5310... Val Loss: 1.5310\n",
            "Epoch: 27/40... Step: 2400... Loss: 1.5136... Val Loss: 1.5223\n",
            "Epoch: 27/40... Step: 2400... Loss: 1.6996... Val Loss: 1.5814\n",
            "Epoch: 27/40... Step: 2400... Loss: 1.7292... Val Loss: 1.6184\n",
            "Epoch: 27/40... Step: 2400... Loss: 1.5253... Val Loss: 1.5998\n",
            "Epoch: 27/40... Step: 2400... Loss: 1.4823... Val Loss: 1.5802\n",
            "Epoch: 27/40... Step: 2400... Loss: 1.3827... Val Loss: 1.5520\n",
            "Epoch: 27/40... Step: 2400... Loss: 1.4373... Val Loss: 1.5376\n",
            "Epoch: 27/40... Step: 2400... Loss: 1.4988... Val Loss: 1.5333\n",
            "Epoch: 27/40... Step: 2400... Loss: 1.4955... Val Loss: 1.5295\n",
            "Epoch: 27/40... Step: 2410... Loss: 1.5107... Val Loss: 1.5107\n",
            "Epoch: 27/40... Step: 2410... Loss: 1.4958... Val Loss: 1.5032\n",
            "Epoch: 27/40... Step: 2410... Loss: 1.7182... Val Loss: 1.5749\n",
            "Epoch: 27/40... Step: 2410... Loss: 1.7483... Val Loss: 1.6182\n",
            "Epoch: 27/40... Step: 2410... Loss: 1.4681... Val Loss: 1.5882\n",
            "Epoch: 27/40... Step: 2410... Loss: 1.4541... Val Loss: 1.5659\n",
            "Epoch: 27/40... Step: 2410... Loss: 1.3009... Val Loss: 1.5280\n",
            "Epoch: 27/40... Step: 2410... Loss: 1.4170... Val Loss: 1.5141\n",
            "Epoch: 27/40... Step: 2410... Loss: 1.4612... Val Loss: 1.5083\n",
            "Epoch: 27/40... Step: 2410... Loss: 1.5428... Val Loss: 1.5117\n",
            "Epoch: 27/40... Step: 2420... Loss: 1.5215... Val Loss: 1.5215\n",
            "Epoch: 27/40... Step: 2420... Loss: 1.4699... Val Loss: 1.4957\n",
            "Epoch: 27/40... Step: 2420... Loss: 1.7213... Val Loss: 1.5709\n",
            "Epoch: 27/40... Step: 2420... Loss: 1.7351... Val Loss: 1.6120\n",
            "Epoch: 27/40... Step: 2420... Loss: 1.4614... Val Loss: 1.5818\n",
            "Epoch: 27/40... Step: 2420... Loss: 1.4486... Val Loss: 1.5596\n",
            "Epoch: 27/40... Step: 2420... Loss: 1.3102... Val Loss: 1.5240\n",
            "Epoch: 27/40... Step: 2420... Loss: 1.4379... Val Loss: 1.5132\n",
            "Epoch: 27/40... Step: 2420... Loss: 1.4709... Val Loss: 1.5085\n",
            "Epoch: 27/40... Step: 2420... Loss: 1.4738... Val Loss: 1.5051\n",
            "Epoch: 27/40... Step: 2430... Loss: 1.5375... Val Loss: 1.5375\n",
            "Epoch: 27/40... Step: 2430... Loss: 1.4834... Val Loss: 1.5105\n",
            "Epoch: 27/40... Step: 2430... Loss: 1.7365... Val Loss: 1.5858\n",
            "Epoch: 27/40... Step: 2430... Loss: 1.7628... Val Loss: 1.6301\n",
            "Epoch: 27/40... Step: 2430... Loss: 1.5074... Val Loss: 1.6055\n",
            "Epoch: 27/40... Step: 2430... Loss: 1.4503... Val Loss: 1.5797\n",
            "Epoch: 27/40... Step: 2430... Loss: 1.3699... Val Loss: 1.5497\n",
            "Epoch: 27/40... Step: 2430... Loss: 1.5005... Val Loss: 1.5435\n",
            "Epoch: 27/40... Step: 2430... Loss: 1.4680... Val Loss: 1.5351\n",
            "Epoch: 27/40... Step: 2430... Loss: 1.5153... Val Loss: 1.5332\n",
            "Epoch: 27/40... Step: 2440... Loss: 1.5431... Val Loss: 1.5431\n",
            "Epoch: 27/40... Step: 2440... Loss: 1.5217... Val Loss: 1.5324\n",
            "Epoch: 27/40... Step: 2440... Loss: 1.7389... Val Loss: 1.6012\n",
            "Epoch: 27/40... Step: 2440... Loss: 1.7434... Val Loss: 1.6368\n",
            "Epoch: 27/40... Step: 2440... Loss: 1.4873... Val Loss: 1.6069\n",
            "Epoch: 27/40... Step: 2440... Loss: 1.4939... Val Loss: 1.5880\n",
            "Epoch: 27/40... Step: 2440... Loss: 1.3525... Val Loss: 1.5544\n",
            "Epoch: 27/40... Step: 2440... Loss: 1.4829... Val Loss: 1.5455\n",
            "Epoch: 27/40... Step: 2440... Loss: 1.4782... Val Loss: 1.5380\n",
            "Epoch: 27/40... Step: 2440... Loss: 1.5440... Val Loss: 1.5386\n",
            "Epoch: 27/40... Step: 2450... Loss: 1.5387... Val Loss: 1.5387\n",
            "Epoch: 27/40... Step: 2450... Loss: 1.5057... Val Loss: 1.5222\n",
            "Epoch: 27/40... Step: 2450... Loss: 1.7443... Val Loss: 1.5962\n",
            "Epoch: 27/40... Step: 2450... Loss: 1.7628... Val Loss: 1.6379\n",
            "Epoch: 27/40... Step: 2450... Loss: 1.5300... Val Loss: 1.6163\n",
            "Epoch: 27/40... Step: 2450... Loss: 1.4918... Val Loss: 1.5956\n",
            "Epoch: 27/40... Step: 2450... Loss: 1.4107... Val Loss: 1.5691\n",
            "Epoch: 27/40... Step: 2450... Loss: 1.5060... Val Loss: 1.5612\n",
            "Epoch: 27/40... Step: 2450... Loss: 1.4982... Val Loss: 1.5542\n",
            "Epoch: 27/40... Step: 2450... Loss: 1.5450... Val Loss: 1.5533\n",
            "Epoch: 27/40... Step: 2460... Loss: 1.5442... Val Loss: 1.5442\n",
            "Epoch: 27/40... Step: 2460... Loss: 1.5133... Val Loss: 1.5288\n",
            "Epoch: 27/40... Step: 2460... Loss: 1.7630... Val Loss: 1.6068\n",
            "Epoch: 27/40... Step: 2460... Loss: 1.7584... Val Loss: 1.6447\n",
            "Epoch: 27/40... Step: 2460... Loss: 1.5050... Val Loss: 1.6168\n",
            "Epoch: 27/40... Step: 2460... Loss: 1.5132... Val Loss: 1.5995\n",
            "Epoch: 27/40... Step: 2460... Loss: 1.3952... Val Loss: 1.5703\n",
            "Epoch: 27/40... Step: 2460... Loss: 1.4930... Val Loss: 1.5607\n",
            "Epoch: 27/40... Step: 2460... Loss: 1.4875... Val Loss: 1.5525\n",
            "Epoch: 27/40... Step: 2460... Loss: 1.5554... Val Loss: 1.5528\n",
            "Epoch: 27/40... Step: 2470... Loss: 1.5607... Val Loss: 1.5607\n",
            "Epoch: 27/40... Step: 2470... Loss: 1.5057... Val Loss: 1.5332\n",
            "Epoch: 27/40... Step: 2470... Loss: 1.7707... Val Loss: 1.6124\n",
            "Epoch: 27/40... Step: 2470... Loss: 1.7898... Val Loss: 1.6567\n",
            "Epoch: 27/40... Step: 2470... Loss: 1.5161... Val Loss: 1.6286\n",
            "Epoch: 27/40... Step: 2470... Loss: 1.5364... Val Loss: 1.6132\n",
            "Epoch: 27/40... Step: 2470... Loss: 1.3934... Val Loss: 1.5818\n",
            "Epoch: 27/40... Step: 2470... Loss: 1.4859... Val Loss: 1.5698\n",
            "Epoch: 27/40... Step: 2470... Loss: 1.4984... Val Loss: 1.5619\n",
            "Epoch: 27/40... Step: 2470... Loss: 1.5543... Val Loss: 1.5611\n",
            "Epoch: 27/40... Step: 2480... Loss: 1.5574... Val Loss: 1.5574\n",
            "Epoch: 27/40... Step: 2480... Loss: 1.5104... Val Loss: 1.5339\n",
            "Epoch: 27/40... Step: 2480... Loss: 1.7369... Val Loss: 1.6016\n",
            "Epoch: 27/40... Step: 2480... Loss: 1.7682... Val Loss: 1.6432\n",
            "Epoch: 27/40... Step: 2480... Loss: 1.4823... Val Loss: 1.6110\n",
            "Epoch: 27/40... Step: 2480... Loss: 1.5123... Val Loss: 1.5946\n",
            "Epoch: 27/40... Step: 2480... Loss: 1.3886... Val Loss: 1.5652\n",
            "Epoch: 27/40... Step: 2480... Loss: 1.4688... Val Loss: 1.5531\n",
            "Epoch: 27/40... Step: 2480... Loss: 1.5045... Val Loss: 1.5477\n",
            "Epoch: 27/40... Step: 2480... Loss: 1.5241... Val Loss: 1.5454\n",
            "Epoch: 28/40... Step: 2490... Loss: 1.5381... Val Loss: 1.5381\n",
            "Epoch: 28/40... Step: 2490... Loss: 1.5058... Val Loss: 1.5220\n",
            "Epoch: 28/40... Step: 2490... Loss: 1.7239... Val Loss: 1.5893\n",
            "Epoch: 28/40... Step: 2490... Loss: 1.7386... Val Loss: 1.6266\n",
            "Epoch: 28/40... Step: 2490... Loss: 1.4980... Val Loss: 1.6009\n",
            "Epoch: 28/40... Step: 2490... Loss: 1.4831... Val Loss: 1.5813\n",
            "Epoch: 28/40... Step: 2490... Loss: 1.3433... Val Loss: 1.5473\n",
            "Epoch: 28/40... Step: 2490... Loss: 1.4422... Val Loss: 1.5341\n",
            "Epoch: 28/40... Step: 2490... Loss: 1.5044... Val Loss: 1.5308\n",
            "Epoch: 28/40... Step: 2490... Loss: 1.5261... Val Loss: 1.5304\n",
            "Epoch: 28/40... Step: 2500... Loss: 1.5102... Val Loss: 1.5102\n",
            "Epoch: 28/40... Step: 2500... Loss: 1.4931... Val Loss: 1.5017\n",
            "Epoch: 28/40... Step: 2500... Loss: 1.7319... Val Loss: 1.5784\n",
            "Epoch: 28/40... Step: 2500... Loss: 1.7236... Val Loss: 1.6147\n",
            "Epoch: 28/40... Step: 2500... Loss: 1.4892... Val Loss: 1.5896\n",
            "Epoch: 28/40... Step: 2500... Loss: 1.4651... Val Loss: 1.5688\n",
            "Epoch: 28/40... Step: 2500... Loss: 1.3341... Val Loss: 1.5353\n",
            "Epoch: 28/40... Step: 2500... Loss: 1.4464... Val Loss: 1.5242\n",
            "Epoch: 28/40... Step: 2500... Loss: 1.4498... Val Loss: 1.5159\n",
            "Epoch: 28/40... Step: 2500... Loss: 1.5416... Val Loss: 1.5185\n",
            "Epoch: 28/40... Step: 2510... Loss: 1.5171... Val Loss: 1.5171\n",
            "Epoch: 28/40... Step: 2510... Loss: 1.4880... Val Loss: 1.5025\n",
            "Epoch: 28/40... Step: 2510... Loss: 1.7067... Val Loss: 1.5706\n",
            "Epoch: 28/40... Step: 2510... Loss: 1.7308... Val Loss: 1.6106\n",
            "Epoch: 28/40... Step: 2510... Loss: 1.4831... Val Loss: 1.5851\n",
            "Epoch: 28/40... Step: 2510... Loss: 1.4400... Val Loss: 1.5609\n",
            "Epoch: 28/40... Step: 2510... Loss: 1.3395... Val Loss: 1.5293\n",
            "Epoch: 28/40... Step: 2510... Loss: 1.4249... Val Loss: 1.5162\n",
            "Epoch: 28/40... Step: 2510... Loss: 1.4598... Val Loss: 1.5100\n",
            "Epoch: 28/40... Step: 2510... Loss: 1.5365... Val Loss: 1.5126\n",
            "Epoch: 28/40... Step: 2520... Loss: 1.5404... Val Loss: 1.5404\n",
            "Epoch: 28/40... Step: 2520... Loss: 1.4954... Val Loss: 1.5179\n",
            "Epoch: 28/40... Step: 2520... Loss: 1.7233... Val Loss: 1.5864\n",
            "Epoch: 28/40... Step: 2520... Loss: 1.7543... Val Loss: 1.6284\n",
            "Epoch: 28/40... Step: 2520... Loss: 1.4927... Val Loss: 1.6012\n",
            "Epoch: 28/40... Step: 2520... Loss: 1.4537... Val Loss: 1.5766\n",
            "Epoch: 28/40... Step: 2520... Loss: 1.3340... Val Loss: 1.5420\n",
            "Epoch: 28/40... Step: 2520... Loss: 1.4541... Val Loss: 1.5310\n",
            "Epoch: 28/40... Step: 2520... Loss: 1.4773... Val Loss: 1.5250\n",
            "Epoch: 28/40... Step: 2520... Loss: 1.5406... Val Loss: 1.5266\n",
            "Epoch: 28/40... Step: 2530... Loss: 1.5492... Val Loss: 1.5492\n",
            "Epoch: 28/40... Step: 2530... Loss: 1.4878... Val Loss: 1.5185\n",
            "Epoch: 28/40... Step: 2530... Loss: 1.7292... Val Loss: 1.5888\n",
            "Epoch: 28/40... Step: 2530... Loss: 1.7565... Val Loss: 1.6307\n",
            "Epoch: 28/40... Step: 2530... Loss: 1.5130... Val Loss: 1.6071\n",
            "Epoch: 28/40... Step: 2530... Loss: 1.4860... Val Loss: 1.5870\n",
            "Epoch: 28/40... Step: 2530... Loss: 1.3848... Val Loss: 1.5581\n",
            "Epoch: 28/40... Step: 2530... Loss: 1.4987... Val Loss: 1.5507\n",
            "Epoch: 28/40... Step: 2530... Loss: 1.4964... Val Loss: 1.5446\n",
            "Epoch: 28/40... Step: 2530... Loss: 1.5238... Val Loss: 1.5425\n",
            "Epoch: 28/40... Step: 2540... Loss: 1.5496... Val Loss: 1.5496\n",
            "Epoch: 28/40... Step: 2540... Loss: 1.5310... Val Loss: 1.5403\n",
            "Epoch: 28/40... Step: 2540... Loss: 1.7362... Val Loss: 1.6056\n",
            "Epoch: 28/40... Step: 2540... Loss: 1.7519... Val Loss: 1.6421\n",
            "Epoch: 28/40... Step: 2540... Loss: 1.4872... Val Loss: 1.6112\n",
            "Epoch: 28/40... Step: 2540... Loss: 1.4899... Val Loss: 1.5909\n",
            "Epoch: 28/40... Step: 2540... Loss: 1.4128... Val Loss: 1.5655\n",
            "Epoch: 28/40... Step: 2540... Loss: 1.5074... Val Loss: 1.5582\n",
            "Epoch: 28/40... Step: 2540... Loss: 1.5188... Val Loss: 1.5538\n",
            "Epoch: 28/40... Step: 2540... Loss: 1.5542... Val Loss: 1.5539\n",
            "Epoch: 28/40... Step: 2550... Loss: 1.5500... Val Loss: 1.5500\n",
            "Epoch: 28/40... Step: 2550... Loss: 1.5155... Val Loss: 1.5328\n",
            "Epoch: 28/40... Step: 2550... Loss: 1.7316... Val Loss: 1.5990\n",
            "Epoch: 28/40... Step: 2550... Loss: 1.7859... Val Loss: 1.6458\n",
            "Epoch: 28/40... Step: 2550... Loss: 1.5277... Val Loss: 1.6222\n",
            "Epoch: 28/40... Step: 2550... Loss: 1.5339... Val Loss: 1.6075\n",
            "Epoch: 28/40... Step: 2550... Loss: 1.3932... Val Loss: 1.5768\n",
            "Epoch: 28/40... Step: 2550... Loss: 1.5132... Val Loss: 1.5689\n",
            "Epoch: 28/40... Step: 2550... Loss: 1.5242... Val Loss: 1.5639\n",
            "Epoch: 28/40... Step: 2550... Loss: 1.5263... Val Loss: 1.5602\n",
            "Epoch: 28/40... Step: 2560... Loss: 1.5622... Val Loss: 1.5622\n",
            "Epoch: 28/40... Step: 2560... Loss: 1.5317... Val Loss: 1.5470\n",
            "Epoch: 28/40... Step: 2560... Loss: 1.7254... Val Loss: 1.6065\n",
            "Epoch: 28/40... Step: 2560... Loss: 1.7537... Val Loss: 1.6433\n",
            "Epoch: 28/40... Step: 2560... Loss: 1.5287... Val Loss: 1.6204\n",
            "Epoch: 28/40... Step: 2560... Loss: 1.5162... Val Loss: 1.6030\n",
            "Epoch: 28/40... Step: 2560... Loss: 1.3934... Val Loss: 1.5731\n",
            "Epoch: 28/40... Step: 2560... Loss: 1.4993... Val Loss: 1.5638\n",
            "Epoch: 28/40... Step: 2560... Loss: 1.5185... Val Loss: 1.5588\n",
            "Epoch: 28/40... Step: 2560... Loss: 1.5459... Val Loss: 1.5575\n",
            "Epoch: 28/40... Step: 2570... Loss: 1.5470... Val Loss: 1.5470\n",
            "Epoch: 28/40... Step: 2570... Loss: 1.5249... Val Loss: 1.5359\n",
            "Epoch: 28/40... Step: 2570... Loss: 1.7332... Val Loss: 1.6017\n",
            "Epoch: 28/40... Step: 2570... Loss: 1.7571... Val Loss: 1.6406\n",
            "Epoch: 28/40... Step: 2570... Loss: 1.5312... Val Loss: 1.6187\n",
            "Epoch: 28/40... Step: 2570... Loss: 1.5352... Val Loss: 1.6048\n",
            "Epoch: 28/40... Step: 2570... Loss: 1.4164... Val Loss: 1.5779\n",
            "Epoch: 28/40... Step: 2570... Loss: 1.4815... Val Loss: 1.5658\n",
            "Epoch: 28/40... Step: 2570... Loss: 1.5150... Val Loss: 1.5602\n",
            "Epoch: 28/40... Step: 2570... Loss: 1.5200... Val Loss: 1.5562\n",
            "Epoch: 29/40... Step: 2580... Loss: 1.5372... Val Loss: 1.5372\n",
            "Epoch: 29/40... Step: 2580... Loss: 1.5218... Val Loss: 1.5295\n",
            "Epoch: 29/40... Step: 2580... Loss: 1.7444... Val Loss: 1.6011\n",
            "Epoch: 29/40... Step: 2580... Loss: 1.7520... Val Loss: 1.6389\n",
            "Epoch: 29/40... Step: 2580... Loss: 1.5281... Val Loss: 1.6167\n",
            "Epoch: 29/40... Step: 2580... Loss: 1.4821... Val Loss: 1.5943\n",
            "Epoch: 29/40... Step: 2580... Loss: 1.3825... Val Loss: 1.5640\n",
            "Epoch: 29/40... Step: 2580... Loss: 1.4610... Val Loss: 1.5511\n",
            "Epoch: 29/40... Step: 2580... Loss: 1.4856... Val Loss: 1.5438\n",
            "Epoch: 29/40... Step: 2580... Loss: 1.5368... Val Loss: 1.5431\n",
            "Epoch: 29/40... Step: 2590... Loss: 1.5113... Val Loss: 1.5113\n",
            "Epoch: 29/40... Step: 2590... Loss: 1.5057... Val Loss: 1.5085\n",
            "Epoch: 29/40... Step: 2590... Loss: 1.7502... Val Loss: 1.5890\n",
            "Epoch: 29/40... Step: 2590... Loss: 1.7503... Val Loss: 1.6294\n",
            "Epoch: 29/40... Step: 2590... Loss: 1.4753... Val Loss: 1.5986\n",
            "Epoch: 29/40... Step: 2590... Loss: 1.4518... Val Loss: 1.5741\n",
            "Epoch: 29/40... Step: 2590... Loss: 1.3337... Val Loss: 1.5398\n",
            "Epoch: 29/40... Step: 2590... Loss: 1.4441... Val Loss: 1.5278\n",
            "Epoch: 29/40... Step: 2590... Loss: 1.4879... Val Loss: 1.5234\n",
            "Epoch: 29/40... Step: 2590... Loss: 1.5387... Val Loss: 1.5249\n",
            "Epoch: 29/40... Step: 2600... Loss: 1.5119... Val Loss: 1.5119\n",
            "Epoch: 29/40... Step: 2600... Loss: 1.4827... Val Loss: 1.4973\n",
            "Epoch: 29/40... Step: 2600... Loss: 1.7435... Val Loss: 1.5794\n",
            "Epoch: 29/40... Step: 2600... Loss: 1.7442... Val Loss: 1.6206\n",
            "Epoch: 29/40... Step: 2600... Loss: 1.4678... Val Loss: 1.5900\n",
            "Epoch: 29/40... Step: 2600... Loss: 1.4753... Val Loss: 1.5709\n",
            "Epoch: 29/40... Step: 2600... Loss: 1.3398... Val Loss: 1.5379\n",
            "Epoch: 29/40... Step: 2600... Loss: 1.4346... Val Loss: 1.5250\n",
            "Epoch: 29/40... Step: 2600... Loss: 1.4623... Val Loss: 1.5180\n",
            "Epoch: 29/40... Step: 2600... Loss: 1.5037... Val Loss: 1.5166\n",
            "Epoch: 29/40... Step: 2610... Loss: 1.5433... Val Loss: 1.5433\n",
            "Epoch: 29/40... Step: 2610... Loss: 1.4905... Val Loss: 1.5169\n",
            "Epoch: 29/40... Step: 2610... Loss: 1.7150... Val Loss: 1.5829\n",
            "Epoch: 29/40... Step: 2610... Loss: 1.7334... Val Loss: 1.6205\n",
            "Epoch: 29/40... Step: 2610... Loss: 1.4775... Val Loss: 1.5919\n",
            "Epoch: 29/40... Step: 2610... Loss: 1.4756... Val Loss: 1.5725\n",
            "Epoch: 29/40... Step: 2610... Loss: 1.3543... Val Loss: 1.5414\n",
            "Epoch: 29/40... Step: 2610... Loss: 1.4768... Val Loss: 1.5333\n",
            "Epoch: 29/40... Step: 2610... Loss: 1.4764... Val Loss: 1.5270\n",
            "Epoch: 29/40... Step: 2610... Loss: 1.5172... Val Loss: 1.5260\n",
            "Epoch: 29/40... Step: 2620... Loss: 1.5430... Val Loss: 1.5430\n",
            "Epoch: 29/40... Step: 2620... Loss: 1.5165... Val Loss: 1.5297\n",
            "Epoch: 29/40... Step: 2620... Loss: 1.7169... Val Loss: 1.5921\n",
            "Epoch: 29/40... Step: 2620... Loss: 1.7745... Val Loss: 1.6377\n",
            "Epoch: 29/40... Step: 2620... Loss: 1.5076... Val Loss: 1.6117\n",
            "Epoch: 29/40... Step: 2620... Loss: 1.4985... Val Loss: 1.5928\n",
            "Epoch: 29/40... Step: 2620... Loss: 1.3785... Val Loss: 1.5622\n",
            "Epoch: 29/40... Step: 2620... Loss: 1.4455... Val Loss: 1.5476\n",
            "Epoch: 29/40... Step: 2620... Loss: 1.4990... Val Loss: 1.5422\n",
            "Epoch: 29/40... Step: 2620... Loss: 1.5269... Val Loss: 1.5407\n",
            "Epoch: 29/40... Step: 2630... Loss: 1.5600... Val Loss: 1.5600\n",
            "Epoch: 29/40... Step: 2630... Loss: 1.5024... Val Loss: 1.5312\n",
            "Epoch: 29/40... Step: 2630... Loss: 1.7451... Val Loss: 1.6025\n",
            "Epoch: 29/40... Step: 2630... Loss: 1.7506... Val Loss: 1.6395\n",
            "Epoch: 29/40... Step: 2630... Loss: 1.5326... Val Loss: 1.6181\n",
            "Epoch: 29/40... Step: 2630... Loss: 1.5115... Val Loss: 1.6004\n",
            "Epoch: 29/40... Step: 2630... Loss: 1.4015... Val Loss: 1.5720\n",
            "Epoch: 29/40... Step: 2630... Loss: 1.5268... Val Loss: 1.5663\n",
            "Epoch: 29/40... Step: 2630... Loss: 1.5247... Val Loss: 1.5617\n",
            "Epoch: 29/40... Step: 2630... Loss: 1.5482... Val Loss: 1.5603\n",
            "Epoch: 29/40... Step: 2640... Loss: 1.5603... Val Loss: 1.5603\n",
            "Epoch: 29/40... Step: 2640... Loss: 1.5094... Val Loss: 1.5349\n",
            "Epoch: 29/40... Step: 2640... Loss: 1.7433... Val Loss: 1.6043\n",
            "Epoch: 29/40... Step: 2640... Loss: 1.7767... Val Loss: 1.6474\n",
            "Epoch: 29/40... Step: 2640... Loss: 1.5294... Val Loss: 1.6238\n",
            "Epoch: 29/40... Step: 2640... Loss: 1.5234... Val Loss: 1.6071\n",
            "Epoch: 29/40... Step: 2640... Loss: 1.4067... Val Loss: 1.5785\n",
            "Epoch: 29/40... Step: 2640... Loss: 1.5002... Val Loss: 1.5687\n",
            "Epoch: 29/40... Step: 2640... Loss: 1.5131... Val Loss: 1.5625\n",
            "Epoch: 29/40... Step: 2640... Loss: 1.5508... Val Loss: 1.5613\n",
            "Epoch: 29/40... Step: 2650... Loss: 1.5713... Val Loss: 1.5713\n",
            "Epoch: 29/40... Step: 2650... Loss: 1.5423... Val Loss: 1.5568\n",
            "Epoch: 29/40... Step: 2650... Loss: 1.7551... Val Loss: 1.6229\n",
            "Epoch: 29/40... Step: 2650... Loss: 1.7681... Val Loss: 1.6592\n",
            "Epoch: 29/40... Step: 2650... Loss: 1.5465... Val Loss: 1.6366\n",
            "Epoch: 29/40... Step: 2650... Loss: 1.5487... Val Loss: 1.6220\n",
            "Epoch: 29/40... Step: 2650... Loss: 1.4201... Val Loss: 1.5932\n",
            "Epoch: 29/40... Step: 2650... Loss: 1.5008... Val Loss: 1.5816\n",
            "Epoch: 29/40... Step: 2650... Loss: 1.5185... Val Loss: 1.5746\n",
            "Epoch: 29/40... Step: 2650... Loss: 1.5560... Val Loss: 1.5727\n",
            "Epoch: 29/40... Step: 2660... Loss: 1.5581... Val Loss: 1.5581\n",
            "Epoch: 29/40... Step: 2660... Loss: 1.5153... Val Loss: 1.5367\n",
            "Epoch: 29/40... Step: 2660... Loss: 1.7163... Val Loss: 1.5966\n",
            "Epoch: 29/40... Step: 2660... Loss: 1.7680... Val Loss: 1.6394\n",
            "Epoch: 29/40... Step: 2660... Loss: 1.5179... Val Loss: 1.6151\n",
            "Epoch: 29/40... Step: 2660... Loss: 1.5049... Val Loss: 1.5968\n",
            "Epoch: 29/40... Step: 2660... Loss: 1.4064... Val Loss: 1.5696\n",
            "Epoch: 29/40... Step: 2660... Loss: 1.4884... Val Loss: 1.5594\n",
            "Epoch: 29/40... Step: 2660... Loss: 1.5127... Val Loss: 1.5542\n",
            "Epoch: 29/40... Step: 2660... Loss: 1.5538... Val Loss: 1.5542\n",
            "Epoch: 30/40... Step: 2670... Loss: 1.5529... Val Loss: 1.5529\n",
            "Epoch: 30/40... Step: 2670... Loss: 1.5074... Val Loss: 1.5301\n",
            "Epoch: 30/40... Step: 2670... Loss: 1.7322... Val Loss: 1.5975\n",
            "Epoch: 30/40... Step: 2670... Loss: 1.7671... Val Loss: 1.6399\n",
            "Epoch: 30/40... Step: 2670... Loss: 1.5093... Val Loss: 1.6138\n",
            "Epoch: 30/40... Step: 2670... Loss: 1.5062... Val Loss: 1.5959\n",
            "Epoch: 30/40... Step: 2670... Loss: 1.4008... Val Loss: 1.5680\n",
            "Epoch: 30/40... Step: 2670... Loss: 1.4905... Val Loss: 1.5583\n",
            "Epoch: 30/40... Step: 2670... Loss: 1.4854... Val Loss: 1.5502\n",
            "Epoch: 30/40... Step: 2670... Loss: 1.5069... Val Loss: 1.5459\n",
            "Epoch: 30/40... Step: 2680... Loss: 1.5253... Val Loss: 1.5253\n",
            "Epoch: 30/40... Step: 2680... Loss: 1.5031... Val Loss: 1.5142\n",
            "Epoch: 30/40... Step: 2680... Loss: 1.7137... Val Loss: 1.5807\n",
            "Epoch: 30/40... Step: 2680... Loss: 1.7337... Val Loss: 1.6190\n",
            "Epoch: 30/40... Step: 2680... Loss: 1.4987... Val Loss: 1.5949\n",
            "Epoch: 30/40... Step: 2680... Loss: 1.4907... Val Loss: 1.5775\n",
            "Epoch: 30/40... Step: 2680... Loss: 1.3327... Val Loss: 1.5426\n",
            "Epoch: 30/40... Step: 2680... Loss: 1.4349... Val Loss: 1.5291\n",
            "Epoch: 30/40... Step: 2680... Loss: 1.4660... Val Loss: 1.5221\n",
            "Epoch: 30/40... Step: 2680... Loss: 1.5494... Val Loss: 1.5248\n",
            "Epoch: 30/40... Step: 2690... Loss: 1.5205... Val Loss: 1.5205\n",
            "Epoch: 30/40... Step: 2690... Loss: 1.4801... Val Loss: 1.5003\n",
            "Epoch: 30/40... Step: 2690... Loss: 1.7408... Val Loss: 1.5805\n",
            "Epoch: 30/40... Step: 2690... Loss: 1.7399... Val Loss: 1.6203\n",
            "Epoch: 30/40... Step: 2690... Loss: 1.4863... Val Loss: 1.5935\n",
            "Epoch: 30/40... Step: 2690... Loss: 1.4892... Val Loss: 1.5761\n",
            "Epoch: 30/40... Step: 2690... Loss: 1.3254... Val Loss: 1.5403\n",
            "Epoch: 30/40... Step: 2690... Loss: 1.4401... Val Loss: 1.5278\n",
            "Epoch: 30/40... Step: 2690... Loss: 1.4898... Val Loss: 1.5236\n",
            "Epoch: 30/40... Step: 2690... Loss: 1.5388... Val Loss: 1.5251\n",
            "Epoch: 30/40... Step: 2700... Loss: 1.5428... Val Loss: 1.5428\n",
            "Epoch: 30/40... Step: 2700... Loss: 1.4754... Val Loss: 1.5091\n",
            "Epoch: 30/40... Step: 2700... Loss: 1.7341... Val Loss: 1.5841\n",
            "Epoch: 30/40... Step: 2700... Loss: 1.7606... Val Loss: 1.6282\n",
            "Epoch: 30/40... Step: 2700... Loss: 1.4771... Val Loss: 1.5980\n",
            "Epoch: 30/40... Step: 2700... Loss: 1.4670... Val Loss: 1.5762\n",
            "Epoch: 30/40... Step: 2700... Loss: 1.3178... Val Loss: 1.5393\n",
            "Epoch: 30/40... Step: 2700... Loss: 1.4805... Val Loss: 1.5319\n",
            "Epoch: 30/40... Step: 2700... Loss: 1.4591... Val Loss: 1.5238\n",
            "Epoch: 30/40... Step: 2700... Loss: 1.5235... Val Loss: 1.5238\n",
            "Epoch: 30/40... Step: 2710... Loss: 1.5426... Val Loss: 1.5426\n",
            "Epoch: 30/40... Step: 2710... Loss: 1.5028... Val Loss: 1.5227\n",
            "Epoch: 30/40... Step: 2710... Loss: 1.7705... Val Loss: 1.6053\n",
            "Epoch: 30/40... Step: 2710... Loss: 1.7766... Val Loss: 1.6481\n",
            "Epoch: 30/40... Step: 2710... Loss: 1.5167... Val Loss: 1.6218\n",
            "Epoch: 30/40... Step: 2710... Loss: 1.4921... Val Loss: 1.6002\n",
            "Epoch: 30/40... Step: 2710... Loss: 1.3724... Val Loss: 1.5677\n",
            "Epoch: 30/40... Step: 2710... Loss: 1.5023... Val Loss: 1.5595\n",
            "Epoch: 30/40... Step: 2710... Loss: 1.4922... Val Loss: 1.5520\n",
            "Epoch: 30/40... Step: 2710... Loss: 1.5584... Val Loss: 1.5527\n",
            "Epoch: 30/40... Step: 2720... Loss: 1.5585... Val Loss: 1.5585\n",
            "Epoch: 30/40... Step: 2720... Loss: 1.5365... Val Loss: 1.5475\n",
            "Epoch: 30/40... Step: 2720... Loss: 1.7580... Val Loss: 1.6177\n",
            "Epoch: 30/40... Step: 2720... Loss: 1.7709... Val Loss: 1.6560\n",
            "Epoch: 30/40... Step: 2720... Loss: 1.5006... Val Loss: 1.6249\n",
            "Epoch: 30/40... Step: 2720... Loss: 1.5072... Val Loss: 1.6053\n",
            "Epoch: 30/40... Step: 2720... Loss: 1.4122... Val Loss: 1.5777\n",
            "Epoch: 30/40... Step: 2720... Loss: 1.4942... Val Loss: 1.5673\n",
            "Epoch: 30/40... Step: 2720... Loss: 1.5276... Val Loss: 1.5629\n",
            "Epoch: 30/40... Step: 2720... Loss: 1.5512... Val Loss: 1.5617\n",
            "Epoch: 30/40... Step: 2730... Loss: 1.5598... Val Loss: 1.5598\n",
            "Epoch: 30/40... Step: 2730... Loss: 1.5379... Val Loss: 1.5488\n",
            "Epoch: 30/40... Step: 2730... Loss: 1.7456... Val Loss: 1.6144\n",
            "Epoch: 30/40... Step: 2730... Loss: 1.7983... Val Loss: 1.6604\n",
            "Epoch: 30/40... Step: 2730... Loss: 1.5302... Val Loss: 1.6344\n",
            "Epoch: 30/40... Step: 2730... Loss: 1.5315... Val Loss: 1.6172\n",
            "Epoch: 30/40... Step: 2730... Loss: 1.4198... Val Loss: 1.5890\n",
            "Epoch: 30/40... Step: 2730... Loss: 1.4950... Val Loss: 1.5773\n",
            "Epoch: 30/40... Step: 2730... Loss: 1.5179... Val Loss: 1.5707\n",
            "Epoch: 30/40... Step: 2730... Loss: 1.5748... Val Loss: 1.5711\n",
            "Epoch: 30/40... Step: 2740... Loss: 1.5662... Val Loss: 1.5662\n",
            "Epoch: 30/40... Step: 2740... Loss: 1.5407... Val Loss: 1.5535\n",
            "Epoch: 30/40... Step: 2740... Loss: 1.7813... Val Loss: 1.6294\n",
            "Epoch: 30/40... Step: 2740... Loss: 1.7742... Val Loss: 1.6656\n",
            "Epoch: 30/40... Step: 2740... Loss: 1.5626... Val Loss: 1.6450\n",
            "Epoch: 30/40... Step: 2740... Loss: 1.5369... Val Loss: 1.6270\n",
            "Epoch: 30/40... Step: 2740... Loss: 1.4062... Val Loss: 1.5954\n",
            "Epoch: 30/40... Step: 2740... Loss: 1.5103... Val Loss: 1.5848\n",
            "Epoch: 30/40... Step: 2740... Loss: 1.5232... Val Loss: 1.5780\n",
            "Epoch: 30/40... Step: 2740... Loss: 1.5858... Val Loss: 1.5787\n",
            "Epoch: 30/40... Step: 2750... Loss: 1.5636... Val Loss: 1.5636\n",
            "Epoch: 30/40... Step: 2750... Loss: 1.5403... Val Loss: 1.5520\n",
            "Epoch: 30/40... Step: 2750... Loss: 1.7664... Val Loss: 1.6234\n",
            "Epoch: 30/40... Step: 2750... Loss: 1.8063... Val Loss: 1.6692\n",
            "Epoch: 30/40... Step: 2750... Loss: 1.5463... Val Loss: 1.6446\n",
            "Epoch: 30/40... Step: 2750... Loss: 1.5215... Val Loss: 1.6241\n",
            "Epoch: 30/40... Step: 2750... Loss: 1.4122... Val Loss: 1.5938\n",
            "Epoch: 30/40... Step: 2750... Loss: 1.4883... Val Loss: 1.5806\n",
            "Epoch: 30/40... Step: 2750... Loss: 1.5274... Val Loss: 1.5747\n",
            "Epoch: 30/40... Step: 2750... Loss: 1.5553... Val Loss: 1.5728\n",
            "Epoch: 30/40... Step: 2760... Loss: 1.5664... Val Loss: 1.5664\n",
            "Epoch: 30/40... Step: 2760... Loss: 1.5166... Val Loss: 1.5415\n",
            "Epoch: 30/40... Step: 2760... Loss: 1.7512... Val Loss: 1.6114\n",
            "Epoch: 30/40... Step: 2760... Loss: 1.7662... Val Loss: 1.6501\n",
            "Epoch: 30/40... Step: 2760... Loss: 1.5395... Val Loss: 1.6280\n",
            "Epoch: 30/40... Step: 2760... Loss: 1.4998... Val Loss: 1.6066\n",
            "Epoch: 30/40... Step: 2760... Loss: 1.4107... Val Loss: 1.5786\n",
            "Epoch: 30/40... Step: 2760... Loss: 1.4705... Val Loss: 1.5651\n",
            "Epoch: 30/40... Step: 2760... Loss: 1.5154... Val Loss: 1.5596\n",
            "Epoch: 30/40... Step: 2760... Loss: 1.5381... Val Loss: 1.5574\n",
            "Epoch: 31/40... Step: 2770... Loss: 1.5344... Val Loss: 1.5344\n",
            "Epoch: 31/40... Step: 2770... Loss: 1.5270... Val Loss: 1.5307\n",
            "Epoch: 31/40... Step: 2770... Loss: 1.7259... Val Loss: 1.5958\n",
            "Epoch: 31/40... Step: 2770... Loss: 1.7863... Val Loss: 1.6434\n",
            "Epoch: 31/40... Step: 2770... Loss: 1.5070... Val Loss: 1.6161\n",
            "Epoch: 31/40... Step: 2770... Loss: 1.4700... Val Loss: 1.5918\n",
            "Epoch: 31/40... Step: 2770... Loss: 1.3441... Val Loss: 1.5564\n",
            "Epoch: 31/40... Step: 2770... Loss: 1.4709... Val Loss: 1.5457\n",
            "Epoch: 31/40... Step: 2770... Loss: 1.4732... Val Loss: 1.5376\n",
            "Epoch: 31/40... Step: 2770... Loss: 1.5245... Val Loss: 1.5363\n",
            "Epoch: 31/40... Step: 2780... Loss: 1.5158... Val Loss: 1.5158\n",
            "Epoch: 31/40... Step: 2780... Loss: 1.4925... Val Loss: 1.5041\n",
            "Epoch: 31/40... Step: 2780... Loss: 1.7559... Val Loss: 1.5881\n",
            "Epoch: 31/40... Step: 2780... Loss: 1.7540... Val Loss: 1.6295\n",
            "Epoch: 31/40... Step: 2780... Loss: 1.5141... Val Loss: 1.6064\n",
            "Epoch: 31/40... Step: 2780... Loss: 1.4725... Val Loss: 1.5841\n",
            "Epoch: 31/40... Step: 2780... Loss: 1.3537... Val Loss: 1.5512\n",
            "Epoch: 31/40... Step: 2780... Loss: 1.4610... Val Loss: 1.5399\n",
            "Epoch: 31/40... Step: 2780... Loss: 1.4833... Val Loss: 1.5336\n",
            "Epoch: 31/40... Step: 2780... Loss: 1.5243... Val Loss: 1.5327\n",
            "Epoch: 31/40... Step: 2790... Loss: 1.5311... Val Loss: 1.5311\n",
            "Epoch: 31/40... Step: 2790... Loss: 1.4987... Val Loss: 1.5149\n",
            "Epoch: 31/40... Step: 2790... Loss: 1.7334... Val Loss: 1.5877\n",
            "Epoch: 31/40... Step: 2790... Loss: 1.7588... Val Loss: 1.6305\n",
            "Epoch: 31/40... Step: 2790... Loss: 1.5022... Val Loss: 1.6048\n",
            "Epoch: 31/40... Step: 2790... Loss: 1.4695... Val Loss: 1.5823\n",
            "Epoch: 31/40... Step: 2790... Loss: 1.3679... Val Loss: 1.5517\n",
            "Epoch: 31/40... Step: 2790... Loss: 1.4664... Val Loss: 1.5410\n",
            "Epoch: 31/40... Step: 2790... Loss: 1.4790... Val Loss: 1.5341\n",
            "Epoch: 31/40... Step: 2790... Loss: 1.5258... Val Loss: 1.5333\n",
            "Epoch: 31/40... Step: 2800... Loss: 1.5510... Val Loss: 1.5510\n",
            "Epoch: 31/40... Step: 2800... Loss: 1.4973... Val Loss: 1.5242\n",
            "Epoch: 31/40... Step: 2800... Loss: 1.7831... Val Loss: 1.6105\n",
            "Epoch: 31/40... Step: 2800... Loss: 1.7459... Val Loss: 1.6444\n",
            "Epoch: 31/40... Step: 2800... Loss: 1.4958... Val Loss: 1.6146\n",
            "Epoch: 31/40... Step: 2800... Loss: 1.4609... Val Loss: 1.5890\n",
            "Epoch: 31/40... Step: 2800... Loss: 1.3548... Val Loss: 1.5556\n",
            "Epoch: 31/40... Step: 2800... Loss: 1.5194... Val Loss: 1.5510\n",
            "Epoch: 31/40... Step: 2800... Loss: 1.5212... Val Loss: 1.5477\n",
            "Epoch: 31/40... Step: 2800... Loss: 1.5352... Val Loss: 1.5465\n",
            "Epoch: 31/40... Step: 2810... Loss: 1.5613... Val Loss: 1.5613\n",
            "Epoch: 31/40... Step: 2810... Loss: 1.5052... Val Loss: 1.5333\n",
            "Epoch: 31/40... Step: 2810... Loss: 1.7353... Val Loss: 1.6006\n",
            "Epoch: 31/40... Step: 2810... Loss: 1.7872... Val Loss: 1.6472\n",
            "Epoch: 31/40... Step: 2810... Loss: 1.5265... Val Loss: 1.6231\n",
            "Epoch: 31/40... Step: 2810... Loss: 1.5042... Val Loss: 1.6033\n",
            "Epoch: 31/40... Step: 2810... Loss: 1.3848... Val Loss: 1.5721\n",
            "Epoch: 31/40... Step: 2810... Loss: 1.5190... Val Loss: 1.5654\n",
            "Epoch: 31/40... Step: 2810... Loss: 1.5464... Val Loss: 1.5633\n",
            "Epoch: 31/40... Step: 2810... Loss: 1.5588... Val Loss: 1.5629\n",
            "Epoch: 31/40... Step: 2820... Loss: 1.5729... Val Loss: 1.5729\n",
            "Epoch: 31/40... Step: 2820... Loss: 1.4982... Val Loss: 1.5355\n",
            "Epoch: 31/40... Step: 2820... Loss: 1.7329... Val Loss: 1.6013\n",
            "Epoch: 31/40... Step: 2820... Loss: 1.7986... Val Loss: 1.6507\n",
            "Epoch: 31/40... Step: 2820... Loss: 1.5182... Val Loss: 1.6242\n",
            "Epoch: 31/40... Step: 2820... Loss: 1.5141... Val Loss: 1.6058\n",
            "Epoch: 31/40... Step: 2820... Loss: 1.4347... Val Loss: 1.5814\n",
            "Epoch: 31/40... Step: 2820... Loss: 1.5315... Val Loss: 1.5751\n",
            "Epoch: 31/40... Step: 2820... Loss: 1.5393... Val Loss: 1.5712\n",
            "Epoch: 31/40... Step: 2820... Loss: 1.5489... Val Loss: 1.5689\n",
            "Epoch: 31/40... Step: 2830... Loss: 1.5661... Val Loss: 1.5661\n",
            "Epoch: 31/40... Step: 2830... Loss: 1.5301... Val Loss: 1.5481\n",
            "Epoch: 31/40... Step: 2830... Loss: 1.7492... Val Loss: 1.6151\n",
            "Epoch: 31/40... Step: 2830... Loss: 1.7827... Val Loss: 1.6570\n",
            "Epoch: 31/40... Step: 2830... Loss: 1.5412... Val Loss: 1.6338\n",
            "Epoch: 31/40... Step: 2830... Loss: 1.5254... Val Loss: 1.6158\n",
            "Epoch: 31/40... Step: 2830... Loss: 1.4244... Val Loss: 1.5884\n",
            "Epoch: 31/40... Step: 2830... Loss: 1.5169... Val Loss: 1.5795\n",
            "Epoch: 31/40... Step: 2830... Loss: 1.5445... Val Loss: 1.5756\n",
            "Epoch: 31/40... Step: 2830... Loss: 1.5718... Val Loss: 1.5752\n",
            "Epoch: 31/40... Step: 2840... Loss: 1.5642... Val Loss: 1.5642\n",
            "Epoch: 31/40... Step: 2840... Loss: 1.5522... Val Loss: 1.5582\n",
            "Epoch: 31/40... Step: 2840... Loss: 1.7753... Val Loss: 1.6306\n",
            "Epoch: 31/40... Step: 2840... Loss: 1.7933... Val Loss: 1.6713\n",
            "Epoch: 31/40... Step: 2840... Loss: 1.5264... Val Loss: 1.6423\n",
            "Epoch: 31/40... Step: 2840... Loss: 1.5471... Val Loss: 1.6264\n",
            "Epoch: 31/40... Step: 2840... Loss: 1.4245... Val Loss: 1.5976\n",
            "Epoch: 31/40... Step: 2840... Loss: 1.5083... Val Loss: 1.5864\n",
            "Epoch: 31/40... Step: 2840... Loss: 1.5521... Val Loss: 1.5826\n",
            "Epoch: 31/40... Step: 2840... Loss: 1.5830... Val Loss: 1.5827\n",
            "Epoch: 31/40... Step: 2850... Loss: 1.5609... Val Loss: 1.5609\n",
            "Epoch: 31/40... Step: 2850... Loss: 1.5126... Val Loss: 1.5368\n",
            "Epoch: 31/40... Step: 2850... Loss: 1.7363... Val Loss: 1.6033\n",
            "Epoch: 31/40... Step: 2850... Loss: 1.7765... Val Loss: 1.6466\n",
            "Epoch: 31/40... Step: 2850... Loss: 1.5171... Val Loss: 1.6207\n",
            "Epoch: 31/40... Step: 2850... Loss: 1.5180... Val Loss: 1.6036\n",
            "Epoch: 31/40... Step: 2850... Loss: 1.4200... Val Loss: 1.5773\n",
            "Epoch: 31/40... Step: 2850... Loss: 1.4510... Val Loss: 1.5615\n",
            "Epoch: 31/40... Step: 2850... Loss: 1.5403... Val Loss: 1.5592\n",
            "Epoch: 31/40... Step: 2850... Loss: 1.5544... Val Loss: 1.5587\n",
            "Epoch: 32/40... Step: 2860... Loss: 1.5366... Val Loss: 1.5366\n",
            "Epoch: 32/40... Step: 2860... Loss: 1.5162... Val Loss: 1.5264\n",
            "Epoch: 32/40... Step: 2860... Loss: 1.7373... Val Loss: 1.5967\n",
            "Epoch: 32/40... Step: 2860... Loss: 1.7616... Val Loss: 1.6379\n",
            "Epoch: 32/40... Step: 2860... Loss: 1.5243... Val Loss: 1.6152\n",
            "Epoch: 32/40... Step: 2860... Loss: 1.4850... Val Loss: 1.5935\n",
            "Epoch: 32/40... Step: 2860... Loss: 1.3849... Val Loss: 1.5637\n",
            "Epoch: 32/40... Step: 2860... Loss: 1.4674... Val Loss: 1.5517\n",
            "Epoch: 32/40... Step: 2860... Loss: 1.5012... Val Loss: 1.5461\n",
            "Epoch: 32/40... Step: 2860... Loss: 1.5401... Val Loss: 1.5455\n",
            "Epoch: 32/40... Step: 2870... Loss: 1.5182... Val Loss: 1.5182\n",
            "Epoch: 32/40... Step: 2870... Loss: 1.5196... Val Loss: 1.5189\n",
            "Epoch: 32/40... Step: 2870... Loss: 1.7626... Val Loss: 1.6001\n",
            "Epoch: 32/40... Step: 2870... Loss: 1.7857... Val Loss: 1.6465\n",
            "Epoch: 32/40... Step: 2870... Loss: 1.4988... Val Loss: 1.6170\n",
            "Epoch: 32/40... Step: 2870... Loss: 1.4630... Val Loss: 1.5913\n",
            "Epoch: 32/40... Step: 2870... Loss: 1.3598... Val Loss: 1.5582\n",
            "Epoch: 32/40... Step: 2870... Loss: 1.4698... Val Loss: 1.5472\n",
            "Epoch: 32/40... Step: 2870... Loss: 1.4602... Val Loss: 1.5375\n",
            "Epoch: 32/40... Step: 2870... Loss: 1.5666... Val Loss: 1.5404\n",
            "Epoch: 32/40... Step: 2880... Loss: 1.5168... Val Loss: 1.5168\n",
            "Epoch: 32/40... Step: 2880... Loss: 1.4842... Val Loss: 1.5005\n",
            "Epoch: 32/40... Step: 2880... Loss: 1.7529... Val Loss: 1.5846\n",
            "Epoch: 32/40... Step: 2880... Loss: 1.7453... Val Loss: 1.6248\n",
            "Epoch: 32/40... Step: 2880... Loss: 1.4903... Val Loss: 1.5979\n",
            "Epoch: 32/40... Step: 2880... Loss: 1.4558... Val Loss: 1.5742\n",
            "Epoch: 32/40... Step: 2880... Loss: 1.3210... Val Loss: 1.5380\n",
            "Epoch: 32/40... Step: 2880... Loss: 1.4592... Val Loss: 1.5282\n",
            "Epoch: 32/40... Step: 2880... Loss: 1.4776... Val Loss: 1.5226\n",
            "Epoch: 32/40... Step: 2880... Loss: 1.5329... Val Loss: 1.5236\n",
            "Epoch: 32/40... Step: 2890... Loss: 1.5479... Val Loss: 1.5479\n",
            "Epoch: 32/40... Step: 2890... Loss: 1.5071... Val Loss: 1.5275\n",
            "Epoch: 32/40... Step: 2890... Loss: 1.7678... Val Loss: 1.6076\n",
            "Epoch: 32/40... Step: 2890... Loss: 1.7562... Val Loss: 1.6447\n",
            "Epoch: 32/40... Step: 2890... Loss: 1.5160... Val Loss: 1.6190\n",
            "Epoch: 32/40... Step: 2890... Loss: 1.4736... Val Loss: 1.5948\n",
            "Epoch: 32/40... Step: 2890... Loss: 1.3726... Val Loss: 1.5630\n",
            "Epoch: 32/40... Step: 2890... Loss: 1.4945... Val Loss: 1.5545\n",
            "Epoch: 32/40... Step: 2890... Loss: 1.5218... Val Loss: 1.5508\n",
            "Epoch: 32/40... Step: 2890... Loss: 1.5345... Val Loss: 1.5492\n",
            "Epoch: 32/40... Step: 2900... Loss: 1.5710... Val Loss: 1.5710\n",
            "Epoch: 32/40... Step: 2900... Loss: 1.5349... Val Loss: 1.5529\n",
            "Epoch: 32/40... Step: 2900... Loss: 1.7818... Val Loss: 1.6292\n",
            "Epoch: 32/40... Step: 2900... Loss: 1.8181... Val Loss: 1.6764\n",
            "Epoch: 32/40... Step: 2900... Loss: 1.5372... Val Loss: 1.6486\n",
            "Epoch: 32/40... Step: 2900... Loss: 1.5284... Val Loss: 1.6285\n",
            "Epoch: 32/40... Step: 2900... Loss: 1.4032... Val Loss: 1.5964\n",
            "Epoch: 32/40... Step: 2900... Loss: 1.5070... Val Loss: 1.5852\n",
            "Epoch: 32/40... Step: 2900... Loss: 1.5067... Val Loss: 1.5765\n",
            "Epoch: 32/40... Step: 2900... Loss: 1.5595... Val Loss: 1.5748\n",
            "Epoch: 32/40... Step: 2910... Loss: 1.5790... Val Loss: 1.5790\n",
            "Epoch: 32/40... Step: 2910... Loss: 1.5354... Val Loss: 1.5572\n",
            "Epoch: 32/40... Step: 2910... Loss: 1.7831... Val Loss: 1.6325\n",
            "Epoch: 32/40... Step: 2910... Loss: 1.7936... Val Loss: 1.6728\n",
            "Epoch: 32/40... Step: 2910... Loss: 1.5164... Val Loss: 1.6415\n",
            "Epoch: 32/40... Step: 2910... Loss: 1.5130... Val Loss: 1.6201\n",
            "Epoch: 32/40... Step: 2910... Loss: 1.4173... Val Loss: 1.5911\n",
            "Epoch: 32/40... Step: 2910... Loss: 1.5152... Val Loss: 1.5816\n",
            "Epoch: 32/40... Step: 2910... Loss: 1.5550... Val Loss: 1.5787\n",
            "Epoch: 32/40... Step: 2910... Loss: 1.5854... Val Loss: 1.5794\n",
            "Epoch: 32/40... Step: 2920... Loss: 1.5744... Val Loss: 1.5744\n",
            "Epoch: 32/40... Step: 2920... Loss: 1.5265... Val Loss: 1.5505\n",
            "Epoch: 32/40... Step: 2920... Loss: 1.7819... Val Loss: 1.6276\n",
            "Epoch: 32/40... Step: 2920... Loss: 1.8114... Val Loss: 1.6736\n",
            "Epoch: 32/40... Step: 2920... Loss: 1.5538... Val Loss: 1.6496\n",
            "Epoch: 32/40... Step: 2920... Loss: 1.5349... Val Loss: 1.6305\n",
            "Epoch: 32/40... Step: 2920... Loss: 1.4240... Val Loss: 1.6010\n",
            "Epoch: 32/40... Step: 2920... Loss: 1.5032... Val Loss: 1.5888\n",
            "Epoch: 32/40... Step: 2920... Loss: 1.5254... Val Loss: 1.5817\n",
            "Epoch: 32/40... Step: 2920... Loss: 1.5792... Val Loss: 1.5815\n",
            "Epoch: 32/40... Step: 2930... Loss: 1.5767... Val Loss: 1.5767\n",
            "Epoch: 32/40... Step: 2930... Loss: 1.5581... Val Loss: 1.5674\n",
            "Epoch: 32/40... Step: 2930... Loss: 1.7984... Val Loss: 1.6444\n",
            "Epoch: 32/40... Step: 2930... Loss: 1.7723... Val Loss: 1.6764\n",
            "Epoch: 32/40... Step: 2930... Loss: 1.5469... Val Loss: 1.6505\n",
            "Epoch: 32/40... Step: 2930... Loss: 1.5278... Val Loss: 1.6300\n",
            "Epoch: 32/40... Step: 2930... Loss: 1.4117... Val Loss: 1.5989\n",
            "Epoch: 32/40... Step: 2930... Loss: 1.4862... Val Loss: 1.5848\n",
            "Epoch: 32/40... Step: 2930... Loss: 1.5289... Val Loss: 1.5786\n",
            "Epoch: 32/40... Step: 2930... Loss: 1.5737... Val Loss: 1.5781\n",
            "Epoch: 32/40... Step: 2940... Loss: 1.5737... Val Loss: 1.5737\n",
            "Epoch: 32/40... Step: 2940... Loss: 1.5227... Val Loss: 1.5482\n",
            "Epoch: 32/40... Step: 2940... Loss: 1.7816... Val Loss: 1.6260\n",
            "Epoch: 32/40... Step: 2940... Loss: 1.7996... Val Loss: 1.6694\n",
            "Epoch: 32/40... Step: 2940... Loss: 1.5198... Val Loss: 1.6395\n",
            "Epoch: 32/40... Step: 2940... Loss: 1.5089... Val Loss: 1.6177\n",
            "Epoch: 32/40... Step: 2940... Loss: 1.4219... Val Loss: 1.5897\n",
            "Epoch: 32/40... Step: 2940... Loss: 1.4862... Val Loss: 1.5768\n",
            "Epoch: 32/40... Step: 2940... Loss: 1.5332... Val Loss: 1.5720\n",
            "Epoch: 32/40... Step: 2940... Loss: 1.5523... Val Loss: 1.5700\n",
            "Epoch: 33/40... Step: 2950... Loss: 1.5483... Val Loss: 1.5483\n",
            "Epoch: 33/40... Step: 2950... Loss: 1.5241... Val Loss: 1.5362\n",
            "Epoch: 33/40... Step: 2950... Loss: 1.7471... Val Loss: 1.6065\n",
            "Epoch: 33/40... Step: 2950... Loss: 1.7455... Val Loss: 1.6413\n",
            "Epoch: 33/40... Step: 2950... Loss: 1.5061... Val Loss: 1.6142\n",
            "Epoch: 33/40... Step: 2950... Loss: 1.4990... Val Loss: 1.5950\n",
            "Epoch: 33/40... Step: 2950... Loss: 1.3893... Val Loss: 1.5656\n",
            "Epoch: 33/40... Step: 2950... Loss: 1.4713... Val Loss: 1.5539\n",
            "Epoch: 33/40... Step: 2950... Loss: 1.5204... Val Loss: 1.5501\n",
            "Epoch: 33/40... Step: 2950... Loss: 1.5519... Val Loss: 1.5503\n",
            "Epoch: 33/40... Step: 2960... Loss: 1.5255... Val Loss: 1.5255\n",
            "Epoch: 33/40... Step: 2960... Loss: 1.5387... Val Loss: 1.5321\n",
            "Epoch: 33/40... Step: 2960... Loss: 1.7675... Val Loss: 1.6105\n",
            "Epoch: 33/40... Step: 2960... Loss: 1.7598... Val Loss: 1.6478\n",
            "Epoch: 33/40... Step: 2960... Loss: 1.5081... Val Loss: 1.6199\n",
            "Epoch: 33/40... Step: 2960... Loss: 1.4891... Val Loss: 1.5981\n",
            "Epoch: 33/40... Step: 2960... Loss: 1.3566... Val Loss: 1.5636\n",
            "Epoch: 33/40... Step: 2960... Loss: 1.4761... Val Loss: 1.5527\n",
            "Epoch: 33/40... Step: 2960... Loss: 1.4993... Val Loss: 1.5467\n",
            "Epoch: 33/40... Step: 2960... Loss: 1.5556... Val Loss: 1.5476\n",
            "Epoch: 33/40... Step: 2970... Loss: 1.5355... Val Loss: 1.5355\n",
            "Epoch: 33/40... Step: 2970... Loss: 1.5118... Val Loss: 1.5237\n",
            "Epoch: 33/40... Step: 2970... Loss: 1.7835... Val Loss: 1.6103\n",
            "Epoch: 33/40... Step: 2970... Loss: 1.7658... Val Loss: 1.6492\n",
            "Epoch: 33/40... Step: 2970... Loss: 1.4990... Val Loss: 1.6191\n",
            "Epoch: 33/40... Step: 2970... Loss: 1.4438... Val Loss: 1.5899\n",
            "Epoch: 33/40... Step: 2970... Loss: 1.3543... Val Loss: 1.5562\n",
            "Epoch: 33/40... Step: 2970... Loss: 1.4678... Val Loss: 1.5452\n",
            "Epoch: 33/40... Step: 2970... Loss: 1.4924... Val Loss: 1.5393\n",
            "Epoch: 33/40... Step: 2970... Loss: 1.5500... Val Loss: 1.5404\n",
            "Epoch: 33/40... Step: 2980... Loss: 1.5660... Val Loss: 1.5660\n",
            "Epoch: 33/40... Step: 2980... Loss: 1.5096... Val Loss: 1.5378\n",
            "Epoch: 33/40... Step: 2980... Loss: 1.7860... Val Loss: 1.6205\n",
            "Epoch: 33/40... Step: 2980... Loss: 1.7404... Val Loss: 1.6505\n",
            "Epoch: 33/40... Step: 2980... Loss: 1.5340... Val Loss: 1.6272\n",
            "Epoch: 33/40... Step: 2980... Loss: 1.4626... Val Loss: 1.5998\n",
            "Epoch: 33/40... Step: 2980... Loss: 1.3575... Val Loss: 1.5652\n",
            "Epoch: 33/40... Step: 2980... Loss: 1.4906... Val Loss: 1.5558\n",
            "Epoch: 33/40... Step: 2980... Loss: 1.4944... Val Loss: 1.5490\n",
            "Epoch: 33/40... Step: 2980... Loss: 1.5343... Val Loss: 1.5475\n",
            "Epoch: 33/40... Step: 2990... Loss: 1.5755... Val Loss: 1.5755\n",
            "Epoch: 33/40... Step: 2990... Loss: 1.5357... Val Loss: 1.5556\n",
            "Epoch: 33/40... Step: 2990... Loss: 1.7602... Val Loss: 1.6238\n",
            "Epoch: 33/40... Step: 2990... Loss: 1.8276... Val Loss: 1.6747\n",
            "Epoch: 33/40... Step: 2990... Loss: 1.5470... Val Loss: 1.6492\n",
            "Epoch: 33/40... Step: 2990... Loss: 1.5164... Val Loss: 1.6270\n",
            "Epoch: 33/40... Step: 2990... Loss: 1.4269... Val Loss: 1.5984\n",
            "Epoch: 33/40... Step: 2990... Loss: 1.5255... Val Loss: 1.5893\n",
            "Epoch: 33/40... Step: 2990... Loss: 1.5399... Val Loss: 1.5838\n",
            "Epoch: 33/40... Step: 2990... Loss: 1.5987... Val Loss: 1.5853\n",
            "Epoch: 33/40... Step: 3000... Loss: 1.5827... Val Loss: 1.5827\n",
            "Epoch: 33/40... Step: 3000... Loss: 1.5451... Val Loss: 1.5639\n",
            "Epoch: 33/40... Step: 3000... Loss: 1.7605... Val Loss: 1.6294\n",
            "Epoch: 33/40... Step: 3000... Loss: 1.7992... Val Loss: 1.6719\n",
            "Epoch: 33/40... Step: 3000... Loss: 1.5482... Val Loss: 1.6472\n",
            "Epoch: 33/40... Step: 3000... Loss: 1.5292... Val Loss: 1.6275\n",
            "Epoch: 33/40... Step: 3000... Loss: 1.4198... Val Loss: 1.5978\n",
            "Epoch: 33/40... Step: 3000... Loss: 1.5515... Val Loss: 1.5920\n",
            "Epoch: 33/40... Step: 3000... Loss: 1.5228... Val Loss: 1.5843\n",
            "Epoch: 33/40... Step: 3000... Loss: 1.5811... Val Loss: 1.5840\n",
            "Epoch: 33/40... Step: 3010... Loss: 1.5830... Val Loss: 1.5830\n",
            "Epoch: 33/40... Step: 3010... Loss: 1.5559... Val Loss: 1.5695\n",
            "Epoch: 33/40... Step: 3010... Loss: 1.7602... Val Loss: 1.6330\n",
            "Epoch: 33/40... Step: 3010... Loss: 1.8042... Val Loss: 1.6758\n",
            "Epoch: 33/40... Step: 3010... Loss: 1.5772... Val Loss: 1.6561\n",
            "Epoch: 33/40... Step: 3010... Loss: 1.5405... Val Loss: 1.6368\n",
            "Epoch: 33/40... Step: 3010... Loss: 1.4485... Val Loss: 1.6099\n",
            "Epoch: 33/40... Step: 3010... Loss: 1.5431... Val Loss: 1.6016\n",
            "Epoch: 33/40... Step: 3010... Loss: 1.5661... Val Loss: 1.5976\n",
            "Epoch: 33/40... Step: 3010... Loss: 1.5853... Val Loss: 1.5964\n",
            "Epoch: 33/40... Step: 3020... Loss: 1.5876... Val Loss: 1.5876\n",
            "Epoch: 33/40... Step: 3020... Loss: 1.5735... Val Loss: 1.5806\n",
            "Epoch: 33/40... Step: 3020... Loss: 1.7802... Val Loss: 1.6471\n",
            "Epoch: 33/40... Step: 3020... Loss: 1.8214... Val Loss: 1.6907\n",
            "Epoch: 33/40... Step: 3020... Loss: 1.5661... Val Loss: 1.6658\n",
            "Epoch: 33/40... Step: 3020... Loss: 1.5584... Val Loss: 1.6479\n",
            "Epoch: 33/40... Step: 3020... Loss: 1.4203... Val Loss: 1.6154\n",
            "Epoch: 33/40... Step: 3020... Loss: 1.5188... Val Loss: 1.6033\n",
            "Epoch: 33/40... Step: 3020... Loss: 1.5191... Val Loss: 1.5939\n",
            "Epoch: 33/40... Step: 3020... Loss: 1.5761... Val Loss: 1.5922\n",
            "Epoch: 33/40... Step: 3030... Loss: 1.5844... Val Loss: 1.5844\n",
            "Epoch: 33/40... Step: 3030... Loss: 1.5202... Val Loss: 1.5523\n",
            "Epoch: 33/40... Step: 3030... Loss: 1.7736... Val Loss: 1.6261\n",
            "Epoch: 33/40... Step: 3030... Loss: 1.8116... Val Loss: 1.6724\n",
            "Epoch: 33/40... Step: 3030... Loss: 1.5329... Val Loss: 1.6445\n",
            "Epoch: 33/40... Step: 3030... Loss: 1.5569... Val Loss: 1.6299\n",
            "Epoch: 33/40... Step: 3030... Loss: 1.4348... Val Loss: 1.6020\n",
            "Epoch: 33/40... Step: 3030... Loss: 1.4793... Val Loss: 1.5867\n",
            "Epoch: 33/40... Step: 3030... Loss: 1.5224... Val Loss: 1.5796\n",
            "Epoch: 33/40... Step: 3030... Loss: 1.5549... Val Loss: 1.5771\n",
            "Epoch: 34/40... Step: 3040... Loss: 1.5712... Val Loss: 1.5712\n",
            "Epoch: 34/40... Step: 3040... Loss: 1.5346... Val Loss: 1.5529\n",
            "Epoch: 34/40... Step: 3040... Loss: 1.7830... Val Loss: 1.6296\n",
            "Epoch: 34/40... Step: 3040... Loss: 1.7868... Val Loss: 1.6689\n",
            "Epoch: 34/40... Step: 3040... Loss: 1.5295... Val Loss: 1.6410\n",
            "Epoch: 34/40... Step: 3040... Loss: 1.5109... Val Loss: 1.6193\n",
            "Epoch: 34/40... Step: 3040... Loss: 1.3916... Val Loss: 1.5868\n",
            "Epoch: 34/40... Step: 3040... Loss: 1.5126... Val Loss: 1.5775\n",
            "Epoch: 34/40... Step: 3040... Loss: 1.5118... Val Loss: 1.5702\n",
            "Epoch: 34/40... Step: 3040... Loss: 1.5560... Val Loss: 1.5688\n",
            "Epoch: 34/40... Step: 3050... Loss: 1.5316... Val Loss: 1.5316\n",
            "Epoch: 34/40... Step: 3050... Loss: 1.5193... Val Loss: 1.5255\n",
            "Epoch: 34/40... Step: 3050... Loss: 1.7745... Val Loss: 1.6085\n",
            "Epoch: 34/40... Step: 3050... Loss: 1.7499... Val Loss: 1.6438\n",
            "Epoch: 34/40... Step: 3050... Loss: 1.5391... Val Loss: 1.6229\n",
            "Epoch: 34/40... Step: 3050... Loss: 1.4982... Val Loss: 1.6021\n",
            "Epoch: 34/40... Step: 3050... Loss: 1.3658... Val Loss: 1.5684\n",
            "Epoch: 34/40... Step: 3050... Loss: 1.4856... Val Loss: 1.5580\n",
            "Epoch: 34/40... Step: 3050... Loss: 1.5038... Val Loss: 1.5520\n",
            "Epoch: 34/40... Step: 3050... Loss: 1.5485... Val Loss: 1.5516\n",
            "Epoch: 34/40... Step: 3060... Loss: 1.5351... Val Loss: 1.5351\n",
            "Epoch: 34/40... Step: 3060... Loss: 1.5185... Val Loss: 1.5268\n",
            "Epoch: 34/40... Step: 3060... Loss: 1.7577... Val Loss: 1.6038\n",
            "Epoch: 34/40... Step: 3060... Loss: 1.8232... Val Loss: 1.6587\n",
            "Epoch: 34/40... Step: 3060... Loss: 1.5208... Val Loss: 1.6311\n",
            "Epoch: 34/40... Step: 3060... Loss: 1.4757... Val Loss: 1.6052\n",
            "Epoch: 34/40... Step: 3060... Loss: 1.3545... Val Loss: 1.5694\n",
            "Epoch: 34/40... Step: 3060... Loss: 1.4910... Val Loss: 1.5596\n",
            "Epoch: 34/40... Step: 3060... Loss: 1.5449... Val Loss: 1.5579\n",
            "Epoch: 34/40... Step: 3060... Loss: 1.5576... Val Loss: 1.5579\n",
            "Epoch: 34/40... Step: 3070... Loss: 1.5571... Val Loss: 1.5571\n",
            "Epoch: 34/40... Step: 3070... Loss: 1.5159... Val Loss: 1.5365\n",
            "Epoch: 34/40... Step: 3070... Loss: 1.7799... Val Loss: 1.6176\n",
            "Epoch: 34/40... Step: 3070... Loss: 1.7879... Val Loss: 1.6602\n",
            "Epoch: 34/40... Step: 3070... Loss: 1.5535... Val Loss: 1.6389\n",
            "Epoch: 34/40... Step: 3070... Loss: 1.5130... Val Loss: 1.6179\n",
            "Epoch: 34/40... Step: 3070... Loss: 1.3953... Val Loss: 1.5861\n",
            "Epoch: 34/40... Step: 3070... Loss: 1.5018... Val Loss: 1.5756\n",
            "Epoch: 34/40... Step: 3070... Loss: 1.5317... Val Loss: 1.5707\n",
            "Epoch: 34/40... Step: 3070... Loss: 1.5615... Val Loss: 1.5698\n",
            "Epoch: 34/40... Step: 3080... Loss: 1.5833... Val Loss: 1.5833\n",
            "Epoch: 34/40... Step: 3080... Loss: 1.5481... Val Loss: 1.5657\n",
            "Epoch: 34/40... Step: 3080... Loss: 1.8223... Val Loss: 1.6513\n",
            "Epoch: 34/40... Step: 3080... Loss: 1.8480... Val Loss: 1.7005\n",
            "Epoch: 34/40... Step: 3080... Loss: 1.5143... Val Loss: 1.6632\n",
            "Epoch: 34/40... Step: 3080... Loss: 1.5526... Val Loss: 1.6448\n",
            "Epoch: 34/40... Step: 3080... Loss: 1.4669... Val Loss: 1.6194\n",
            "Epoch: 34/40... Step: 3080... Loss: 1.5054... Val Loss: 1.6051\n",
            "Epoch: 34/40... Step: 3080... Loss: 1.5531... Val Loss: 1.5993\n",
            "Epoch: 34/40... Step: 3080... Loss: 1.5809... Val Loss: 1.5975\n",
            "Epoch: 34/40... Step: 3090... Loss: 1.5903... Val Loss: 1.5903\n",
            "Epoch: 34/40... Step: 3090... Loss: 1.5443... Val Loss: 1.5673\n",
            "Epoch: 34/40... Step: 3090... Loss: 1.8234... Val Loss: 1.6526\n",
            "Epoch: 34/40... Step: 3090... Loss: 1.8291... Val Loss: 1.6968\n",
            "Epoch: 34/40... Step: 3090... Loss: 1.5428... Val Loss: 1.6660\n",
            "Epoch: 34/40... Step: 3090... Loss: 1.5263... Val Loss: 1.6427\n",
            "Epoch: 34/40... Step: 3090... Loss: 1.4197... Val Loss: 1.6108\n",
            "Epoch: 34/40... Step: 3090... Loss: 1.5598... Val Loss: 1.6045\n",
            "Epoch: 34/40... Step: 3090... Loss: 1.5480... Val Loss: 1.5982\n",
            "Epoch: 34/40... Step: 3090... Loss: 1.5833... Val Loss: 1.5967\n",
            "Epoch: 34/40... Step: 3100... Loss: 1.5884... Val Loss: 1.5884\n",
            "Epoch: 34/40... Step: 3100... Loss: 1.5255... Val Loss: 1.5570\n",
            "Epoch: 34/40... Step: 3100... Loss: 1.7918... Val Loss: 1.6352\n",
            "Epoch: 34/40... Step: 3100... Loss: 1.8150... Val Loss: 1.6802\n",
            "Epoch: 34/40... Step: 3100... Loss: 1.5506... Val Loss: 1.6543\n",
            "Epoch: 34/40... Step: 3100... Loss: 1.5491... Val Loss: 1.6367\n",
            "Epoch: 34/40... Step: 3100... Loss: 1.4429... Val Loss: 1.6091\n",
            "Epoch: 34/40... Step: 3100... Loss: 1.5213... Val Loss: 1.5981\n",
            "Epoch: 34/40... Step: 3100... Loss: 1.5389... Val Loss: 1.5915\n",
            "Epoch: 34/40... Step: 3100... Loss: 1.5663... Val Loss: 1.5890\n",
            "Epoch: 34/40... Step: 3110... Loss: 1.5897... Val Loss: 1.5897\n",
            "Epoch: 34/40... Step: 3110... Loss: 1.5488... Val Loss: 1.5693\n",
            "Epoch: 34/40... Step: 3110... Loss: 1.7705... Val Loss: 1.6364\n",
            "Epoch: 34/40... Step: 3110... Loss: 1.8058... Val Loss: 1.6787\n",
            "Epoch: 34/40... Step: 3110... Loss: 1.5871... Val Loss: 1.6604\n",
            "Epoch: 34/40... Step: 3110... Loss: 1.5381... Val Loss: 1.6400\n",
            "Epoch: 34/40... Step: 3110... Loss: 1.4683... Val Loss: 1.6155\n",
            "Epoch: 34/40... Step: 3110... Loss: 1.5381... Val Loss: 1.6058\n",
            "Epoch: 34/40... Step: 3110... Loss: 1.5567... Val Loss: 1.6003\n",
            "Epoch: 34/40... Step: 3110... Loss: 1.5808... Val Loss: 1.5984\n",
            "Epoch: 34/40... Step: 3120... Loss: 1.5822... Val Loss: 1.5822\n",
            "Epoch: 34/40... Step: 3120... Loss: 1.5259... Val Loss: 1.5540\n",
            "Epoch: 34/40... Step: 3120... Loss: 1.8154... Val Loss: 1.6412\n",
            "Epoch: 34/40... Step: 3120... Loss: 1.8345... Val Loss: 1.6895\n",
            "Epoch: 34/40... Step: 3120... Loss: 1.5506... Val Loss: 1.6617\n",
            "Epoch: 34/40... Step: 3120... Loss: 1.5460... Val Loss: 1.6424\n",
            "Epoch: 34/40... Step: 3120... Loss: 1.4381... Val Loss: 1.6132\n",
            "Epoch: 34/40... Step: 3120... Loss: 1.5136... Val Loss: 1.6008\n",
            "Epoch: 34/40... Step: 3120... Loss: 1.5602... Val Loss: 1.5963\n",
            "Epoch: 34/40... Step: 3120... Loss: 1.5860... Val Loss: 1.5953\n",
            "Epoch: 35/40... Step: 3130... Loss: 1.5903... Val Loss: 1.5903\n",
            "Epoch: 35/40... Step: 3130... Loss: 1.5230... Val Loss: 1.5566\n",
            "Epoch: 35/40... Step: 3130... Loss: 1.7511... Val Loss: 1.6215\n",
            "Epoch: 35/40... Step: 3130... Loss: 1.8250... Val Loss: 1.6723\n",
            "Epoch: 35/40... Step: 3130... Loss: 1.5192... Val Loss: 1.6417\n",
            "Epoch: 35/40... Step: 3130... Loss: 1.5323... Val Loss: 1.6235\n",
            "Epoch: 35/40... Step: 3130... Loss: 1.4029... Val Loss: 1.5920\n",
            "Epoch: 35/40... Step: 3130... Loss: 1.4959... Val Loss: 1.5800\n",
            "Epoch: 35/40... Step: 3130... Loss: 1.5219... Val Loss: 1.5735\n",
            "Epoch: 35/40... Step: 3130... Loss: 1.5741... Val Loss: 1.5736\n",
            "Epoch: 35/40... Step: 3140... Loss: 1.5651... Val Loss: 1.5651\n",
            "Epoch: 35/40... Step: 3140... Loss: 1.5217... Val Loss: 1.5434\n",
            "Epoch: 35/40... Step: 3140... Loss: 1.7996... Val Loss: 1.6288\n",
            "Epoch: 35/40... Step: 3140... Loss: 1.7558... Val Loss: 1.6606\n",
            "Epoch: 35/40... Step: 3140... Loss: 1.5339... Val Loss: 1.6352\n",
            "Epoch: 35/40... Step: 3140... Loss: 1.4684... Val Loss: 1.6074\n",
            "Epoch: 35/40... Step: 3140... Loss: 1.3959... Val Loss: 1.5772\n",
            "Epoch: 35/40... Step: 3140... Loss: 1.4913... Val Loss: 1.5665\n",
            "Epoch: 35/40... Step: 3140... Loss: 1.5217... Val Loss: 1.5615\n",
            "Epoch: 35/40... Step: 3140... Loss: 1.5729... Val Loss: 1.5626\n",
            "Epoch: 35/40... Step: 3150... Loss: 1.5400... Val Loss: 1.5400\n",
            "Epoch: 35/40... Step: 3150... Loss: 1.5242... Val Loss: 1.5321\n",
            "Epoch: 35/40... Step: 3150... Loss: 1.8089... Val Loss: 1.6244\n",
            "Epoch: 35/40... Step: 3150... Loss: 1.7967... Val Loss: 1.6674\n",
            "Epoch: 35/40... Step: 3150... Loss: 1.5178... Val Loss: 1.6375\n",
            "Epoch: 35/40... Step: 3150... Loss: 1.4886... Val Loss: 1.6127\n",
            "Epoch: 35/40... Step: 3150... Loss: 1.3877... Val Loss: 1.5805\n",
            "Epoch: 35/40... Step: 3150... Loss: 1.4729... Val Loss: 1.5671\n",
            "Epoch: 35/40... Step: 3150... Loss: 1.5117... Val Loss: 1.5609\n",
            "Epoch: 35/40... Step: 3150... Loss: 1.6039... Val Loss: 1.5652\n",
            "Epoch: 35/40... Step: 3160... Loss: 1.5571... Val Loss: 1.5571\n",
            "Epoch: 35/40... Step: 3160... Loss: 1.5062... Val Loss: 1.5316\n",
            "Epoch: 35/40... Step: 3160... Loss: 1.7763... Val Loss: 1.6132\n",
            "Epoch: 35/40... Step: 3160... Loss: 1.7820... Val Loss: 1.6554\n",
            "Epoch: 35/40... Step: 3160... Loss: 1.5529... Val Loss: 1.6349\n",
            "Epoch: 35/40... Step: 3160... Loss: 1.4845... Val Loss: 1.6098\n",
            "Epoch: 35/40... Step: 3160... Loss: 1.3564... Val Loss: 1.5736\n",
            "Epoch: 35/40... Step: 3160... Loss: 1.5044... Val Loss: 1.5650\n",
            "Epoch: 35/40... Step: 3160... Loss: 1.4912... Val Loss: 1.5568\n",
            "Epoch: 35/40... Step: 3160... Loss: 1.5440... Val Loss: 1.5555\n",
            "Epoch: 35/40... Step: 3170... Loss: 1.5714... Val Loss: 1.5714\n",
            "Epoch: 35/40... Step: 3170... Loss: 1.5252... Val Loss: 1.5483\n",
            "Epoch: 35/40... Step: 3170... Loss: 1.8126... Val Loss: 1.6364\n",
            "Epoch: 35/40... Step: 3170... Loss: 1.8645... Val Loss: 1.6934\n",
            "Epoch: 35/40... Step: 3170... Loss: 1.5536... Val Loss: 1.6655\n",
            "Epoch: 35/40... Step: 3170... Loss: 1.5455... Val Loss: 1.6455\n",
            "Epoch: 35/40... Step: 3170... Loss: 1.4027... Val Loss: 1.6108\n",
            "Epoch: 35/40... Step: 3170... Loss: 1.5435... Val Loss: 1.6024\n",
            "Epoch: 35/40... Step: 3170... Loss: 1.5534... Val Loss: 1.5969\n",
            "Epoch: 35/40... Step: 3170... Loss: 1.5725... Val Loss: 1.5945\n",
            "Epoch: 35/40... Step: 3180... Loss: 1.5916... Val Loss: 1.5916\n",
            "Epoch: 35/40... Step: 3180... Loss: 1.5480... Val Loss: 1.5698\n",
            "Epoch: 35/40... Step: 3180... Loss: 1.8261... Val Loss: 1.6552\n",
            "Epoch: 35/40... Step: 3180... Loss: 1.8278... Val Loss: 1.6984\n",
            "Epoch: 35/40... Step: 3180... Loss: 1.5911... Val Loss: 1.6769\n",
            "Epoch: 35/40... Step: 3180... Loss: 1.5651... Val Loss: 1.6583\n",
            "Epoch: 35/40... Step: 3180... Loss: 1.4235... Val Loss: 1.6247\n",
            "Epoch: 35/40... Step: 3180... Loss: 1.5535... Val Loss: 1.6158\n",
            "Epoch: 35/40... Step: 3180... Loss: 1.5489... Val Loss: 1.6084\n",
            "Epoch: 35/40... Step: 3180... Loss: 1.5528... Val Loss: 1.6028\n",
            "Epoch: 35/40... Step: 3190... Loss: 1.5856... Val Loss: 1.5856\n",
            "Epoch: 35/40... Step: 3190... Loss: 1.5589... Val Loss: 1.5723\n",
            "Epoch: 35/40... Step: 3190... Loss: 1.8068... Val Loss: 1.6505\n",
            "Epoch: 35/40... Step: 3190... Loss: 1.8012... Val Loss: 1.6882\n",
            "Epoch: 35/40... Step: 3190... Loss: 1.5829... Val Loss: 1.6671\n",
            "Epoch: 35/40... Step: 3190... Loss: 1.5193... Val Loss: 1.6425\n",
            "Epoch: 35/40... Step: 3190... Loss: 1.4641... Val Loss: 1.6170\n",
            "Epoch: 35/40... Step: 3190... Loss: 1.5792... Val Loss: 1.6123\n",
            "Epoch: 35/40... Step: 3190... Loss: 1.5657... Val Loss: 1.6071\n",
            "Epoch: 35/40... Step: 3190... Loss: 1.6052... Val Loss: 1.6069\n",
            "Epoch: 35/40... Step: 3200... Loss: 1.5885... Val Loss: 1.5885\n",
            "Epoch: 35/40... Step: 3200... Loss: 1.5752... Val Loss: 1.5819\n",
            "Epoch: 35/40... Step: 3200... Loss: 1.8120... Val Loss: 1.6586\n",
            "Epoch: 35/40... Step: 3200... Loss: 1.8092... Val Loss: 1.6962\n",
            "Epoch: 35/40... Step: 3200... Loss: 1.6108... Val Loss: 1.6792\n",
            "Epoch: 35/40... Step: 3200... Loss: 1.5558... Val Loss: 1.6586\n",
            "Epoch: 35/40... Step: 3200... Loss: 1.4784... Val Loss: 1.6329\n",
            "Epoch: 35/40... Step: 3200... Loss: 1.5671... Val Loss: 1.6246\n",
            "Epoch: 35/40... Step: 3200... Loss: 1.5277... Val Loss: 1.6139\n",
            "Epoch: 35/40... Step: 3200... Loss: 1.5933... Val Loss: 1.6118\n",
            "Epoch: 35/40... Step: 3210... Loss: 1.5787... Val Loss: 1.5787\n",
            "Epoch: 35/40... Step: 3210... Loss: 1.5459... Val Loss: 1.5623\n",
            "Epoch: 35/40... Step: 3210... Loss: 1.8022... Val Loss: 1.6423\n",
            "Epoch: 35/40... Step: 3210... Loss: 1.8083... Val Loss: 1.6838\n",
            "Epoch: 35/40... Step: 3210... Loss: 1.5584... Val Loss: 1.6587\n",
            "Epoch: 35/40... Step: 3210... Loss: 1.5305... Val Loss: 1.6373\n",
            "Epoch: 35/40... Step: 3210... Loss: 1.4616... Val Loss: 1.6122\n",
            "Epoch: 35/40... Step: 3210... Loss: 1.5456... Val Loss: 1.6039\n",
            "Epoch: 35/40... Step: 3210... Loss: 1.5477... Val Loss: 1.5977\n",
            "Epoch: 35/40... Step: 3210... Loss: 1.5696... Val Loss: 1.5949\n",
            "Epoch: 35/40... Step: 3220... Loss: 1.5840... Val Loss: 1.5840\n",
            "Epoch: 35/40... Step: 3220... Loss: 1.5283... Val Loss: 1.5562\n",
            "Epoch: 35/40... Step: 3220... Loss: 1.7904... Val Loss: 1.6342\n",
            "Epoch: 35/40... Step: 3220... Loss: 1.8418... Val Loss: 1.6861\n",
            "Epoch: 35/40... Step: 3220... Loss: 1.5743... Val Loss: 1.6638\n",
            "Epoch: 35/40... Step: 3220... Loss: 1.5037... Val Loss: 1.6371\n",
            "Epoch: 35/40... Step: 3220... Loss: 1.4444... Val Loss: 1.6096\n",
            "Epoch: 35/40... Step: 3220... Loss: 1.5197... Val Loss: 1.5983\n",
            "Epoch: 35/40... Step: 3220... Loss: 1.5198... Val Loss: 1.5896\n",
            "Epoch: 35/40... Step: 3220... Loss: 1.5521... Val Loss: 1.5858\n",
            "Epoch: 36/40... Step: 3230... Loss: 1.5542... Val Loss: 1.5542\n",
            "Epoch: 36/40... Step: 3230... Loss: 1.5143... Val Loss: 1.5342\n",
            "Epoch: 36/40... Step: 3230... Loss: 1.7789... Val Loss: 1.6158\n",
            "Epoch: 36/40... Step: 3230... Loss: 1.8005... Val Loss: 1.6620\n",
            "Epoch: 36/40... Step: 3230... Loss: 1.5324... Val Loss: 1.6361\n",
            "Epoch: 36/40... Step: 3230... Loss: 1.4869... Val Loss: 1.6112\n",
            "Epoch: 36/40... Step: 3230... Loss: 1.4019... Val Loss: 1.5813\n",
            "Epoch: 36/40... Step: 3230... Loss: 1.5063... Val Loss: 1.5719\n",
            "Epoch: 36/40... Step: 3230... Loss: 1.5128... Val Loss: 1.5653\n",
            "Epoch: 36/40... Step: 3230... Loss: 1.5692... Val Loss: 1.5657\n",
            "Epoch: 36/40... Step: 3240... Loss: 1.5624... Val Loss: 1.5624\n",
            "Epoch: 36/40... Step: 3240... Loss: 1.5479... Val Loss: 1.5551\n",
            "Epoch: 36/40... Step: 3240... Loss: 1.8094... Val Loss: 1.6399\n",
            "Epoch: 36/40... Step: 3240... Loss: 1.8014... Val Loss: 1.6802\n",
            "Epoch: 36/40... Step: 3240... Loss: 1.5457... Val Loss: 1.6533\n",
            "Epoch: 36/40... Step: 3240... Loss: 1.5173... Val Loss: 1.6307\n",
            "Epoch: 36/40... Step: 3240... Loss: 1.3941... Val Loss: 1.5969\n",
            "Epoch: 36/40... Step: 3240... Loss: 1.5056... Val Loss: 1.5854\n",
            "Epoch: 36/40... Step: 3240... Loss: 1.5423... Val Loss: 1.5807\n",
            "Epoch: 36/40... Step: 3240... Loss: 1.5972... Val Loss: 1.5823\n",
            "Epoch: 36/40... Step: 3250... Loss: 1.5726... Val Loss: 1.5726\n",
            "Epoch: 36/40... Step: 3250... Loss: 1.5394... Val Loss: 1.5560\n",
            "Epoch: 36/40... Step: 3250... Loss: 1.7655... Val Loss: 1.6258\n",
            "Epoch: 36/40... Step: 3250... Loss: 1.8037... Val Loss: 1.6703\n",
            "Epoch: 36/40... Step: 3250... Loss: 1.5447... Val Loss: 1.6452\n",
            "Epoch: 36/40... Step: 3250... Loss: 1.4733... Val Loss: 1.6165\n",
            "Epoch: 36/40... Step: 3250... Loss: 1.3987... Val Loss: 1.5854\n",
            "Epoch: 36/40... Step: 3250... Loss: 1.5017... Val Loss: 1.5749\n",
            "Epoch: 36/40... Step: 3250... Loss: 1.4862... Val Loss: 1.5651\n",
            "Epoch: 36/40... Step: 3250... Loss: 1.5659... Val Loss: 1.5652\n",
            "Epoch: 36/40... Step: 3260... Loss: 1.5830... Val Loss: 1.5830\n",
            "Epoch: 36/40... Step: 3260... Loss: 1.5537... Val Loss: 1.5683\n",
            "Epoch: 36/40... Step: 3260... Loss: 1.8056... Val Loss: 1.6474\n",
            "Epoch: 36/40... Step: 3260... Loss: 1.8270... Val Loss: 1.6923\n",
            "Epoch: 36/40... Step: 3260... Loss: 1.5758... Val Loss: 1.6690\n",
            "Epoch: 36/40... Step: 3260... Loss: 1.5171... Val Loss: 1.6437\n",
            "Epoch: 36/40... Step: 3260... Loss: 1.4077... Val Loss: 1.6100\n",
            "Epoch: 36/40... Step: 3260... Loss: 1.5511... Val Loss: 1.6026\n",
            "Epoch: 36/40... Step: 3260... Loss: 1.5406... Val Loss: 1.5957\n",
            "Epoch: 36/40... Step: 3260... Loss: 1.5956... Val Loss: 1.5957\n",
            "Epoch: 36/40... Step: 3270... Loss: 1.5972... Val Loss: 1.5972\n",
            "Epoch: 36/40... Step: 3270... Loss: 1.5710... Val Loss: 1.5841\n",
            "Epoch: 36/40... Step: 3270... Loss: 1.8522... Val Loss: 1.6734\n",
            "Epoch: 36/40... Step: 3270... Loss: 1.8860... Val Loss: 1.7266\n",
            "Epoch: 36/40... Step: 3270... Loss: 1.5757... Val Loss: 1.6964\n",
            "Epoch: 36/40... Step: 3270... Loss: 1.5406... Val Loss: 1.6704\n",
            "Epoch: 36/40... Step: 3270... Loss: 1.4395... Val Loss: 1.6374\n",
            "Epoch: 36/40... Step: 3270... Loss: 1.5692... Val Loss: 1.6289\n",
            "Epoch: 36/40... Step: 3270... Loss: 1.5843... Val Loss: 1.6240\n",
            "Epoch: 36/40... Step: 3270... Loss: 1.6300... Val Loss: 1.6246\n",
            "Epoch: 36/40... Step: 3280... Loss: 1.6088... Val Loss: 1.6088\n",
            "Epoch: 36/40... Step: 3280... Loss: 1.5351... Val Loss: 1.5719\n",
            "Epoch: 36/40... Step: 3280... Loss: 1.8220... Val Loss: 1.6553\n",
            "Epoch: 36/40... Step: 3280... Loss: 1.8428... Val Loss: 1.7022\n",
            "Epoch: 36/40... Step: 3280... Loss: 1.5484... Val Loss: 1.6714\n",
            "Epoch: 36/40... Step: 3280... Loss: 1.5484... Val Loss: 1.6509\n",
            "Epoch: 36/40... Step: 3280... Loss: 1.4592... Val Loss: 1.6235\n",
            "Epoch: 36/40... Step: 3280... Loss: 1.5627... Val Loss: 1.6159\n",
            "Epoch: 36/40... Step: 3280... Loss: 1.5617... Val Loss: 1.6099\n",
            "Epoch: 36/40... Step: 3280... Loss: 1.6063... Val Loss: 1.6095\n",
            "Epoch: 36/40... Step: 3290... Loss: 1.6028... Val Loss: 1.6028\n",
            "Epoch: 36/40... Step: 3290... Loss: 1.5752... Val Loss: 1.5890\n",
            "Epoch: 36/40... Step: 3290... Loss: 1.8074... Val Loss: 1.6618\n",
            "Epoch: 36/40... Step: 3290... Loss: 1.8162... Val Loss: 1.7004\n",
            "Epoch: 36/40... Step: 3290... Loss: 1.5478... Val Loss: 1.6699\n",
            "Epoch: 36/40... Step: 3290... Loss: 1.5514... Val Loss: 1.6501\n",
            "Epoch: 36/40... Step: 3290... Loss: 1.4967... Val Loss: 1.6282\n",
            "Epoch: 36/40... Step: 3290... Loss: 1.5437... Val Loss: 1.6177\n",
            "Epoch: 36/40... Step: 3290... Loss: 1.5678... Val Loss: 1.6121\n",
            "Epoch: 36/40... Step: 3290... Loss: 1.6054... Val Loss: 1.6114\n",
            "Epoch: 36/40... Step: 3300... Loss: 1.6228... Val Loss: 1.6228\n",
            "Epoch: 36/40... Step: 3300... Loss: 1.5728... Val Loss: 1.5978\n",
            "Epoch: 36/40... Step: 3300... Loss: 1.7923... Val Loss: 1.6627\n",
            "Epoch: 36/40... Step: 3300... Loss: 1.8406... Val Loss: 1.7072\n",
            "Epoch: 36/40... Step: 3300... Loss: 1.5833... Val Loss: 1.6824\n",
            "Epoch: 36/40... Step: 3300... Loss: 1.5730... Val Loss: 1.6641\n",
            "Epoch: 36/40... Step: 3300... Loss: 1.4714... Val Loss: 1.6366\n",
            "Epoch: 36/40... Step: 3300... Loss: 1.5441... Val Loss: 1.6250\n",
            "Epoch: 36/40... Step: 3300... Loss: 1.5385... Val Loss: 1.6154\n",
            "Epoch: 36/40... Step: 3300... Loss: 1.5929... Val Loss: 1.6132\n",
            "Epoch: 36/40... Step: 3310... Loss: 1.6122... Val Loss: 1.6122\n",
            "Epoch: 36/40... Step: 3310... Loss: 1.5643... Val Loss: 1.5883\n",
            "Epoch: 36/40... Step: 3310... Loss: 1.8099... Val Loss: 1.6622\n",
            "Epoch: 36/40... Step: 3310... Loss: 1.8248... Val Loss: 1.7028\n",
            "Epoch: 36/40... Step: 3310... Loss: 1.5578... Val Loss: 1.6738\n",
            "Epoch: 36/40... Step: 3310... Loss: 1.5607... Val Loss: 1.6550\n",
            "Epoch: 36/40... Step: 3310... Loss: 1.4544... Val Loss: 1.6263\n",
            "Epoch: 36/40... Step: 3310... Loss: 1.5180... Val Loss: 1.6128\n",
            "Epoch: 36/40... Step: 3310... Loss: 1.5477... Val Loss: 1.6055\n",
            "Epoch: 36/40... Step: 3310... Loss: 1.5829... Val Loss: 1.6033\n",
            "Epoch: 37/40... Step: 3320... Loss: 1.5781... Val Loss: 1.5781\n",
            "Epoch: 37/40... Step: 3320... Loss: 1.5287... Val Loss: 1.5534\n",
            "Epoch: 37/40... Step: 3320... Loss: 1.7928... Val Loss: 1.6332\n",
            "Epoch: 37/40... Step: 3320... Loss: 1.7674... Val Loss: 1.6667\n",
            "Epoch: 37/40... Step: 3320... Loss: 1.5527... Val Loss: 1.6439\n",
            "Epoch: 37/40... Step: 3320... Loss: 1.4867... Val Loss: 1.6177\n",
            "Epoch: 37/40... Step: 3320... Loss: 1.4039... Val Loss: 1.5872\n",
            "Epoch: 37/40... Step: 3320... Loss: 1.5188... Val Loss: 1.5786\n",
            "Epoch: 37/40... Step: 3320... Loss: 1.5052... Val Loss: 1.5705\n",
            "Epoch: 37/40... Step: 3320... Loss: 1.5619... Val Loss: 1.5696\n",
            "Epoch: 37/40... Step: 3330... Loss: 1.5773... Val Loss: 1.5773\n",
            "Epoch: 37/40... Step: 3330... Loss: 1.5157... Val Loss: 1.5465\n",
            "Epoch: 37/40... Step: 3330... Loss: 1.8273... Val Loss: 1.6401\n",
            "Epoch: 37/40... Step: 3330... Loss: 1.7891... Val Loss: 1.6773\n",
            "Epoch: 37/40... Step: 3330... Loss: 1.5793... Val Loss: 1.6577\n",
            "Epoch: 37/40... Step: 3330... Loss: 1.4996... Val Loss: 1.6314\n",
            "Epoch: 37/40... Step: 3330... Loss: 1.4254... Val Loss: 1.6019\n",
            "Epoch: 37/40... Step: 3330... Loss: 1.5297... Val Loss: 1.5929\n",
            "Epoch: 37/40... Step: 3330... Loss: 1.5167... Val Loss: 1.5844\n",
            "Epoch: 37/40... Step: 3330... Loss: 1.5803... Val Loss: 1.5840\n",
            "Epoch: 37/40... Step: 3340... Loss: 1.5679... Val Loss: 1.5679\n",
            "Epoch: 37/40... Step: 3340... Loss: 1.5318... Val Loss: 1.5498\n",
            "Epoch: 37/40... Step: 3340... Loss: 1.8246... Val Loss: 1.6414\n",
            "Epoch: 37/40... Step: 3340... Loss: 1.8118... Val Loss: 1.6840\n",
            "Epoch: 37/40... Step: 3340... Loss: 1.5688... Val Loss: 1.6610\n",
            "Epoch: 37/40... Step: 3340... Loss: 1.4855... Val Loss: 1.6317\n",
            "Epoch: 37/40... Step: 3340... Loss: 1.3782... Val Loss: 1.5955\n",
            "Epoch: 37/40... Step: 3340... Loss: 1.5451... Val Loss: 1.5892\n",
            "Epoch: 37/40... Step: 3340... Loss: 1.5242... Val Loss: 1.5820\n",
            "Epoch: 37/40... Step: 3340... Loss: 1.5957... Val Loss: 1.5834\n",
            "Epoch: 37/40... Step: 3350... Loss: 1.6037... Val Loss: 1.6037\n",
            "Epoch: 37/40... Step: 3350... Loss: 1.5491... Val Loss: 1.5764\n",
            "Epoch: 37/40... Step: 3350... Loss: 1.8258... Val Loss: 1.6595\n",
            "Epoch: 37/40... Step: 3350... Loss: 1.8134... Val Loss: 1.6980\n",
            "Epoch: 37/40... Step: 3350... Loss: 1.5914... Val Loss: 1.6767\n",
            "Epoch: 37/40... Step: 3350... Loss: 1.5274... Val Loss: 1.6518\n",
            "Epoch: 37/40... Step: 3350... Loss: 1.4042... Val Loss: 1.6164\n",
            "Epoch: 37/40... Step: 3350... Loss: 1.5454... Val Loss: 1.6076\n",
            "Epoch: 37/40... Step: 3350... Loss: 1.5401... Val Loss: 1.6001\n",
            "Epoch: 37/40... Step: 3350... Loss: 1.6005... Val Loss: 1.6001\n",
            "Epoch: 37/40... Step: 3360... Loss: 1.6097... Val Loss: 1.6097\n",
            "Epoch: 37/40... Step: 3360... Loss: 1.5545... Val Loss: 1.5821\n",
            "Epoch: 37/40... Step: 3360... Loss: 1.8252... Val Loss: 1.6631\n",
            "Epoch: 37/40... Step: 3360... Loss: 1.8778... Val Loss: 1.7168\n",
            "Epoch: 37/40... Step: 3360... Loss: 1.5851... Val Loss: 1.6904\n",
            "Epoch: 37/40... Step: 3360... Loss: 1.5424... Val Loss: 1.6658\n",
            "Epoch: 37/40... Step: 3360... Loss: 1.4443... Val Loss: 1.6341\n",
            "Epoch: 37/40... Step: 3360... Loss: 1.5533... Val Loss: 1.6240\n",
            "Epoch: 37/40... Step: 3360... Loss: 1.5704... Val Loss: 1.6181\n",
            "Epoch: 37/40... Step: 3360... Loss: 1.6210... Val Loss: 1.6184\n",
            "Epoch: 37/40... Step: 3370... Loss: 1.6120... Val Loss: 1.6120\n",
            "Epoch: 37/40... Step: 3370... Loss: 1.5956... Val Loss: 1.6038\n",
            "Epoch: 37/40... Step: 3370... Loss: 1.8248... Val Loss: 1.6775\n",
            "Epoch: 37/40... Step: 3370... Loss: 1.8138... Val Loss: 1.7115\n",
            "Epoch: 37/40... Step: 3370... Loss: 1.5341... Val Loss: 1.6761\n",
            "Epoch: 37/40... Step: 3370... Loss: 1.5943... Val Loss: 1.6624\n",
            "Epoch: 37/40... Step: 3370... Loss: 1.4251... Val Loss: 1.6285\n",
            "Epoch: 37/40... Step: 3370... Loss: 1.5874... Val Loss: 1.6234\n",
            "Epoch: 37/40... Step: 3370... Loss: 1.5574... Val Loss: 1.6161\n",
            "Epoch: 37/40... Step: 3370... Loss: 1.6125... Val Loss: 1.6157\n",
            "Epoch: 37/40... Step: 3380... Loss: 1.6004... Val Loss: 1.6004\n",
            "Epoch: 37/40... Step: 3380... Loss: 1.5552... Val Loss: 1.5778\n",
            "Epoch: 37/40... Step: 3380... Loss: 1.8023... Val Loss: 1.6527\n",
            "Epoch: 37/40... Step: 3380... Loss: 1.8332... Val Loss: 1.6978\n",
            "Epoch: 37/40... Step: 3380... Loss: 1.5648... Val Loss: 1.6712\n",
            "Epoch: 37/40... Step: 3380... Loss: 1.5666... Val Loss: 1.6538\n",
            "Epoch: 37/40... Step: 3380... Loss: 1.4745... Val Loss: 1.6281\n",
            "Epoch: 37/40... Step: 3380... Loss: 1.5453... Val Loss: 1.6178\n",
            "Epoch: 37/40... Step: 3380... Loss: 1.5561... Val Loss: 1.6109\n",
            "Epoch: 37/40... Step: 3380... Loss: 1.6039... Val Loss: 1.6102\n",
            "Epoch: 37/40... Step: 3390... Loss: 1.6157... Val Loss: 1.6157\n",
            "Epoch: 37/40... Step: 3390... Loss: 1.5351... Val Loss: 1.5754\n",
            "Epoch: 37/40... Step: 3390... Loss: 1.8313... Val Loss: 1.6607\n",
            "Epoch: 37/40... Step: 3390... Loss: 1.8335... Val Loss: 1.7039\n",
            "Epoch: 37/40... Step: 3390... Loss: 1.5771... Val Loss: 1.6785\n",
            "Epoch: 37/40... Step: 3390... Loss: 1.5420... Val Loss: 1.6558\n",
            "Epoch: 37/40... Step: 3390... Loss: 1.4411... Val Loss: 1.6251\n",
            "Epoch: 37/40... Step: 3390... Loss: 1.5741... Val Loss: 1.6187\n",
            "Epoch: 37/40... Step: 3390... Loss: 1.5726... Val Loss: 1.6136\n",
            "Epoch: 37/40... Step: 3390... Loss: 1.6389... Val Loss: 1.6161\n",
            "Epoch: 37/40... Step: 3400... Loss: 1.6159... Val Loss: 1.6159\n",
            "Epoch: 37/40... Step: 3400... Loss: 1.5624... Val Loss: 1.5892\n",
            "Epoch: 37/40... Step: 3400... Loss: 1.8155... Val Loss: 1.6646\n",
            "Epoch: 37/40... Step: 3400... Loss: 1.8442... Val Loss: 1.7095\n",
            "Epoch: 37/40... Step: 3400... Loss: 1.5896... Val Loss: 1.6855\n",
            "Epoch: 37/40... Step: 3400... Loss: 1.5663... Val Loss: 1.6656\n",
            "Epoch: 37/40... Step: 3400... Loss: 1.4454... Val Loss: 1.6342\n",
            "Epoch: 37/40... Step: 3400... Loss: 1.5544... Val Loss: 1.6242\n",
            "Epoch: 37/40... Step: 3400... Loss: 1.5595... Val Loss: 1.6170\n",
            "Epoch: 37/40... Step: 3400... Loss: 1.5655... Val Loss: 1.6119\n",
            "Epoch: 38/40... Step: 3410... Loss: 1.5945... Val Loss: 1.5945\n",
            "Epoch: 38/40... Step: 3410... Loss: 1.5628... Val Loss: 1.5786\n",
            "Epoch: 38/40... Step: 3410... Loss: 1.8078... Val Loss: 1.6550\n",
            "Epoch: 38/40... Step: 3410... Loss: 1.8461... Val Loss: 1.7028\n",
            "Epoch: 38/40... Step: 3410... Loss: 1.5640... Val Loss: 1.6750\n",
            "Epoch: 38/40... Step: 3410... Loss: 1.5443... Val Loss: 1.6532\n",
            "Epoch: 38/40... Step: 3410... Loss: 1.4282... Val Loss: 1.6211\n",
            "Epoch: 38/40... Step: 3410... Loss: 1.5126... Val Loss: 1.6075\n",
            "Epoch: 38/40... Step: 3410... Loss: 1.5501... Val Loss: 1.6012\n",
            "Epoch: 38/40... Step: 3410... Loss: 1.5953... Val Loss: 1.6006\n",
            "Epoch: 38/40... Step: 3420... Loss: 1.5662... Val Loss: 1.5662\n",
            "Epoch: 38/40... Step: 3420... Loss: 1.5341... Val Loss: 1.5502\n",
            "Epoch: 38/40... Step: 3420... Loss: 1.8443... Val Loss: 1.6482\n",
            "Epoch: 38/40... Step: 3420... Loss: 1.8110... Val Loss: 1.6889\n",
            "Epoch: 38/40... Step: 3420... Loss: 1.5979... Val Loss: 1.6707\n",
            "Epoch: 38/40... Step: 3420... Loss: 1.5200... Val Loss: 1.6456\n",
            "Epoch: 38/40... Step: 3420... Loss: 1.3919... Val Loss: 1.6093\n",
            "Epoch: 38/40... Step: 3420... Loss: 1.4994... Val Loss: 1.5956\n",
            "Epoch: 38/40... Step: 3420... Loss: 1.5411... Val Loss: 1.5895\n",
            "Epoch: 38/40... Step: 3420... Loss: 1.5534... Val Loss: 1.5859\n",
            "Epoch: 38/40... Step: 3430... Loss: 1.5890... Val Loss: 1.5890\n",
            "Epoch: 38/40... Step: 3430... Loss: 1.5437... Val Loss: 1.5664\n",
            "Epoch: 38/40... Step: 3430... Loss: 1.8295... Val Loss: 1.6541\n",
            "Epoch: 38/40... Step: 3430... Loss: 1.8210... Val Loss: 1.6958\n",
            "Epoch: 38/40... Step: 3430... Loss: 1.5246... Val Loss: 1.6616\n",
            "Epoch: 38/40... Step: 3430... Loss: 1.4978... Val Loss: 1.6343\n",
            "Epoch: 38/40... Step: 3430... Loss: 1.3687... Val Loss: 1.5963\n",
            "Epoch: 38/40... Step: 3430... Loss: 1.5126... Val Loss: 1.5859\n",
            "Epoch: 38/40... Step: 3430... Loss: 1.5372... Val Loss: 1.5805\n",
            "Epoch: 38/40... Step: 3430... Loss: 1.5857... Val Loss: 1.5810\n",
            "Epoch: 38/40... Step: 3440... Loss: 1.6167... Val Loss: 1.6167\n",
            "Epoch: 38/40... Step: 3440... Loss: 1.5875... Val Loss: 1.6021\n",
            "Epoch: 38/40... Step: 3440... Loss: 1.8143... Val Loss: 1.6728\n",
            "Epoch: 38/40... Step: 3440... Loss: 1.8654... Val Loss: 1.7210\n",
            "Epoch: 38/40... Step: 3440... Loss: 1.6022... Val Loss: 1.6972\n",
            "Epoch: 38/40... Step: 3440... Loss: 1.5325... Val Loss: 1.6698\n",
            "Epoch: 38/40... Step: 3440... Loss: 1.4375... Val Loss: 1.6366\n",
            "Epoch: 38/40... Step: 3440... Loss: 1.5566... Val Loss: 1.6266\n",
            "Epoch: 38/40... Step: 3440... Loss: 1.5535... Val Loss: 1.6185\n",
            "Epoch: 38/40... Step: 3440... Loss: 1.6171... Val Loss: 1.6184\n",
            "Epoch: 38/40... Step: 3450... Loss: 1.6373... Val Loss: 1.6373\n",
            "Epoch: 38/40... Step: 3450... Loss: 1.5815... Val Loss: 1.6094\n",
            "Epoch: 38/40... Step: 3450... Loss: 1.8832... Val Loss: 1.7007\n",
            "Epoch: 38/40... Step: 3450... Loss: 1.9010... Val Loss: 1.7508\n",
            "Epoch: 38/40... Step: 3450... Loss: 1.6086... Val Loss: 1.7223\n",
            "Epoch: 38/40... Step: 3450... Loss: 1.5383... Val Loss: 1.6917\n",
            "Epoch: 38/40... Step: 3450... Loss: 1.4098... Val Loss: 1.6514\n",
            "Epoch: 38/40... Step: 3450... Loss: 1.5949... Val Loss: 1.6443\n",
            "Epoch: 38/40... Step: 3450... Loss: 1.5867... Val Loss: 1.6379\n",
            "Epoch: 38/40... Step: 3450... Loss: 1.6248... Val Loss: 1.6366\n",
            "Epoch: 38/40... Step: 3460... Loss: 1.6372... Val Loss: 1.6372\n",
            "Epoch: 38/40... Step: 3460... Loss: 1.5886... Val Loss: 1.6129\n",
            "Epoch: 38/40... Step: 3460... Loss: 1.8497... Val Loss: 1.6918\n",
            "Epoch: 38/40... Step: 3460... Loss: 1.8827... Val Loss: 1.7395\n",
            "Epoch: 38/40... Step: 3460... Loss: 1.5560... Val Loss: 1.7028\n",
            "Epoch: 38/40... Step: 3460... Loss: 1.5934... Val Loss: 1.6846\n",
            "Epoch: 38/40... Step: 3460... Loss: 1.4165... Val Loss: 1.6463\n",
            "Epoch: 38/40... Step: 3460... Loss: 1.5595... Val Loss: 1.6354\n",
            "Epoch: 38/40... Step: 3460... Loss: 1.5945... Val Loss: 1.6309\n",
            "Epoch: 38/40... Step: 3460... Loss: 1.6268... Val Loss: 1.6305\n",
            "Epoch: 38/40... Step: 3470... Loss: 1.6222... Val Loss: 1.6222\n",
            "Epoch: 38/40... Step: 3470... Loss: 1.5850... Val Loss: 1.6036\n",
            "Epoch: 38/40... Step: 3470... Loss: 1.8540... Val Loss: 1.6871\n",
            "Epoch: 38/40... Step: 3470... Loss: 1.8405... Val Loss: 1.7254\n",
            "Epoch: 38/40... Step: 3470... Loss: 1.5836... Val Loss: 1.6971\n",
            "Epoch: 38/40... Step: 3470... Loss: 1.5664... Val Loss: 1.6753\n",
            "Epoch: 38/40... Step: 3470... Loss: 1.4367... Val Loss: 1.6412\n",
            "Epoch: 38/40... Step: 3470... Loss: 1.5357... Val Loss: 1.6280\n",
            "Epoch: 38/40... Step: 3470... Loss: 1.5939... Val Loss: 1.6242\n",
            "Epoch: 38/40... Step: 3470... Loss: 1.6395... Val Loss: 1.6258\n",
            "Epoch: 38/40... Step: 3480... Loss: 1.6117... Val Loss: 1.6117\n",
            "Epoch: 38/40... Step: 3480... Loss: 1.5756... Val Loss: 1.5937\n",
            "Epoch: 38/40... Step: 3480... Loss: 1.8175... Val Loss: 1.6683\n",
            "Epoch: 38/40... Step: 3480... Loss: 1.8510... Val Loss: 1.7139\n",
            "Epoch: 38/40... Step: 3480... Loss: 1.6028... Val Loss: 1.6917\n",
            "Epoch: 38/40... Step: 3480... Loss: 1.5946... Val Loss: 1.6755\n",
            "Epoch: 38/40... Step: 3480... Loss: 1.4523... Val Loss: 1.6436\n",
            "Epoch: 38/40... Step: 3480... Loss: 1.5461... Val Loss: 1.6315\n",
            "Epoch: 38/40... Step: 3480... Loss: 1.5628... Val Loss: 1.6238\n",
            "Epoch: 38/40... Step: 3480... Loss: 1.6391... Val Loss: 1.6254\n",
            "Epoch: 38/40... Step: 3490... Loss: 1.6230... Val Loss: 1.6230\n",
            "Epoch: 38/40... Step: 3490... Loss: 1.5798... Val Loss: 1.6014\n",
            "Epoch: 38/40... Step: 3490... Loss: 1.8384... Val Loss: 1.6804\n",
            "Epoch: 38/40... Step: 3490... Loss: 1.8675... Val Loss: 1.7272\n",
            "Epoch: 38/40... Step: 3490... Loss: 1.5803... Val Loss: 1.6978\n",
            "Epoch: 38/40... Step: 3490... Loss: 1.5794... Val Loss: 1.6781\n",
            "Epoch: 38/40... Step: 3490... Loss: 1.4506... Val Loss: 1.6456\n",
            "Epoch: 38/40... Step: 3490... Loss: 1.5310... Val Loss: 1.6313\n",
            "Epoch: 38/40... Step: 3490... Loss: 1.5953... Val Loss: 1.6273\n",
            "Epoch: 38/40... Step: 3490... Loss: 1.6018... Val Loss: 1.6247\n",
            "Epoch: 39/40... Step: 3500... Loss: 1.6176... Val Loss: 1.6176\n",
            "Epoch: 39/40... Step: 3500... Loss: 1.5862... Val Loss: 1.6019\n",
            "Epoch: 39/40... Step: 3500... Loss: 1.7971... Val Loss: 1.6670\n",
            "Epoch: 39/40... Step: 3500... Loss: 1.8683... Val Loss: 1.7173\n",
            "Epoch: 39/40... Step: 3500... Loss: 1.6087... Val Loss: 1.6956\n",
            "Epoch: 39/40... Step: 3500... Loss: 1.5308... Val Loss: 1.6681\n",
            "Epoch: 39/40... Step: 3500... Loss: 1.4203... Val Loss: 1.6327\n",
            "Epoch: 39/40... Step: 3500... Loss: 1.5363... Val Loss: 1.6207\n",
            "Epoch: 39/40... Step: 3500... Loss: 1.5907... Val Loss: 1.6173\n",
            "Epoch: 39/40... Step: 3500... Loss: 1.6098... Val Loss: 1.6166\n",
            "Epoch: 39/40... Step: 3510... Loss: 1.5620... Val Loss: 1.5620\n",
            "Epoch: 39/40... Step: 3510... Loss: 1.5302... Val Loss: 1.5461\n",
            "Epoch: 39/40... Step: 3510... Loss: 1.8139... Val Loss: 1.6354\n",
            "Epoch: 39/40... Step: 3510... Loss: 1.8103... Val Loss: 1.6791\n",
            "Epoch: 39/40... Step: 3510... Loss: 1.5788... Val Loss: 1.6591\n",
            "Epoch: 39/40... Step: 3510... Loss: 1.5253... Val Loss: 1.6368\n",
            "Epoch: 39/40... Step: 3510... Loss: 1.4244... Val Loss: 1.6064\n",
            "Epoch: 39/40... Step: 3510... Loss: 1.5109... Val Loss: 1.5945\n",
            "Epoch: 39/40... Step: 3510... Loss: 1.5649... Val Loss: 1.5912\n",
            "Epoch: 39/40... Step: 3510... Loss: 1.5978... Val Loss: 1.5919\n",
            "Epoch: 39/40... Step: 3520... Loss: 1.5766... Val Loss: 1.5766\n",
            "Epoch: 39/40... Step: 3520... Loss: 1.5494... Val Loss: 1.5630\n",
            "Epoch: 39/40... Step: 3520... Loss: 1.8809... Val Loss: 1.6690\n",
            "Epoch: 39/40... Step: 3520... Loss: 1.8384... Val Loss: 1.7113\n",
            "Epoch: 39/40... Step: 3520... Loss: 1.5503... Val Loss: 1.6791\n",
            "Epoch: 39/40... Step: 3520... Loss: 1.5521... Val Loss: 1.6579\n",
            "Epoch: 39/40... Step: 3520... Loss: 1.4138... Val Loss: 1.6231\n",
            "Epoch: 39/40... Step: 3520... Loss: 1.5002... Val Loss: 1.6077\n",
            "Epoch: 39/40... Step: 3520... Loss: 1.5887... Val Loss: 1.6056\n",
            "Epoch: 39/40... Step: 3520... Loss: 1.5913... Val Loss: 1.6042\n",
            "Epoch: 39/40... Step: 3530... Loss: 1.5917... Val Loss: 1.5917\n",
            "Epoch: 39/40... Step: 3530... Loss: 1.5650... Val Loss: 1.5783\n",
            "Epoch: 39/40... Step: 3530... Loss: 1.8406... Val Loss: 1.6658\n",
            "Epoch: 39/40... Step: 3530... Loss: 1.8446... Val Loss: 1.7105\n",
            "Epoch: 39/40... Step: 3530... Loss: 1.5697... Val Loss: 1.6823\n",
            "Epoch: 39/40... Step: 3530... Loss: 1.5235... Val Loss: 1.6559\n",
            "Epoch: 39/40... Step: 3530... Loss: 1.4487... Val Loss: 1.6263\n",
            "Epoch: 39/40... Step: 3530... Loss: 1.5485... Val Loss: 1.6166\n",
            "Epoch: 39/40... Step: 3530... Loss: 1.5416... Val Loss: 1.6082\n",
            "Epoch: 39/40... Step: 3530... Loss: 1.6077... Val Loss: 1.6082\n",
            "Epoch: 39/40... Step: 3540... Loss: 1.5982... Val Loss: 1.5982\n",
            "Epoch: 39/40... Step: 3540... Loss: 1.5940... Val Loss: 1.5961\n",
            "Epoch: 39/40... Step: 3540... Loss: 1.8810... Val Loss: 1.6910\n",
            "Epoch: 39/40... Step: 3540... Loss: 1.8714... Val Loss: 1.7361\n",
            "Epoch: 39/40... Step: 3540... Loss: 1.6100... Val Loss: 1.7109\n",
            "Epoch: 39/40... Step: 3540... Loss: 1.5735... Val Loss: 1.6880\n",
            "Epoch: 39/40... Step: 3540... Loss: 1.4397... Val Loss: 1.6525\n",
            "Epoch: 39/40... Step: 3540... Loss: 1.5838... Val Loss: 1.6439\n",
            "Epoch: 39/40... Step: 3540... Loss: 1.5916... Val Loss: 1.6381\n",
            "Epoch: 39/40... Step: 3540... Loss: 1.6262... Val Loss: 1.6369\n",
            "Epoch: 39/40... Step: 3550... Loss: 1.6251... Val Loss: 1.6251\n",
            "Epoch: 39/40... Step: 3550... Loss: 1.5770... Val Loss: 1.6010\n",
            "Epoch: 39/40... Step: 3550... Loss: 1.8521... Val Loss: 1.6847\n",
            "Epoch: 39/40... Step: 3550... Loss: 1.9029... Val Loss: 1.7393\n",
            "Epoch: 39/40... Step: 3550... Loss: 1.6132... Val Loss: 1.7141\n",
            "Epoch: 39/40... Step: 3550... Loss: 1.5932... Val Loss: 1.6939\n",
            "Epoch: 39/40... Step: 3550... Loss: 1.4818... Val Loss: 1.6636\n",
            "Epoch: 39/40... Step: 3550... Loss: 1.5691... Val Loss: 1.6518\n",
            "Epoch: 39/40... Step: 3550... Loss: 1.5741... Val Loss: 1.6432\n",
            "Epoch: 39/40... Step: 3550... Loss: 1.6612... Val Loss: 1.6450\n",
            "Epoch: 39/40... Step: 3560... Loss: 1.6204... Val Loss: 1.6204\n",
            "Epoch: 39/40... Step: 3560... Loss: 1.5872... Val Loss: 1.6038\n",
            "Epoch: 39/40... Step: 3560... Loss: 1.8153... Val Loss: 1.6743\n",
            "Epoch: 39/40... Step: 3560... Loss: 1.8673... Val Loss: 1.7225\n",
            "Epoch: 39/40... Step: 3560... Loss: 1.5549... Val Loss: 1.6890\n",
            "Epoch: 39/40... Step: 3560... Loss: 1.5984... Val Loss: 1.6739\n",
            "Epoch: 39/40... Step: 3560... Loss: 1.4618... Val Loss: 1.6436\n",
            "Epoch: 39/40... Step: 3560... Loss: 1.6019... Val Loss: 1.6384\n",
            "Epoch: 39/40... Step: 3560... Loss: 1.5747... Val Loss: 1.6313\n",
            "Epoch: 39/40... Step: 3560... Loss: 1.6600... Val Loss: 1.6342\n",
            "Epoch: 39/40... Step: 3570... Loss: 1.6167... Val Loss: 1.6167\n",
            "Epoch: 39/40... Step: 3570... Loss: 1.5881... Val Loss: 1.6024\n",
            "Epoch: 39/40... Step: 3570... Loss: 1.8361... Val Loss: 1.6803\n",
            "Epoch: 39/40... Step: 3570... Loss: 1.8433... Val Loss: 1.7211\n",
            "Epoch: 39/40... Step: 3570... Loss: 1.6231... Val Loss: 1.7015\n",
            "Epoch: 39/40... Step: 3570... Loss: 1.5785... Val Loss: 1.6810\n",
            "Epoch: 39/40... Step: 3570... Loss: 1.4641... Val Loss: 1.6500\n",
            "Epoch: 39/40... Step: 3570... Loss: 1.5967... Val Loss: 1.6433\n",
            "Epoch: 39/40... Step: 3570... Loss: 1.5780... Val Loss: 1.6361\n",
            "Epoch: 39/40... Step: 3570... Loss: 1.6517... Val Loss: 1.6376\n",
            "Epoch: 39/40... Step: 3580... Loss: 1.6152... Val Loss: 1.6152\n",
            "Epoch: 39/40... Step: 3580... Loss: 1.5753... Val Loss: 1.5953\n",
            "Epoch: 39/40... Step: 3580... Loss: 1.8446... Val Loss: 1.6784\n",
            "Epoch: 39/40... Step: 3580... Loss: 1.8663... Val Loss: 1.7253\n",
            "Epoch: 39/40... Step: 3580... Loss: 1.6107... Val Loss: 1.7024\n",
            "Epoch: 39/40... Step: 3580... Loss: 1.5711... Val Loss: 1.6805\n",
            "Epoch: 39/40... Step: 3580... Loss: 1.4698... Val Loss: 1.6504\n",
            "Epoch: 39/40... Step: 3580... Loss: 1.5452... Val Loss: 1.6373\n",
            "Epoch: 39/40... Step: 3580... Loss: 1.5710... Val Loss: 1.6299\n",
            "Epoch: 39/40... Step: 3580... Loss: 1.6331... Val Loss: 1.6302\n",
            "Epoch: 40/40... Step: 3590... Loss: 1.6061... Val Loss: 1.6061\n",
            "Epoch: 40/40... Step: 3590... Loss: 1.5834... Val Loss: 1.5947\n",
            "Epoch: 40/40... Step: 3590... Loss: 1.8521... Val Loss: 1.6805\n",
            "Epoch: 40/40... Step: 3590... Loss: 1.8521... Val Loss: 1.7234\n",
            "Epoch: 40/40... Step: 3590... Loss: 1.5659... Val Loss: 1.6919\n",
            "Epoch: 40/40... Step: 3590... Loss: 1.5611... Val Loss: 1.6701\n",
            "Epoch: 40/40... Step: 3590... Loss: 1.4615... Val Loss: 1.6403\n",
            "Epoch: 40/40... Step: 3590... Loss: 1.5170... Val Loss: 1.6249\n",
            "Epoch: 40/40... Step: 3590... Loss: 1.6016... Val Loss: 1.6223\n",
            "Epoch: 40/40... Step: 3590... Loss: 1.6220... Val Loss: 1.6223\n",
            "Epoch: 40/40... Step: 3600... Loss: 1.5807... Val Loss: 1.5807\n",
            "Epoch: 40/40... Step: 3600... Loss: 1.5273... Val Loss: 1.5540\n",
            "Epoch: 40/40... Step: 3600... Loss: 1.8337... Val Loss: 1.6472\n",
            "Epoch: 40/40... Step: 3600... Loss: 1.7933... Val Loss: 1.6837\n",
            "Epoch: 40/40... Step: 3600... Loss: 1.5572... Val Loss: 1.6584\n",
            "Epoch: 40/40... Step: 3600... Loss: 1.5265... Val Loss: 1.6364\n",
            "Epoch: 40/40... Step: 3600... Loss: 1.4223... Val Loss: 1.6058\n",
            "Epoch: 40/40... Step: 3600... Loss: 1.5416... Val Loss: 1.5978\n",
            "Epoch: 40/40... Step: 3600... Loss: 1.5341... Val Loss: 1.5907\n",
            "Epoch: 40/40... Step: 3600... Loss: 1.5723... Val Loss: 1.5889\n",
            "Epoch: 40/40... Step: 3610... Loss: 1.5847... Val Loss: 1.5847\n",
            "Epoch: 40/40... Step: 3610... Loss: 1.5444... Val Loss: 1.5645\n",
            "Epoch: 40/40... Step: 3610... Loss: 1.8404... Val Loss: 1.6565\n",
            "Epoch: 40/40... Step: 3610... Loss: 1.8673... Val Loss: 1.7092\n",
            "Epoch: 40/40... Step: 3610... Loss: 1.5683... Val Loss: 1.6810\n",
            "Epoch: 40/40... Step: 3610... Loss: 1.5477... Val Loss: 1.6588\n",
            "Epoch: 40/40... Step: 3610... Loss: 1.4244... Val Loss: 1.6253\n",
            "Epoch: 40/40... Step: 3610... Loss: 1.5353... Val Loss: 1.6141\n",
            "Epoch: 40/40... Step: 3610... Loss: 1.5769... Val Loss: 1.6099\n",
            "Epoch: 40/40... Step: 3610... Loss: 1.6230... Val Loss: 1.6113\n",
            "Epoch: 40/40... Step: 3620... Loss: 1.6042... Val Loss: 1.6042\n",
            "Epoch: 40/40... Step: 3620... Loss: 1.5835... Val Loss: 1.5939\n",
            "Epoch: 40/40... Step: 3620... Loss: 1.8329... Val Loss: 1.6736\n",
            "Epoch: 40/40... Step: 3620... Loss: 1.8414... Val Loss: 1.7155\n",
            "Epoch: 40/40... Step: 3620... Loss: 1.5934... Val Loss: 1.6911\n",
            "Epoch: 40/40... Step: 3620... Loss: 1.5431... Val Loss: 1.6664\n",
            "Epoch: 40/40... Step: 3620... Loss: 1.4172... Val Loss: 1.6308\n",
            "Epoch: 40/40... Step: 3620... Loss: 1.5501... Val Loss: 1.6207\n",
            "Epoch: 40/40... Step: 3620... Loss: 1.5581... Val Loss: 1.6138\n",
            "Epoch: 40/40... Step: 3620... Loss: 1.6057... Val Loss: 1.6130\n",
            "Epoch: 40/40... Step: 3630... Loss: 1.6279... Val Loss: 1.6279\n",
            "Epoch: 40/40... Step: 3630... Loss: 1.6278... Val Loss: 1.6279\n",
            "Epoch: 40/40... Step: 3630... Loss: 1.8728... Val Loss: 1.7095\n",
            "Epoch: 40/40... Step: 3630... Loss: 1.8809... Val Loss: 1.7523\n",
            "Epoch: 40/40... Step: 3630... Loss: 1.5997... Val Loss: 1.7218\n",
            "Epoch: 40/40... Step: 3630... Loss: 1.5713... Val Loss: 1.6967\n",
            "Epoch: 40/40... Step: 3630... Loss: 1.4552... Val Loss: 1.6622\n",
            "Epoch: 40/40... Step: 3630... Loss: 1.6118... Val Loss: 1.6559\n",
            "Epoch: 40/40... Step: 3630... Loss: 1.6016... Val Loss: 1.6499\n",
            "Epoch: 40/40... Step: 3630... Loss: 1.6504... Val Loss: 1.6499\n",
            "Epoch: 40/40... Step: 3640... Loss: 1.6334... Val Loss: 1.6334\n",
            "Epoch: 40/40... Step: 3640... Loss: 1.5920... Val Loss: 1.6127\n",
            "Epoch: 40/40... Step: 3640... Loss: 1.8800... Val Loss: 1.7018\n",
            "Epoch: 40/40... Step: 3640... Loss: 1.9173... Val Loss: 1.7557\n",
            "Epoch: 40/40... Step: 3640... Loss: 1.6121... Val Loss: 1.7270\n",
            "Epoch: 40/40... Step: 3640... Loss: 1.5849... Val Loss: 1.7033\n",
            "Epoch: 40/40... Step: 3640... Loss: 1.4500... Val Loss: 1.6671\n",
            "Epoch: 40/40... Step: 3640... Loss: 1.5965... Val Loss: 1.6583\n",
            "Epoch: 40/40... Step: 3640... Loss: 1.5796... Val Loss: 1.6495\n",
            "Epoch: 40/40... Step: 3640... Loss: 1.6582... Val Loss: 1.6504\n",
            "Epoch: 40/40... Step: 3650... Loss: 1.6447... Val Loss: 1.6447\n",
            "Epoch: 40/40... Step: 3650... Loss: 1.5745... Val Loss: 1.6096\n",
            "Epoch: 40/40... Step: 3650... Loss: 1.9001... Val Loss: 1.7064\n",
            "Epoch: 40/40... Step: 3650... Loss: 1.8495... Val Loss: 1.7422\n",
            "Epoch: 40/40... Step: 3650... Loss: 1.5947... Val Loss: 1.7127\n",
            "Epoch: 40/40... Step: 3650... Loss: 1.5741... Val Loss: 1.6896\n",
            "Epoch: 40/40... Step: 3650... Loss: 1.4768... Val Loss: 1.6592\n",
            "Epoch: 40/40... Step: 3650... Loss: 1.5984... Val Loss: 1.6516\n",
            "Epoch: 40/40... Step: 3650... Loss: 1.6256... Val Loss: 1.6487\n",
            "Epoch: 40/40... Step: 3650... Loss: 1.6421... Val Loss: 1.6480\n",
            "Epoch: 40/40... Step: 3660... Loss: 1.6205... Val Loss: 1.6205\n",
            "Epoch: 40/40... Step: 3660... Loss: 1.5927... Val Loss: 1.6066\n",
            "Epoch: 40/40... Step: 3660... Loss: 1.8582... Val Loss: 1.6905\n",
            "Epoch: 40/40... Step: 3660... Loss: 1.8836... Val Loss: 1.7388\n",
            "Epoch: 40/40... Step: 3660... Loss: 1.6234... Val Loss: 1.7157\n",
            "Epoch: 40/40... Step: 3660... Loss: 1.6209... Val Loss: 1.6999\n",
            "Epoch: 40/40... Step: 3660... Loss: 1.5156... Val Loss: 1.6736\n",
            "Epoch: 40/40... Step: 3660... Loss: 1.5652... Val Loss: 1.6600\n",
            "Epoch: 40/40... Step: 3660... Loss: 1.6259... Val Loss: 1.6562\n",
            "Epoch: 40/40... Step: 3660... Loss: 1.6584... Val Loss: 1.6564\n",
            "Epoch: 40/40... Step: 3670... Loss: 1.6200... Val Loss: 1.6200\n",
            "Epoch: 40/40... Step: 3670... Loss: 1.5434... Val Loss: 1.5817\n",
            "Epoch: 40/40... Step: 3670... Loss: 1.8647... Val Loss: 1.6760\n",
            "Epoch: 40/40... Step: 3670... Loss: 1.8807... Val Loss: 1.7272\n",
            "Epoch: 40/40... Step: 3670... Loss: 1.5982... Val Loss: 1.7014\n",
            "Epoch: 40/40... Step: 3670... Loss: 1.5975... Val Loss: 1.6841\n",
            "Epoch: 40/40... Step: 3670... Loss: 1.5223... Val Loss: 1.6610\n",
            "Epoch: 40/40... Step: 3670... Loss: 1.5646... Val Loss: 1.6489\n",
            "Epoch: 40/40... Step: 3670... Loss: 1.6030... Val Loss: 1.6438\n",
            "Epoch: 40/40... Step: 3670... Loss: 1.6573... Val Loss: 1.6452\n",
            "Epoch: 40/40... Step: 3680... Loss: 1.6433... Val Loss: 1.6433\n",
            "Epoch: 40/40... Step: 3680... Loss: 1.6057... Val Loss: 1.6245\n",
            "Epoch: 40/40... Step: 3680... Loss: 1.8656... Val Loss: 1.7049\n",
            "Epoch: 40/40... Step: 3680... Loss: 1.8666... Val Loss: 1.7453\n",
            "Epoch: 40/40... Step: 3680... Loss: 1.5924... Val Loss: 1.7147\n",
            "Epoch: 40/40... Step: 3680... Loss: 1.5819... Val Loss: 1.6926\n",
            "Epoch: 40/40... Step: 3680... Loss: 1.4939... Val Loss: 1.6642\n",
            "Epoch: 40/40... Step: 3680... Loss: 1.5373... Val Loss: 1.6483\n",
            "Epoch: 40/40... Step: 3680... Loss: 1.5895... Val Loss: 1.6418\n",
            "Epoch: 40/40... Step: 3680... Loss: 1.6187... Val Loss: 1.6395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTSUTT4vBMlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the model with the name_numberOfEpoch.net\n",
        "modelname = 'lstm_20_epoch.net'\n",
        "\n",
        "checkpoint = {'n_hidden': network.n_hidden,\n",
        "              'n_layers': network.n_layers,\n",
        "              'state_dict': network.state_dict(),\n",
        "              'tokens': network.chars   \n",
        "}\n",
        "\n",
        "with open(modelname, 'wb') as f:\n",
        "  torch.save(checkpoint, f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQQuoAdQT8hy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(network, char, h= None, top_k= None):\n",
        "  # tensor inputs\n",
        "        x = np.array([[network.char2int[char]]])\n",
        "        inputs = torch.from_numpy(x)\n",
        "\n",
        "        inputs = oneHotEncode(inputs, len(network.chars))\n",
        "        \n",
        "        if(train_on_gpu):\n",
        "            inputs = inputs.cuda()\n",
        "        \n",
        "        # detach hidden state from history\n",
        "        h = tuple([each.data for each in h])\n",
        "        # get the output of the model\n",
        "        out, h = network(inputs, h)\n",
        "\n",
        "        # get the character probabilities\n",
        "        p = F.softmax(out, dim=1).data\n",
        "        if(train_on_gpu):\n",
        "            p = p.cpu() # move to cpu\n",
        "        \n",
        "        # get top characters\n",
        "        if top_k is None:\n",
        "            top_ch = np.arange(len(network.chars))\n",
        "        else:\n",
        "            p, top_ch = p.topk(top_k)\n",
        "            top_ch = top_ch.numpy().squeeze()\n",
        "        \n",
        "        # select the likely next character with some element of randomness\n",
        "        p = p.numpy().squeeze()\n",
        "        char = np.random.choice(top_ch, p=p/p.sum())\n",
        "        \n",
        "        # return the encoded value of the predicted char and the hidden state\n",
        "        return network.int2chars[char], h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCpRV40wrvkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(network, size, prime, top_k=None):\n",
        "        \n",
        "    if(train_on_gpu):\n",
        "        network.cuda()\n",
        "    else:\n",
        "        network.cpu()\n",
        "    \n",
        "    network.eval() # eval mode\n",
        "    \n",
        "    # First off, run through the prime characters\n",
        "    chars = [ch for ch in prime]\n",
        "    h = network.init_hidden(1)\n",
        "    for ch in prime:\n",
        "        char, h = predict(network, ch, h, top_k=top_k)\n",
        "\n",
        "    chars.append(char)\n",
        "    \n",
        "    # Now pass in the previous character and get a new one\n",
        "    for ii in range(size):\n",
        "        char, h = predict(network, chars[-1], h, top_k=top_k)\n",
        "        chars.append(char)\n",
        "\n",
        "    return ''.join(chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRvsrNTBsE9z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "551b324b-124f-46d8-d6a3-2400404e2c7e"
      },
      "source": [
        "print(sample(network, 30000, prime='Jesu', top_k=5))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jesu. \n",
            "46 Ṣùgbọ́n kí ẹ̀yin náà sì ń wá ọ̀nà láti máa rìn, wọ́n ń wá ọ̀nà sárà sí àwọn ènìyàn pé àwa tí ń bẹ nínú rẹ̀. \n",
            "18 Nítorí pé kí a má ba à ṣáájú yín ju ni ọmọ Josẹfu,tí í ṣe ọmọ Enamu,tí í ṣe ọmọ Aamini,tí í ṣe ọmọ Aali, tí í ṣe ọmọ Maattati,tí í ṣe ọmọ Judeatili, tí í ṣe ọmọ Neti,tí í ṣe ọmọ Elmeki,tí í ṣe ọmọ Nealiti,tí í ṣe ọmọ Elmu,tí í ṣe ọmọ Matttiti,tí í ṣe ọmọ Aadi, tí í ṣe ọmọ Joa,ti,tí í ṣe omi wá ni ibi sí ìdòde; \n",
            "50 (Ó sì dáhùn, ó sì fi ìrò mọ́ àwọn tí ó ń gbàdúrà, láti máa sìn láti ṣe fún un. \n",
            "27 Nítorí pé, èmí ń fi ọ̀pá rìrà; ṣùgbọ́n ẹni tí ó kọ́ ohun tí Ọmọ ènìyàn sì ń wàásù ìgbàgbọ́ tí ó ń gbọ́ ni ọ̀rọ̀ tí ó wà fún ọ pé, “Ẹ wá kò wí pé, “Èmi kò lè fi ìwọ̀n mọ́.” \n",
            "16 Àkókò ní ìjọba Ọ̀dọ́-àgùntàn ọ̀rọ̀ wọn; ó sì pè ní sábẹ́ òfin tí ó wí fún wọn pé, “Ẹ má ṣe jẹ́ kí a máa jẹ́ ti ara rẹ jẹ ní ọjọ́ mẹ́ta: nítorí tí a ń fi ọkàn, tí ìwọ kò sì tọ̀ ọ́ wí nípa iṣẹ́. \n",
            "41 Nígbà tí ó sì dá wọn lóhùn pé, “Èmi yóò fi ṣe náà ní ẹ̀kọ́ òfin, bẹ́ẹ̀ ni ó wà níbẹ̀, ó sì ń wá ọ̀n lọ́gọn ènìyàn.” \n",
            "21 Nítorí pé ẹ̀yin fẹ́ àwọn tí ń bọ tí ó rí ohunkóhun tí ìwọ ti rí, àti ti ara rẹ ni yóò fi ara rẹ̀ ní ọjọ́ kan nínú rẹ̀, àwọn ọmọ-ẹ̀yìn rẹ̀ sì ń bá a lè jáde wá láti gbàgbọ́: nítorí tí ẹ̀yin kò sì mọ̀.” \n",
            "38 Nítorí náà, Jesu wí fún un pé, “La ó ti ọ̀run wá ni.” \n",
            "12 Nígbà náà ni wọ́n ti ilé wọn ní ọjọ́ kan \n",
            "4 Ní ọjọ́ kejì nítorí pé ó tó bí àgbára rún má ṣe padà sí ìwà mímọ́ náà tí a sọ tí ń bọ̀. \n",
            "22 Nítorí tí ó fi wọ́n wí fún un pé, “Lóòótọ́ yóò mọ̀ pé ìwọ ní ayọ̀ kò sì mú ọ̀rọ̀ Ọlọ́run. \n",
            "22 Ṣùgbọ́n èmi mọ í ṣe nípa iṣẹ́ ìyè àìnípẹ̀kun ní agbèrè. \n",
            "28 Ṣùgbọ́n nígbà tí ẹni tí kò ká sí ìyè náà, aláìní èyí tí ó tun sùrù láti kú wọn:” \n",
            "15 Jesu sì wí fún un, ẹni tí ó bára láti máa fi ohun rí àti àgàntàn? \n",
            "40 Nítorí náà, ó wí pé, “Èmi kò lè ṣàìmù láradá. \n",
            "12 Nítorí náà ni àwa ó sì mọ̀ pé, ẹni tí ó bá sì dá ayàwọ̀ láti gbé ojú rẹ̀ síbẹ́ ní ọjọ́ kajá, tí ìwọ ń sọ mọ́ ti ará, nítorí tí àwọn wọn yóò gbà wá là, kò sì ní ìgbàgbọ́ láàrín ọmọ mi, ó sì wí fún un pé, “Ìwọ fi ọmọ Ọlọ́run pé, èmi ó fi fún wa, ó.” \n",
            "13 Nígbà náà ni ó ti gbọ́ ohùn kan sì yóò sì gba ẹ̀rí mi: ẹ̀yin kò sì dá ara rẹ lọ. \n",
            "21 Nítorí tí ojú rẹ já ọ̀kan ni àwànyín ni yóò já ẹ̀yin mú oúnjẹ láti mọ̀ ọ́n wá, wọ́n sì wá sí ibù, wọ́n sì ń gbé ọ̀rọ̀ náà, tí ó wí fún ọkùnrin náà tí ó ṣe. \n",
            "23 Ṣùgbọ́n kí ẹ̀yin kò ti rí ìgbàlà wọn lóhùn pé, “Ẹ̀yin kọ ká gbà mí, ó ń fi agbọgbọ̀rọ̀ rẹ̀ pẹ̀lú wá.” \n",
            "36 Nítorí tí owún mẹ́rìn láti ọ̀dọ̀ Jesu Kristi Olúwa. \n",
            "26 Ṣùgbọ́n kí ẹ̀yin fẹ́ àwọn ọmọ-ẹ̀yìn rẹ̀ sì jókòó; tí ó sì ń ṣe nǹkan wọ̀nyí; nítorí tí ẹ̀yin ń fẹ́ wí pé, “Lónítọ́, wọ́n sì ń gbé ní ìgbàgbọ́, ó sì mú ọkùnrin náà pé, “Ẹni tí ó ká lọ́wọ́ wọn lọ, àwọn angẹli náà wí fún un pé, “Ẹ mú pé ọwọ́ kì í ṣe ọmọ Matati,tí í ṣe ọmọ Meti,tí í ṣe ọmọ Jameli,tí í ṣe ọmọ Netati,tí í ṣe ọmọ Matttiti, tí í ṣe ọmọ Jaadi,, í ṣe ọmọ Jomi, \n",
            "25 Tí í ṣe ọmọ Elo, tí í ṣe ọmọ Nattiti, tí í ṣe ọmọ Mettatiti,tí í ṣe ọmọ Jode, tí í ṣe ọmọ Natini; tí í ṣe ọmọ Natati,tí í ṣe ọmọ Abami,,tí í ṣe ọmọ Anmi náà, nígbà tí àwọn ọmọ-ẹ̀yìn rẹ̀ wà pẹ̀lú wọn. \n",
            "16 Ṣùgbọ́n kí ẹ̀yin tí ó ń gbà sí ẹ̀gbọ́n ni a ó gbàgbọ́ ti ibẹ̀ kọjá sí òkò inú ọkọ̀ ojú omi lọ; nítorí tí ó fi ń jẹ́rìí yín, nígbà tí àwọn tí ó bá wọn sì màa sọ ohun gbogbo ni ó sọ̀kọ́ lọ́wọ́ àti àwọn ọmọ-ẹ̀yìn rẹ̀. \n",
            "22 Nítorí pé, nígbà tí ó bi má ṣe ran mi: nítorí tí ẹ̀yin ti gbàdúrà, tí a sì rí i pé a kò lọ sí Jerusalẹmu ní agigjùjá ní àwọn agbora, ọkàn rẹ̀ sọ fún ọ pé, kò sí ẹni tí ó mọ ọ̀rọ̀, àti láti mú wọn ní agbára lórí nípa iṣẹ́, òun ni ó ṣe ní àwọn tí kò gbàgbọ́ ni ọwọ́ náà nítorí pé àwọn tí ó tẹ́lẹ̀ jáde lọ sí àjọ. \n",
            "26 Nítorí tí a tí kọ ọ́ pé, “Ẹ kò sì gba ìwà mímọ́ nínú ìgbàgbọ́ náà tí ó tọ̀ ọ́ wá, ó wí pé, “Èmi ni ìyí tí ń bá ti rí ohun ti Ọ̀dọ́-àgùntàn náà pé wọn kò lè ṣe olórí ìlú kan, kí ẹ̀yin kò sì gbọ́ ohùn rẹ̀.” \n",
            "31 Nítorí bí olúkúlùkù ẹni tí ó bá jẹ́ ìránmọ́ lọ, láti gba òtítọ́ sí i nínú àwọn ọ̀tá yín kí wọn kí ẹ̀yin sì ti ṣe nǹkan wọ̀nyí, nígbà tí àwọn agbogbè ti a ti dá mi sínú ohun máa pè é.” \n",
            "32 Nígbà náà ni ó wọ inú ọkọ̀, ó sì ń wàásù nínú Sinagọgu ti àwọn ènìyàn púpọ̀ lọ sá ní etí ẹ̀ṣọ̀ tí ó dá wọn lójútalẹ̀, ó wí pé, “Ọmọ ènìyàn kò ti ṣe gbogbo wọn sọ nǹkan wọ̀nyí ní agbára wá láti ṣe bẹ́ẹ̀ ti. \n",
            "55 Ṣùgbọ́n nígbà náà ni ẹni tí ó bá jẹ ní ọjọ́ kan, ó ń wàásù ìránṣẹ́ rẹ láti ọ̀dọ̀ Ọlọ́run, ó sì dé lárádá, a sì fi ọ̀dá rẹ̀ mọ́; bí kò ṣe ẹ̀mí èṣù jáde kúrò ní ìlérí. \n",
            "19 Jesu wí fún un pé, “Alábùkún fún ni àwọn ọmọ-ẹ̀yìn rẹ̀; wọ́n sì ń wí fún ọ, pé, “Má ṣe jẹ́ pẹ̀lú. \n",
            "24 Ṣùgbọ́n èmi mọ̀, ó sì wí fún un pé, “Èmi mọ ọmọ rẹ̀ méjìlá, tí ó sì ń bẹ lórí rẹ̀, kò sì máa ṣe ní ọ̀run. \n",
            "25 Nítorí náà ni ó ń jẹ́rìí wí fún un pé, “Èyí ni a ti fi omi kan sì ń bọ̀ pẹ̀lú ọmọ mẹ́ta, nígbà tí àwa ni ìyàn mẹ́rin mi tí ó bá gbà á gbọ́, ó sì dúró ní ọgbọ̀n.” \n",
            "11 Ṣùgbọ́n ẹni tí ń bá ni ìyè, àwọn ọmọ-ẹ̀yìn rẹ̀ sì dé òkú sí i wí pé, “Ẹni tí ó bá gbà á jókọọ́ bí kò ṣe ọmọ Josafu. \n",
            "22 Nítorí náà nígbà tá àwọn tí ó ń ṣe ni ẹ̀yin ń fi omi rẹ̀ ní?” \n",
            "49 Nígbà náà ni wọ́n wá láti pa gbogbo àwọn tí ó jẹ́ tí a kò lé wọ inú ìsinmi rẹ̀ sílẹ̀ níwájú wọn; wọ́n sì bọ orúkọ rẹ̀ sí mọ̀. \n",
            "22 Ṣùgbọ́n èyí ni ẹni tí ó fi ọmọ kan tí ó dárí ẹ̀ṣẹ̀ mi. \n",
            "5 Ẹni sì ń kọ́ nínú àwọn tó bọ́. \n",
            "25 Ẹ̀rù sì bà wọ́n fún yín. \n",
            "38 Kò sí ẹni tí ó bá ní, wọ́n ń wí fún un pé, “Èmi kọ ọ̀ mọ́, kí ó má ṣe ṣe àníyàn wí pé, “Èyí ni ó rán mi nínú ilé ní ìwọ ó gbọ́ papà wọ inú iṣẹ̀ ara rẹ̀. \n",
            "15 Nítorí pé nígbà tí àwọn ẹ̀mí èṣù jẹ́ kí a ti wá sí ọkàn wọn lọ; ó sì ń wá ọ̀nà mìmọ́, lóòótọ́ ni mo wí fún yín pé, “A ti kọ ọ́ pé, ‘Ìwọ fẹ́ kí ẹ má ṣe bà mí gbọ́, ó sì fẹ́ kí inú iṣẹ́ rẹ̀. \n",
            "24 Èmi ó tọ̀ ọ́ wí fún wọn pé, “Èmi ni arẹ náà tí ó fi agbára mi fẹ́ rin lórí àpẹ́ tí ó ti ọ̀du sí ni ìwọ kí ó máa sìn nínú àwọn tí a gbà pè wọ́n lọmọ Ọlọ́run, àti àwọn tó sì jókòó pẹ̀lú àwọn ọmọ-ẹ̀yìn rẹ̀, wọ́n wí pé, “Láì bá a sì mú wọn jákejì kí ẹ̀yin kú.” \n",
            "30 Nítorí pé olórí àlùfáà tò ṣí ní orúkọ ọmọ rẹ̀ kò gbọ orí rẹ̀. \n",
            "28 Nítorí náà nígbà tí wọ́n wí pé, “Èmi ni ìyín wọn sì gbé e kalẹ̀ lọ; ó sì ń fi ògo rẹ̀ sàn lógba. \n",
            "29 Ẹ̀yin kò sì dàgbà, a sì ti ọkọ̀ ojú omi kò lè ṣe ohun tí wọ́n sì rí iṣẹ́ ààmì wọ̀nyí, tó kí a máa ń fẹ́ láti ṣe bẹ́ẹ̀, ó gbọ́ ohun tí ẹ̀yin ń ṣe ní àkókò náà, tí ó sì fi ìwé náà, ó sì wí fún un pé, “Ẹ má ṣe jẹ ọmọ, mo sì fi ọ̀dá wà lọ́dọ̀ rẹ̀.” \n",
            "21 “Nígbà náà ni Jesu wí fún un pé, “Èmi ni. \n",
            "27 Èmi kò ní ẹni tí ó kún fún ọ̀rọ̀; wọ́n sì wí fún un pé “Kò ti ọ̀run wá, kí èmi lè mú un yí pé, “Bó wọ́n ti ń wá ní orí ìlú tí a fi ọmọ rẹ̀ kò gbangba náà nítorí tí ó ti ṣe ìtẹ̀bọmi sí ayé, ó si ti wá sí ìyè rẹ̀?” \n",
            "31 Ó wí fún ọmọnìnrin náà wí fún un pé, “Èmi kò lè ṣe iṣẹ́ ìyanu rẹ̀. \n",
            "25 Ṣùgbọ́n nígbà tí àwọn ọmọ-ẹ̀yìn rẹ̀ sì jẹ́ ìran mẹ́rìn,láti ọmọ láààyè.” \n",
            "5 Nígbà náà ni àwọn tí ń bẹ ní Jesu, tí í ṣe ọmọ Naigi, tí í ṣe ọmọ Netisi,tí í ṣe ọmọ Mattiti, tí í ṣe ọmọ Mamtiti, tí í ṣe ọmọ Jaatiti? \n",
            "30 Nítorí pé nígbà tí àwa tò bí ènìyàn lọ, ó sì máa pè nínú wọn lọ, ó sì ń gba ọmọ rẹ̀, nínú rẹ̀ ni ó ń ṣe ìtẹ́bọmi láti mu wá ju di, nítorí pé ẹ̀yin, kò ṣe pẹ̀lú; nítorí tí àwa yóò fi gbàgbà sí i ti ó sì dá wọn lóhùn wí pé, “Èmi kò lè ṣí ìtẹ́bọmi fún yín.” \n",
            "13 Nítorí náà nígbà tí ó ti wà sọ̀dọ̀ rẹ̀. \n",
            "38 Nítorí náà, ẹlẹ́rìí yóò yà wọn ní ọjọ́ kan. \n",
            "43 Nítorí èyí ti ń ròn láti ọ̀dọ̀ Baba wá, àti nítorí ìgbọ́kan ní ìlọ̀kọ́; kí ó lè dè ọ̀n sílẹ̀ láti mo sì jáde, ó wí pé, “Ẹni tí ó bá sì dúró ní òtìtọ́ Ọlọ́run. \n",
            "40 Ṣùgbọ́n kí ó lè máa pa á, ó máa sọ ohun gbogbo fún yín, nítorí tí àwa ń ṣe ti àwọn tí ó ń jọ nínú, bí kò ṣe ẹni tí a fi kọ́ wá láti ṣe búburú.\n",
            "10 Nítorí náà ẹni tí ó bá ṣe bá a gbé wa mọ́. \n",
            "5 Nítorí pé kí ẹ sì fi ara rẹ̀ sọ̀wé. Nítorí náà ni ó sì dúró, wọ́n sì ń fẹ́ láti fi ìdájọ́ rẹ̀; \n",
            "14 Ẹni tí ó bá gbà á gbọ́, ó wí fún ọ pé kò ní ènìyàn, tí ó sì wá fún yín láti ọ̀dọ̀ Olúwa láti máa ṣe, nítorí tí a mú wá. \n",
            "20 Nítorí nínú àwọn tí ń bẹ láàrín ọmọ Ọlọ́run. \n",
            "46 Nítorí náà ni ọmọ rẹ̀ ń tọ̀ mí wá sí ìyè tí ń bẹ ní ọ̀run, àti ẹni tí a rò, ẹ̀yin kò sì gbà á sínú ọkọ̀ méjì, nítorí tí ó wí fún ọkùnrin kan tí ó bà sì mọ́, ó sì ń bẹ nínú rẹ̀, tí ó bá gbọ́ ọmọ Ọlọ́run.” \n",
            "4 Jesu wí fún un pé, “Èmí kí ó má rí i pé ní láti máa ṣe èyí pé, “Alábùkún fún ni ẹ̀yin ni ìwọ ń ṣe ní ọjọ́ méjì.” \n",
            "5 Àwọn aláìsàn pẹ̀lú àwọn agbowó òkù kò sì yé àwọn tí ó ń ṣe ni ó dé má ṣe rò nínú àwọn ọmọ ọkàn ní àwọn tí ó bẹ́rẹ̀ sí wí pé, ‘Ìwọ ni èmi ó fi fún yín láti mú àwọn tí ó jẹ́ pé, “Èmi mọ ohun tí ó ṣẹ̀ṣẹ̀ sì tọ Johanu sínú ohun tí ó ṣe ní ọjọ́ mẹ́ta láti gba ẹ̀mí mi sọ̀rọ̀-mọ́ lè dábabá wa sọ̀nà láti jẹ.” \n",
            "20 Nítorí pé nǹkan wọ̀nyí. \n",
            "41 Nígbà tí ó sì ń wá láti ọ̀dọ̀ Olúwa wa sínú ọwọ kan tí ó ti ọ̀run sọ̀kalẹ̀ wá, kìyín yìí ni ó ti rán ọmọ rẹ̀ kò sí láààyè nípa ti Ẹ̀mí, àti ọmọ rẹ̀. \n",
            "48 Nítorí tí ó ṣe rere lọ́dọ̀:\n",
            "20 Ṣùgbọ́n kò sì mọ̀ pé, kò sí ẹni tí ó lè mọ́? Nítorí tí a ti kọ ọ́ pé, “Ìfàbà ọmọ, ó tún fi fún wọn. \n",
            "36 Nítorí náà, ó sọ fún ọ pé, “Ẹ yóò fẹ́ gba gbogbo àwọn tí ó ń gbé ní iṣẹ́ rẹ̀.” \n",
            "11 Ṣùgbọ́n kí ohun tí ó wá sì ń ṣe ní apá mi, nítorí tí a mọ̀ pé ẹnìkan tí ó dá wà lẹ́yìn. \n",
            "22 Nítorí tí a fi fún un ju inìyìí láti máa ṣe: nítorí ìjọba ni ó ti ṣe ní ọjọ́ kan. \n",
            "12 Nítorí pé, èmi ń rò lọ́dọ̀ rẹ̀, ó sì wí fún un pé, “Ẹ mú wà fún oúnjẹ yìí; ó ti ṣe bẹ́ẹ̀ ni wọn ti ń fi ìyènà tún fi ara rọ̀, ẹni tí ó fi ọwọ́ rẹ̀ jẹ́. Àwọn ọmọ-ẹ̀yìn mi. Nítorí tí ó wà pẹ̀lú mi lórí ìgbàlà ńlá tí ń ṣe ní àgbàgbọ́ ni ó tọ ohun gbogbo wí fún un pé, “Ìwọ ti rí ibi pé, “Èmi ni ọmọ rẹ ti ń bọ tí wọ́n ń tọ̀. \n",
            "35 Nítorí ẹ má ṣe ṣe tún wò. \n",
            "14 Èmi mọ iṣẹ́ rẹ? Ẹ má ṣe jẹ́ tí a ti fi fún ọ̀n kan láti mú ọ lére nínú àwọn ẹni tí ó bá gbọ́ ọ̀rọ̀ náà, wá sì gbọ́ bí a ti pọ̀rù wọn lọ sí ọ̀dọ̀ Ọlọ́run, ẹni tí ó bá sì jọ. \n",
            "36 Ṣùgbọ́n kò nì í ṣe sí ẹ̀bùn mi, ó sì wí pé, “Lóòótọ́ ni mo wí fún yín, wọ́n kọ̀ ojú omi lọ́dọ̀ rẹ̀ pàápé rẹ̀, níwọjú ènìyàn kò sì mọ́ pé, “Ọmọ Ọlọ́run ni ó bá ṣe sì mọ́. \n",
            "25 Ṣùgbọ́n èmi kò lè ṣe iṣẹ́ ìyanu tẹ́lẹ̀ rẹ láti inú ìyá rẹ̀ ní ọmọ.” \n",
            "13 Nígbà náà ni àwọn ọmọ-ẹ̀yìn rẹ̀ sì ń jẹ lẹ́yìn mi, ó wí pé, “Lóòótọ́ ni mo wí fún ọ, ó sì mu ohun tí ó wà ní ìlú náà ni a kò dáríjì a ti fi ìgbà wọ́n.\n",
            "10 Nítorí tí àgbèrè. \n",
            "28 Àwọn ọmọ-ẹ̀yìn rẹ̀ ń wá inú rẹ̀ nítorí tí ó wí fún un pé, wọn ń ṣe nǹkan wọ̀nyí ní ojúrere mìíràn; bí ẹ̀yin bá sì máa sọ ohun gbogbo tí ó ti ṣe ní ojú arákùnrin rẹ̀, tí ó sì wí fún un pé, “Lọ́dọ́ rẹ̀, wọ́n ń rán orí rẹ̀ ni ìjọba Ọlọ́run fún àwọn tí ń wá ọ̀pọ̀ ènìyàn rẹ̀, àti àwọn tí ó gbà wọ́n. \n",
            "40 Ṣùgbọ́n ẹ̀yin ó tọ̀ mí wá, àti àwọn ọmọ-ẹ̀yìn rẹ̀ ń fẹ́ láti fi òmini a sọ̀kalẹ̀ lọ, ó sì fi ara rẹ̀ ń bọ̀ nínú yín pé, kì í ṣe ni ọwọ́ náà,; àwọn tí ó ń ṣe ní àwọn ènìyàn sì tàní ọ̀dọ̀ rẹ̀. Ó búra, ohun tí ó ní omi kan fún ọ.” \n",
            "13 Nítorí pé nípa ìwọ ìwọ ó bá gba ara yín ní oúnjẹ, tí ó bá ń ṣe bẹ́ẹ̀, ó ti ọ̀pọ́ ènìyàn sọ̀kalẹ̀ wá, wọ́n sì bá a rá láti ọwọ́ rẹ̀ jóde kúlò nínú ọkùnrin náà ní ìlọ ní àìmọ́; bí ẹ sì ń jẹ orí ọmọ Ọlọ́run, àti ẹ̀yin kò mọ̀ pé ẹ̀yin kò mọ̀ pé, “Ẹ̀yin yóò ṣe bá sì gbà á lórí ẹ̀ṣẹ̀ ji ni ẹni tí ó fi ohun gbogbo ní àánú.” \n",
            "21 Ní ìjọba Ọlọ́run lógo èkò kò gbọ́ ní ojú adá kan, bí ó ti wá láti jẹ níbi gidigidi. Àwọn tí ó bẹ́rẹ̀ rẹ̀ ti ṣe lè gba ọmọ ọwọ́ náà, àwọn ọmọ-ẹ̀yìn rẹ̀ ń bẹ ní ilò wọ́; báyìí ni ó wá sí ìjọba. Ó sì ń wí pé, “Ẹni tí ó bá ni ìyàwó ni ẹ̀yin ń pè ní Patemu nítorí àwọn tí ó gbà ára náà tí wọ́n sọ̀kọlẹ̀ wá láti wí pé, “Ẹni tí ó bá sì gbé ojú rẹ̀. \n",
            "15 Ẹni tí ó bá gbà á gbọ́, ó wí pé, “Èmi kì í bá ń ṣe náà ni ó lè gbọ́ nípa rẹ̀ láti ọ̀run wá: tí ó sì ti di ẹrú ọ̀dọ̀ rẹ̀, wọ́n sì ń tọ̀ ọ́ wá láti wá fún yín jẹ́. \n",
            "12 Nítorí náà nígbà tí ọ̀pọ̀lẹ̀, wọ́n ń tọ̀ wá lẹ́yìn, nítorí pé ní àìmọ́ wá. \n",
            "20 Nítorí tí a ti rán mi láti máa ṣe orí rẹ̀. \n",
            "5 Nígbà tí Jesu wí fún un pé, “Olúwa wọ angẹli náà sì ń bà láradá.” \n",
            "31 Nítorí pé ẹni tí ó tọ́ ọ́rọ̀ wọn lérí láti máa fi ìmiyàra kúrò lọ́dọ̀ wọn. \n",
            "14 Nítorí náà, ó wí fún un pé, “Ìwọ fi a mú orúkọ rẹ̀ ní Jesu. \n",
            "48 Nítorí tí omi kò lè má ṣe fi ìfẹ́ Ọmọ ni ọkàn yóò sinmọ ọkùnrin náà, ó sì wí fún un pé, “Lọ fi orílọ̀rọ̀ mi: èmi yóò fi gbé e kọjá lọ, kí a mè ṣè dá láìlẹ́. \n",
            "20 Nítorí pé nípa ìgbàgbọ́ lọ sórí ẹ̀ṣẹ̀ ji ni, nítorí pé wọ́n wí fún un pé, “Olúwa ọjọ́ kẹ́kọ́.” \n",
            "31 Ṣùgbọ́n ẹni tí ó ń bá nínú wọn nínú ìwé àìmọ́. \n",
            "46 Nítorí èyí ni a kọjá lọ.” \n",
            "12 Nítorí tí a kọ́ ní ọ̀rọ̀ náà ní òdodo sí mi.” \n",
            "3 Jesu wí fún un pé, “Èyí ni ohun kan tí ó bùkún fún ni a ó sì fi fún ẹni tí ó jókòó lórí ìtẹ́ tẹ̀lé rẹ̀: nítorí nínú ìwọ ni ara rẹ jọ nínú wọn. \n",
            "12 Ṣùgbọ́n ẹ̀yin kò mọ̀ pé, “Ẹni tí ó bá sì jáde lọ, kí ó sì fi ogbo àkọ́bí, nígbà tí a ń fẹ́ kí wọn láradá: náà kò ní ọmọ rẹ̀, tí a ti fi gbogbo wọn lọ sí ọ̀run.’ ” \n",
            "2 Nígbà náà ni ó wí fún un pé, “Èmi ni ọ̀rọ̀ wọn: nítorí tí ó ń wá lójú nínú yín ní ààrùn náà sì fi ọkùnrin náà pé, “Alábùkún fún ni ẹ̀yin nígbà tí ẹ̀yin kì yóò jẹ́ baba rẹ̀. \n",
            "35 Ẹni tìkí a ti fi ọ́ jáde. \n",
            "14 Nítorí tí a ń fi òkì kọlà wọ, ní àánú ọ̀pọ̀ ènìyàn sínú ọkàn wọn. \n",
            "4 Nítorí náà ni àwọn ọmọ-ẹ̀yìn rẹ̀ wọ inú ọkọ̀ ojú omi kí ó mọ̀. \n",
            "47 Àti nípa ìdàwọ́ mọ̀, àwọn ọmọ-ẹ̀yìn rẹ̀ sọ wá sí àwọn angẹli náà fi wá sí ibi.” \n",
            "20 Jesu dáhùn ó sì wí fún un pé, “Ìwọ̀ni tí ó bá ti gbàgbọ́, àti ìgbàlà ńlá ti ń ba ti fi ohun tí ó ń fẹ́ láti ọ̀dọ̀ Jesu tí ó dàbí ẹni tí ó fẹ́ gbé àwọn ọmọ-ẹ̀yìn rẹ̀; àwọn tí ó jókòó pẹ̀lú wọn ni ó fi ohun gbogbo wá sí ìjú,lí ìgbàyà rẹ̀ pẹ̀lú wọ inú ọkùnrin kan, tí ẹ̀yin ń sọ fún un pé, “Aràbúnrin ará Galaria \n",
            "3 Lẹ́yìn èyí ni ó tọ̀ mí wá. \n",
            "32 Nítorí tí ó ṣẹlẹ́ sí ibí náà pẹ̀lú rẹ̀, nítorí pé ó tàbá ń pè mọ́, kí a má ba à lé e, ó sọ̀kalẹ̀ wá sí ìbínú rẹ̀ pé, “Èyí ni ìwọ kò mọ́ angẹli rẹ̀ lọ.” \n",
            "16 Jesu dáhùn, ẹsẹ̀ kí o sì mọ èyí. \n",
            "31 Nígbà náà ni wọ́n sì wá ní ojú àti ọ̀wọ̀n.”\n",
            "10 Jesu sì wí fún un pé, “Lóòótọ́ ni.” \n",
            "34 Nítorí tí ìwọ ti rí ọmọ ọwọ́ náà ní àwọn ọmọ-ẹ̀yìn rẹ̀; \n",
            "7 Jesu ti kọ̀nwọn lọ bẹ́ẹ̀, ó sì ń ṣe nǹkan wọ̀nyí. \n",
            "39 Nítorí èmi ni ẹ̀yin ń fi ọmọ rẹ̀. \n",
            "25 Àwọn angẹli náà wí pé; “Ẹ mú ọmọnìkejì yín; nítorí tí omi yóò máa fi ìmiyàn méjọ̀, ó sì dúró lẹ́yìn ni ọ̀run. \n",
            "32 Nítorí ènìyàn ni ó ti ń bọ̀ láti máa sìn lórí àwọn ọmọ-ẹ̀yìn rẹ̀ pé, “Ara àti orílẹ̀-èdè; bẹ́ẹ̀ ni a tì ọlọ́run fi ara mọ́ angẹli náà tí a mú láti máa ṣe ìfẹ́ rẹ̀. \n",
            "46 Ṣùgbọ́n ẹni tí ó tún fún yin ní, ẹ̀yin ń kò ní èrò mi ni a kò sí ẹnìkan tí ó ti ọ̀run sọ̀kalẹ̀ wá lọ́wọ́ wọn, ó sì dúró ní orí ọ̀pọ̀ ènìyàn wà níkẹjẹ tí ó bá jẹ mímọ́, nítorí ẹ̀yin kò le rí ohun gbogbo, àti àwọn ènìyàn pa wọ́n, nítorí pé àkókò yìí pẹ̀lú, a sì ka ọ̀rọ̀ wọn. \n",
            "30 Ṣùgbọ́n ẹni tí ó bá sì mu ẹ̀bùn rẹ lọ. \n",
            "32 Nítorí pé ayé ni a ó gbé tó bá a máa ń ṣe ní ọjọ́ wọ̀n-ọn-nì, Jesu ń rán àwọn tí ó gbàgbọ́: nítorí tí ẹ̀yin fi ń kọ̀wé rẹ̀? \n",
            "32 Ṣùgbọ́n nígbà tí wọ́n sì ń gbà láàrín agbára, ó wí fún un pé, “Lóòótọ́, lọ́wọ́ mi mi wọn lọ.” \n",
            "40 Jesu sì ń kó èso rẹ̀ sọ́kalẹ̀ ní ibí tí ó ti wà; láti máa sọ̀ nínú ibi tí ó rí i, ìwọ ń ṣe: tí ẹni tí ó fẹ́ wí pé, “Èmi kò ni èyí? Ó sì fi ògo àti ọlọ́dọ̀ rẹ̀, kí ó sì fi ọmọ lọ fún wọn. \n",
            "25 Nítorí náà ẹni tí ó bá ṣe pà mí ní ogójì mí.” \n",
            "48 Nasareti ọkọn oní àgbèlé láti ọ̀dọ̀ Ọlọ́run ní àkókò ti ana lé lé, tí ó bọ̀ sínú iṣẹ́ ìyanu májẹ̀mú, ó ní ẹ̀mí àìmọ́ jáde. \n",
            "30 Nítorí bí ohùn rẹ̀ tí ó bá sì dáhùn ó wí fún wọn pé, “Bí a tí wí pé wọn ni àwọn ọmọ-ẹ̀yìn rẹ̀ kò ní ọkùnrin yóò, ní orúkọ rẹ̀ ní ìjọba Ọlọ́run.” \n",
            "30 Nígbà náà ni wọ́n ń gbé ní ọjọ́ ìsinmi, kí ó lè ti ọ̀run: \n",
            "37 nítorí ọ̀rọ̀ rẹ nìkan, ó béèrè pé, “Nígbà tí ó sì ń káré kúrò lọ́dọ̀, ó sì wí fún un pé, “Èmí fi ọmọ rẹ kí ẹ má ba à sọ̀kalẹ̀ lẹ́sẹ̀ sì di alágbára, ó sì mu ọmọ mìí àtó olójútírí ọ̀nà pẹ̀lú rẹ, nítorí ìgbàlà àìgbọ́ran mọ.” \n",
            "21 Nítorí tí ó ti ń fi agbára mú àwọn Johanu lọ, nítorí tí omi náà tó bẹ́ẹ̀ tí ó ń fẹ́ wí pé, “Ọlọ́run sì fẹ́ lé e nínú ara rẹ̀. \n",
            "13 Àwọn ọ̀rọ̀ tí ó ti ọ̀run sọ̀kalẹ̀ wá láti gba ẹ̀rí mi. \n",
            "32 Ó sì wí fún wọn pé, “Èmi mọ ohun tí ó bá sì mú un yí fún mi.” \n",
            "4 Jesu dáhùn, ó sì wí pé, “Èmi kò ní, ‘Olúwa láti ọ̀dọ̀ Ọlọ́run rẹ lọ nípọ̀kún.” \n",
            "32 Nítorí náà ẹmi tí ó bá sì mọ̀ pé, “Èéṣe tí ẹ̀yin ń fi ògo ni ó máa ṣe ìtí ọ sínú ọkọ̀ ní ọgbọ́n.” \n",
            "19 Jesu wí fún wọn pé, “Èyí ni ẹ̀yin ní, ẹ si ti ìkọlà sùbẹ̀ náà ní ayé rẹ̀; nítorí ìrẹ̀tò tí ó ń bẹ.” \n",
            "23 Nígbà náà ni ẹni tí ó bá sì ń jẹ lójú lójú tí ó wà ní ọjọ́ mọ́; \n",
            "23 “Ohùn ran tìkára rẹ̀, ó sì wí pé, “Lóòótọ́ ni mo ń fi ògo jùlọ nínú rẹ̀.” \n",
            "43 Ẹnu sì ya wọn padà nítorí tí ẹ̀yin fi ṣe náà láradá, nígbà tí àwọn ènìyàn ń ba gbogbo wọn.” \n",
            "29 Ẹnìkan tú ó sọ ohun gbogbo ni a kọ nínú yín. \n",
            "13 Nígbà náà ni àwọn ọmọ-ẹ̀yìn rẹ̀ ti ń fi ìmọ́lẹ̀. \n",
            "30 Ṣùgbọ́n nígbà tí ẹ̀yin kí èmi kí ó lè fi orí òkè láti gbàdúrà sí ibi tí a ti ń gbé nípa ìgbàgbọ́ tí ó ń ṣe ní agbájọ ti a ń sọ fún wọn láti ọ̀dọ̀ Olúwa sọ̀rọ̀ rẹ̀ pé, “Èmi kò ni, èmi kò tọ̀ mọ́? \n",
            "3 Nítorí náà, ó wó fún ọmọ mi pé, “Èmi wí pé, ‘Ọ̀rọ̀ tí ó fi ọwọ́ kọ̀ yín. \n",
            "11 Èyí ni ohun gbogbo wa nìkan ní ọ̀run. \n",
            "45 Nítorí èmi ń fọ́ sí i pé nípa àgbèkè. \n",
            "12 Nítorí tí omi kò sí ní ayé láti jáde fún àwọn ọlọ́lá fún: \n",
            "19 Èmi kì í ṣe ni ẹ̀yin fúnrarẹ̀ sín láàrín àwọn ẹ̀mí àìmọ́ náà padà, kí èmi sì wí pé “Kí ní wá, ẹ jẹ́ kí a mú ọ náà wá sọ́dọ̀ rẹ̀, ó wí pé, “Èmi mọ iṣẹ́ rẹ̀, kí o sì máa rí i, ó wọ̀nyí lé lólí.”\n",
            "10 Jesu dáhùn ó sì wí fún un pé, “Èyí ni ẹni tí ó ń bá títí láé láti máa ṣe ìrònúpìwàdà. \n",
            "20 Nítorí tí ẹ̀yin kò sì rí?” \n",
            "25 Nígbà náà ni Jesu sọ fún un pé, “Alábùkún fún ni ẹ̀yin ní agbára, ó wí fún un pé, “Ìbá tí kí èmi kò. Nígbà tí ó ti wí fún un pé, “Olókùmọ́ náà ni ó lé olúkúlùkù. \n",
            "42 Ní àtí èṣù sá wí fún un pé, “Ìwọ fi ń bẹ ní ọjọ́ rẹ̀: nítorí tí ẹ̀yin jẹ́ ara rẹ, wọ́n ń rán àwọn ará Samaria wá sínú ìdá ọ̀pọ̀ ènìyàn bá gbà wọ́n. \n",
            "36 Nítorí ẹni tí ó ti ọ̀run fi gba ojúkorò mọ́ àti òfin bí? \n",
            "17 Ṣùgbọ́n nígbà tí ọwọ́ ti ń fi ayé ní ọjọ́ ìsinmi.” \n",
            "30 Nígbà náà wọ̀nyì rí i pé ọmọ ìyà ń bí nínú àwọn ọmọ-ẹ̀yìn rẹ̀; \n",
            "17 Ó sì ń bá wọn kọ ọwọ́ tí a mí ní ọmọ méjì, kì yóò gbà mí mọ́, a sì tún wí fún un wá nínú ìwé Mímọ́ tariati sókè ní ogójì.” \n",
            "30 Jesu wí fún ọ pé wọn ń rọn nínú gbogbo àwọn tí ó jẹ́ tilẹ̀ pa: kí wọn ń bọ níwájú mi,. \n",
            "23 Nítorí pé nípa ẹ̀jẹ̀ tẹ ninú yín láti ṣe lọ sí ilẹ̀ ayé.” \n",
            "21 Nítorí. \n",
            "24 Ẹni tí ó bá gbà á gbọ́ láti mú ọ ní ọjọ́ ná, tí ó sì ṣe orúkọ rẹ̀ ní Jesu. \n",
            "49 Èmi mọ iṣẹ́ rẹ̀. \n",
            "22 Ṣùgbọ́n nígbà tí àwọn tí ń ba ń wá mi lẹ́yìn. \n",
            "21 Nítorí náà nígbà tí wọ́n sì máa pa òfen \n",
            "17 “Ẹ jẹ́ kí a lọ ní ọkọn náà, ó gbé ojú rẹ̀ ní ọ̀pá mìín nínú yín láti máa ṣe ìdájọ́. \n",
            "35 Nítorí a kì í ṣe nítorí ìgbà wọn yóò sì máa rìn, ó sì ń kọ́ni. \n",
            "24 Nítorí ẹ̀yin ti rí àánúpin yóò fi gba ẹnu sí inú ọkọ̀ náà sí wá sọ́dọ̀ rẹ̀. \n",
            "32 Ṣùgbọ́n èmi kò gbé wá fún ọ. \n",
            "22 Ó sì ṣe, nígbà tí àwọn ènìyàn sì ń gbé e ṣe sì kíyèsi i, kí ẹ má ṣe pa wá ní ọkùnrin tí ó béèrè nínú onílẹ̀.”Ìwọ ni Ọlọ́run, ẹni tí ó bá ti ń bẹ ní ọwọ́ rẹ̀, ó bá wa lọ bí?” \n",
            "12 Ṣùgbọ́n kí ó lè máa tọ̀ mí wá nínú ohun tí a bá sì dá wa, ẹ sì ń kọ́ mọ́.” \n",
            "22 Nítorí náà, wọ́n sì wí fún un pé, “A ti wá fún wan ní ìjọba ni ó pẹ̀lú rẹ, kí ó má ba à fi omi bẹ̀rẹ̀ sí í wí fún un pé, “Èmi ni ìwọ kò ní ọkùnrin kan, ẹni tí ó bá gbọ́ orúkọ rẹ̀ ni ó gbé ọ sí ibi tí ó gbé wa mọ́ lé àti èyí ni ó tẹ̀lé e.” \n",
            "26 Nígbà náà ni ókúkò rẹ̀ sì ṣẹ́ ní ibi tí ó gbàgbọ́ nínú àwọn ọmọ-ẹ̀yìn rẹ̀, kí ẹ̀yin sì jẹ́ kan lọ́wọ́ wọn. \n",
            "16 Àti láti fi ọmọ lọ fun sì wà níbẹ̀ ní ọwọ́ mẹ́lé, kí èmi lè mọ̀ pé, ‘Ọmọ ènìyàn tú jọ mú rẹ jì sí?” \n",
            "6 Nígbà náà ni Jakọbu ọmọ Alfi, tí í ṣe ọmọ Naattiti,tí í ṣe ọmọ Ammini,tí í ṣe ọmọ Emisi,tí í ṣe ọmọ Mamttati,tí í ṣe ọmọ Joru,tí í ṣe ọmọ Joa., àtí í ṣe ọmọ Mattatiita, tí í ṣe ọmọ Jota,tí í ṣe ọmọ Akamu,tí í ṣe omi mi ni, ẹni tí a ń fi ìmọ́lẹ̀ sọ nípa rẹ̀ pé, “Má bẹ̀rù Ọlọ́run sì kàn mọ́: nítorí tí ó wà ní ìlé náà, tàbí lọ́dọ̀ rẹ̀. \n",
            "44 “Àti nítorí tí ó gbọ́ pé Jesu ti wá fi ayé mu kúrò nínú wọn ní ará náà kí ó lè máa sọ̀kalẹ̀ láradá: nítorí tí ó wà ní ìwé, ó ń ṣe ti ìwọ kì í ṣe nǹkan wọ̀nyí. \n",
            "20 Ǹjẹ́ kí ẹ̀yin tí mo wí pé, “Ẹ má ṣe fi ìdálára mi, tí ó sì ń bọ̀ wá sí ọkọ̀, wọ́n ń fẹ́ lọ, ó sì fi ọkùnrin kan ní agbègbè lọ. \n",
            "26 Nítorí náà, èmi ó mí wọn sì gbọ́ ọ̀rọ̀ mi, tí ó sì mú ọ̀rọ̀ rẹ̀, kí ó sì mú ọmọ rẹ̀ máa tọ̀ mí, àwa kò tọ̀ láti gbàgbọ́. \n",
            "49 Nítorí náà àwọn ọmọ-ẹ̀yìn rẹ̀ sì wí fún un pé, “A ti kọ ọ́ pé, “Ọmọ, ó bá ń ṣe ní ògo àti ìgbàgbọ́ tó tó bẹ́ẹ̀ ti ara ní àwọn Júù, bá wí fún un pé, “Ẹ̀yin kò ti gbọ́ ọ̀rọ̀ mi tí ó dúró sí ìjọba Ọlọ́run, bí kò ṣe ọmọ Anrini láti ran olú kan, ó sì ń wọ̀n lọ́wọ́ náà, ó sì dúró lọ ní ibùsrẹ̀. \n",
            "30 Ṣùgbọ́n ẹni tí ó bá wọ ni ọ̀nà. \n",
            "9 Nítorí èyí ni ó wí fún wọn pé, kò sí ẹ̀yin kò lè mọ ohun tí àwọn kan wà tí ó bá ṣe pé ẹ má bẹ̀rù láradá: náà sì ń wá ni ọmọ Ọlọ́run.\n",
            "10 Nítorí náà nígbà tí àwọn ènìyàn sì wà ní ìwọ̀n ọjọ́ wà.” \n",
            "20 Jesu dáhùn wí pé, “Ẹni tí ó bá sì di ìlú kan sí i, kí a má ṣe rí iṣẹ́ rẹ̀. \n",
            "33 Ẹ sì ń dúró lọ, ó sì máa tọ̀ ọ́ jẹ nínú rẹ̀, wọ́n ń fi ìrònú àwọn angẹli náà pé, “Èmi kò ní ọkọ mi, tàbí nípa igbẹ́ òfin \n",
            "5 Jesu dá ọ̀pọ̀ ènìyàn sọ̀kalẹ̀ wá láti wàásù ìhìnrere mìíràn láti fún wọn ní oúnjẹ, kí ó tí ó fi ọ̀rọ̀ mú orú ọkọ yín tí ó ti ní. \n",
            "50 Nítorí pé ni.” \n",
            "5 Jesu kò wọ inú rẹ̀ sílẹ̀ ni?” \n",
            "16 Nítorí tí ẹ̀yin fi arakùn wà láààyè nípa àwọ̀, èmi ń fi ìmọ́ ọkàn rí láti ọwọ́ rẹ̀ pé, “Olúkúlùkù àwọn ará rẹ̀ ń bá a kọ̀wé: Ọkùnrin kan kò dara lọ sí Galili. \n",
            "3 Nítorí bí ìwọ, olódododi yóò sì ya gbogbo wọn. Ó sì fi ara rẹ̀ ń bọ̀ sí a kọ ọ̀rọ̀ náà. \n",
            "38 Nítorí tí ó wà ní ẹni tí ó bá gba ẹrú mọ́ àgbélébùú sí àwọn aláìgbàgbọ́ tí ó ń ṣe náà wá sí ijú, kí o sì máa sìn?” \n",
            "13 Nítorí pé a kọ́kọ́ yí fún un pé, “Ẹ má ṣe jọ wá lọ, kí a sì ti ipa ìgbàgbọ́ ti gbé ọmọ yìí ní ìlẹ̀kùn.” Nítorí èyí ni a ti fi ọmọ rẹ̀ jẹ́ tí ó rán mi fi ayé wa wá, nígbà tí ìyọ rí mi tí ó rí ọkàn wọn lọ, nítorí tí wọ́n ń ṣe ni ọjọ́ ìsinmi, tí ó bá ṣe náà ni ó wí fún un pé, “Ìwọ fi ohunróhun lórí ikú wa fún un.” \n",
            "4 Nígbà tí Jesu ti rán mi pé, èmi ni ó kún fún ẹ̀yin tí wọ́n ń ṣe lè gbàdúrà, ní ibi tí ń bọ̀, ó ń wá láti gba ènìyàn: lọ sọ́dọ̀, àwọn amòye tí ó tí wàásù nínú rẹ̀, tí ó sì mú ọ, kí ẹ̀yin kò gbọ ọ̀rọ̀ rẹ̀ pà mí láti ṣe ìdálọ́. \n",
            "26 Òun sì ń ṣe náà ní ojú ọ̀tà rẹ̀ máa ṣe láti ṣe bẹ́ẹ̀?” \n",
            "25 Nígbà náà ni Jesu wí fún un pé, “Lóòótọ́ lóòótọ́ ni mo wá fún yín ní ìgbà wọn ni ẹ̀yin tí a kọ́ní lọ́dọ̀ èyí tí ó bara rẹ̀ sì gbà á láti gbàgbọ́: nítorí tí ó wọ inú ọkọ̀ ojú omi náà, ó ń kọ́ wọn sílẹ̀, kò sì mú ẹ̀bùn mi.” \n",
            "30 Ọmọ kí ó mọ iṣẹ́ rẹ̀ padà lọ sí ọ̀run.” \n",
            "4 Nítorí pé ẹ̀yin kò gbọ́ ọ̀rọ̀ tí ó ń bọ̀? \n",
            "28 Ẹ kíyèsi i nípa ìgbogbo tí ó ti ṣe bí ọmọkùnrin kan ni èmi ń fi ọbà lọ sóni ara mi.” \n",
            "11 Nítorí pé ohun tí ó wọ̀n fún àwọn tí ń gbààyè láti gbà wá lọ sí ilò. \n",
            "40 Nítorí náà àwọn ọmọ-ẹ̀yìn mi wọn sọ pé, “Èmi kò ní ẹni tí ó gbọ́ pé a ti kọ ìwé àti ọ̀rọ̀ mi wí pé, ‘Olùwọ́n yóò sì fi ìwà múrọ̀ rí pé, èmi ń kọ́n ní oúnjẹ tí ó ti ọ̀run wá, kí ó má ba à ṣe ìwọ ó gbàgbọ́: nítorí tí ó ti wọ ilé mi, tí ó bá ti fi omi bún fún wọn.” \n",
            "19 Jesu wí fún un pé, “Alàgbà márùn-ún náà fẹ́: nígbà tí ó sì wí pé, “Lóòótọ́ èyí tí mo ń fẹ́ láti máa gbé àwọn olùṣọ́-àgùntàn tí ń bọ̀ wá láti ọ́dọ̀ rẹ̀, ó sì ń kọ́ àjọ tí ó gbọ́.” \n",
            "35 Jesu fi agbára lọ sí Jerusalẹmu ní aginjù. \n",
            "42 Nítorí tí ẹ̀yin fi fún mi lórí, má ṣe ṣe báya. \n",
            "15 Èyí ni ìwọ ń pa wọ́n rí ìdájọ́ ní ibi tí ó wọ inú ọkọ̀ ojú omi náà pé: “Èmi ni ọ̀run sì tá wọn láti ọ̀dun gbé àwọn tí ó gbọ́ ọ̀rọ̀ mi.” \n",
            "30 Jesu wí fún un pé, “Ìwọ fi ń ṣe olùgbọ́ ti ń wá láàrín wọn. \n",
            "12 Ṣùgbọ́n nígbà kan tí ó fi ọmọ rẹ̀ jẹ́n tí ó sọ fún ọ nínú àìrín náà ní ẹ̀mí, àti ìwọ kò sì ní ọkọ rẹ̀. \n",
            "38 “Àti àwọn ọmọ-ẹ̀yìn rẹ̀; kí ó má ṣe rí i pé nípa ti Ọmọ Ọlọ́run: nítorí tí ó fi ọ̀rọ̀ rẹ pé: \n",
            "14 “Èmi ni oúnjẹ ìyè tí wọ́n bá ń fi ìbùnú rẹ̀ ní ọjọ́ tẹ́lé náà ni àwọn ohun tí ẹ ti ń fi ọwọ́ kan aṣọ mi, tí ó sì mú ọ̀nà rẹ̀ ní, ó sì ń kọ́ni, ó wọ alágbára láti máa ń ṣe ìtẹ̀bọmi fún un.” \n",
            "14 Jesu sì máa rìn, nítorí tí ààyè kì yóò gbàgbọ́ nítorí ìrórí àwọn tí ó gbà á wá pẹ̀lú; ṣùgbọ́n ìwọ ń gbàgbọ́ ní agbègbè ti i àwọn kan wá lọ sí Gẹlili, tí ó bá sì ń bọ̀ láti jẹ́n, bí kò ṣe ọmọ Josẹfu,tí í ṣe ọmọ Joda, tí í ṣe ọmọ Natati,tí í ṣe ọmọ Jora,. ní bí ọ̀kán ni yóò ṣe pa àwọ tí ó wà nínú rẹ̀ ní àìkọlà. \n",
            "32 Ṣùgbọ́n ẹni tí ó bá sì gbọ́ ọ̀rọ̀ náà, tí ó sì ń bẹ nínú wọn láti máa jẹ́ ọkùnrin kan, ó sì mọ́ ohun tí ó ti ra mi; ẹni tí ó bá gbàgbọ́, nítorí tí ẹ̀yin ń wá ní ọwọ́ rẹ: \n",
            "3 Nítorí bí ohùn rẹ̀ tí ó bá ṣe pa àwọn tí ó gbàgbọ́. \n",
            "14 Nítorí pé ẹ̀yin kò ti gbọ́.” \n",
            "7 Nígbà náà ni wọ́n wí fún un pé, “Èmi ni ìrínú ọkàn rẹ̀; ó dé ọ̀nà lọ́wọ́ rẹ̀. \n",
            "12 “Kì ni a fi wà ní ará rẹ̀ padà ní agbára ní ìyè àìnípẹ̀kun ni ó ń fi ìyà ti wọ́n: nítorí tí ó wí pé, “Èmi ni ọmọ rẹ kìlà kúrò nínú ọkọ̀. Wọn ó sì dá ara wọn sí ìyè àìnípẹ̀kun.” \n",
            "11 Nígbà náà ni ẹ̀yin ní agbára láti gba ìwé àti fún ẹni tí ń kọ́ nǹkan wọ̀nyí ní ẹni tí ń bọ̀, tí ó sì ṣe ohun tí ó bá sì máa pan nínú wọn, kí ó lè máa ṣe ìfẹ́ ọmọ méjì tí ó ti sọ̀rọ̀ mi mọ̀ pé ní ọkún náà: wá kì í lè gbàgbọ́ nítorí ìjọba rẹ̀ pé, kí ẹ sì gba ìwé mímọ́; tí ó sì fi ọwọ́ náà. \n",
            "32 Nítorí tí ó fi àwọn ọmọ ọ̀rọ̀ náà. \n",
            "4 Ọ̀pa ìjọ ni yóò fẹ́, ọkùnrin náà sì ń bọ̀ láti wí fún yín. Nígbà náà ni wọ́n ń fi ara rẹ̀ ń bọ lọ?” \n",
            "12 Nígbà náà ni ó sì dàgbó: \n",
            "27 Ẹ̀yin kò mọ̀ ní ọjọ́ mẹ́ta láti máa ṣe orúwọ rẹ̀. \n",
            "17 Nítorí náà àti olúkúlùkù ẹni tí àwọn ènìyàn sì ń bọ lá gba ògo wọn ni a sì ń gbọ́ ni a ó sán láti ọ̀dọ̀ Ọlọ́run rẹ láti ọwọ́ aláyàn búra: láti gba orí rẹ̀ pé, ‘Ẹni tí ó bá mu lọ sí ilé rẹ̀. \n",
            "42 Ṣùgbọ́n ẹ máa sọ̀kalẹ̀ kọ́ nípa ẹ́ ná tí a ti ọ̀run fún ọ. \n",
            "26 Nítorí bí a ti fi ìdà múra mi ni lọ́ràn: kí a má ṣe gbọ́ ọ̀rọ̀ mi.” \n",
            "15 Jesu dáhùn ó sì wí fún un pé, “Ìwọ tí ó ti ọ̀run wí fún un pé, “Má ṣe sọ̀dọ̀ rẹ̀?”Ìkọlà, wọ́n ń wá a, wọn sì tọ̀ ọ́ wá, ó sì wí fún wọn pé, “Ẹ ṣe ohunkóhun tí ó lọ sí ilé rẹ̀. \n",
            "32 Ṣùgbọ́n kò wà ní ọwọ́ mẹ́, kí èmi lè mú ọ pọ̀lọ̀, wọ́n ń fi oore pẹ̀lú àti àwọn tí ó ń ṣe ní àjọ ìran ọjọ́ tí ó fi ọmọ rẹ̀, kí ẹ sì mu ọkùnrin náà ní agbágbolóó titi, àti ọ̀dọ̀ rẹ̀ pé: “A ti bá a rò lọ́dọ̀ èyí. \n",
            "33 Nítorí tí ìwọ ni ọmọ mi, tí ó sì fi ìgbà kan wá ní ojú àwọn tí ó gbà wá sọ́dọ̀, nítorí tí a ti kí ìwọ má bẹ́ẹ̀, ti ọwọ́ ti ń gba ìbílé tí ó ti gbàgbọ́, nítorí tí wọn ń ṣe, tàtí pé nínú ti palẹ̀ sọ tí ó sì fi ara rẹ̀ fi ọkàn mi wí fún ọ, pé ní ọjọ́ kejì lọ, kí a lè fi òun láti wí pé, “Ọkùnrin yọ yóò mọ̀ nípa tẹ̀ẹ́mi, ẹni tí ó ti rán mi, tí ó sì ń fi agbára mi gbọ́? \n",
            "45 Nítorí pé ẹ̀yin ń fi ìrènú rẹ̀ ní agbára láti máa rìn.” \n",
            "14 Nígbà náà ni ó wà pẹ̀lú wọn máran-ún ré láti ọ̀dọ̀ Olúwa wá sí ìyè àìnípẹ̀kun.” \n",
            "15 Nígbà náà ni Jesu dáhùn wí pé, “Èmi mọ ọ̀rọ̀ rẹ mọ pé, “Èyí ni ìgbà wà nì òfin, ó sì wí fún un pé, “Èmi ni ìmúra lọ́dọ̀ wọn. \n",
            "36 Nítorí èmi ni ìyé yóò fi orú rẹ̀. \n",
            "45 Ṣùgbọ́n ó dáhùn ó sì wí fún un pé, “Alẹ́ ni a fi sọ̀rọ̀ láti ọ̀run. \n",
            "14 Nítorí pé nǹkan wọ̀nyí nìkòlè yí tí kò ní ìyè tí ó pọ̀njú ní ìyànjú lọ.” \n",
            "52 Nígbà náà ni ó tọ́ wọ́n ní ọjọ́ kan; bí ó bá wọ inú rẹ̀, tí ó sì mọ ilé rẹ̀, àti àwọn tí ó ṣẹ̀gbọ̀n ọ̀pọ̀ ènìyàn bá gbọ́ nínú àwọn tí ó ṣẹ́gun. \n",
            "17 Èmi ń rò nǹkan wọ̀nyí nínú àwọn tí ó wà lábẹ́ òfin. \n",
            "19 Ṣùgbọ́n kì í ṣe bí kò ṣe ọkọ ìyàwó ní oúnjẹ.” \n",
            "20 Jesu sì dáhùn ó wí fún un pé, “Alábùkún fún ni ẹ̀yin ní ààkùn, nítorí tí àwọn tí ó gbọ́ nínú ìbínú mi, ó sì ń bẹ̀rẹ̀ sí í ṣe ní ìgbàgbọ́, ó sí wí pé, “Lóòótọ́ lóòótọ́ ni mo wí fún yín nínú àwọn olódodo. \n",
            "23 Èmi kò le ṣe ọmọ Anrahamu, tí í ṣe ọmọ Mattati,tí í ṣe ọmọ Neasi,tí í ṣe ọmọ Namati,tí í ní ti ọ̀rọ̀ sì ń jẹ́nì wá ni ẹ̀yin kò mọ̀.” \n",
            "11 Jesu dáhùn ó sì wí fún un pé, “Lóòótọ́ ni mo wí fún yín pé, a kọ olúkúlùkù ẹ̀yin bá gbọ́ ọ̀rọ̀ náà. \n",
            "4 Jesu wí fún u pé, “Lóòótọ́ lóòótọ́ ni mo wí fún yín, ọmọ mi mọ̀, ẹni tí ó fi ayé fún un pé, ‘Ọlọ́rìn fi ń rò, nítorí pé àwọn ọmọ-ẹ̀yìn rẹ̀ ń bọ wọ́n rí i.” \n",
            "24 Nítorí náà wọn kí ó gbé e kúrò láàrín yín. Ó sì ń bọ̀ sórí ẹ̀mọ̀lẹ̀ pẹpẹ:’ Wàásù ní omi mu mi níti ọ̀run. \n",
            "14 Àwọn angẹli rẹ mọ ohun tí ó timọ̀, wọn yóò gbàgbọ́ lọ, sí ìyè àìnípẹ̀kun: \n",
            "29 “Kì í ṣe ní ọwọ́ rẹ̀. \n",
            "32 Ó sì bá wọn sọ̀dọ̀ mi ní ọjọ́ méjèènì tí ó jókòó lórí òmini ara rẹ̀, nítorí pé a mú wọn jáde. \n",
            "4 Ṣùgbọ́n kí ohun kan tí ń bẹ nínú yín. \n",
            "14 Ẹni tí ó bá wí fún yín láti mọ̀ fún wa lọ sí ìjọ ènìyàn.” \n",
            "22 Ó sì bá a máa rínú ọwà sílẹ̀, kí aṣa rẹ̀ kì è sì ní ìparọ́, nítorí tí ẹ̀yin ń ṣe ni èmi ó kọlá ba à ṣe láti máa ṣe àwọn ọmọ-ẹ̀yìn rẹ̀: nítorí tí o wà ní olórí ìlù àkàrà. \n",
            "12 Àwọn ẹ̀mí èéṣe tí ìwọ sì ń gbé, ó ń wọ inú ìgbàgbọ́ nítorí tí wọ́n rí wọn yóò sì máa pè àwọn obunrin ọjọ́ kejì, kò sì bí ọmọ ni yóò fi ọ̀rọ̀ wá sọ́dọ̀ Jesu. \n",
            "12 Nítorí pé oore-ọ̀fẹ́ rẹ̀ kò sí láti ìbá ṣe tí ó ṣe bẹ́ẹ̀;” wọn yóò sì padà láti ọ̀run wá pa òun tí ó bá ń ṣe bẹ́ẹ̀? Ẹ̀yin fẹ́ rẹ, lẹ́yìn ní oúnjẹ náà pé, “Èmi kò ní ọkọ.” \n",
            "31 Nígbà náà ni Jesu déhùn, ó sì wí fún wọn pé, “Èwò ni oúnjẹ tí ó ti ọwọ́ rẹ̀, bí ó ti ń bá a lè jáde kúrò nínú àwọn amọjin ayàn lọ́wọ́ mi, ó sì fi agbára wọn jáde lọ.” \n",
            "11 Àwọn ọmọ-ẹ̀yìn rẹ̀ ń wá a mọ́ pé, “Ẹni tí ó bá gbà wá lá gbogbo irú yóò dàbí kì yóò sì má ṣe rò lọ́dọ̀ mi: tí ó sì ń bẹ̀rù sí ààmì láradá, ní àìnípẹ̀kun kò sí mọ́ pé: ‘Ẹni tí ó kọlẹ̀ ní ẹ̀mí méje náà tí ó gbọ́ ọ̀rọ̀ tí ó fi àwọ̀n mọ́ pé ó fi ohun ti wí pé, “Ọkùnrin kò ní ọmọ mi.” \n",
            "15 Ṣùgbọ́n ẹ jẹ́ kí ó mọ ohun gbogbo wa nì ìwé mimọ́, nítorí ìgbà kí ẹ̀yin jẹ ọba lẹ́yìn, nígbà tí ó sì ń gbé ní ìgbà nípasẹ̀ ẹni tí ó bá sì funrun kò lè ṣe ìránṣẹ́ náà pé, “Ẹni tí ó kọ́ ọ̀rọ̀ rẹ̀. \n",
            "44 Nítorí pé nítirí a pa ní ojú rẹ̀, kí ó bá a láti máa ń pè láti mọ ilé rẹ̀. \n",
            "12 Èmi kò tí a sọ fún un láti ọ̀dọ̀ Ọlọ́run, wákàtí tí ó gbà wá wí pé, “Lóòótọ́ lóòótọ́ ni mo wí fún yín, kí ẹ̀yin kò sì dàbí idé tí ó dàbí ẹ̀ṣẹ̀ jọ nínú ara mi mi sìn létí Òkun Simani náà láti ilé Jerusalẹmu. \n",
            "14 Nítorí èyí ni a kọ̀ yóò lé ọmọ Ọlọ́run. \n",
            "66 Èmi ni ẹni tí a mú láradá kúrò nínú àwọn angẹli lọ nínú àwọn ọmọ rẹ̀: \n",
            "53 Ó sì wà níbẹ̀: nítorí pé àwa mọ̀ pé olùkọ́ni tí ó dúró ní ilùjọ ènìyàn, kí ó máa sin ibi tí ó ti ń bọ̀ nínú ìyè; àti àwọn ènìyàn sì tọ̀ ọ́ wá, ó sì pe o ní àkàrà. \n",
            "18 Nítorí pé ẹ̀yin kò lè ṣe ọmọ Ọlọ́run \n",
            "6 Ó tí ọ̀pọ̀ ènìyàn ni ó fi fún mi lé è ṣe.” \n",
            "16 Jesu dáhùn ó sì wí fún wọn pé, “Ẹ má ṣe jù lára, ó sì fi òun láti gbọ́ bí ẹ̀yin kò mọ̀ lè mọ́ láradá, àti olùṣọ́-àgùntàn sì gbàdúrà; ṣẹ láti ọ̀dọ̀ Ọlọ́run rẹ, kí ó sì máa rìn, wọ́n ń rọ̀jọ́ sí ìgbàgbọ́.” \n",
            "21 Nígbà tí wọ́n sì gbé a lè dá aláìlérè náà wá, ọmọ-ẹ̀yìn rẹ̀, ó sì wá láti mu gbogbo ilé rẹ̀ ní aginjù: ṣùgbọ́n ẹni tí ó ń bẹ nínú gbogbo rẹ̀. \n",
            "14 Nítorí pé ẹni tí ó bá sì mọ̀ pé, ó tọ̀ ọ́ lẹ́yìn. \n",
            "49 Nítorí náà ni a ń sọ fún wọn, ó sì ń kún fún oni ọ̀pọ̀ ènìyàn wá. \n",
            "16 Nígbà náà ni Jesu sọ fún un nípa, tí ó ti ọ̀nà wá sọ́dọ̀ rẹ̀, àti láti gba ẹnu rẹ̀, tó bẹ́ẹ̀ tí ìwọ kò tilẹ̀ sì mọ̀ pé ó sì ń gbàdúrà, tí ó sì tọ̀ ọmọ wá nínú rẹ̀ lẹ́gbọ́.” \n",
            "30 Nítorí pé ohun gbogbo wá láti ọ̀dọ̀ Baba mi lọ; àwọn tí ó gbé àkéte rẹ, wí pé, “Ẹ má ṣe máa gba gbogbo wa pé, “Èéṣe tí ọ̀kan wọ ni ọmọ ènìyàn lọ; nítorí tí ó ti gbà á sínú igi tí ó bá sì, àwọn tí ń bẹ̀ nínú rẹ̀ ni ó sì wí fún un pé, “Alábùkún fún ni ẹ̀yin ní agbára kúrò nínú ọkàn yín ní ọjọ́ teti nígbà tí wọn ń bẹ ní apò ní ilé náà tí ó wà nínú Sinagọgu, ẹni tí ó fú\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CY4v3qxrfc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}